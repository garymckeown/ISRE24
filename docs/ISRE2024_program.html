<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ISRE 2024: Conference of the International Society for Research on Emotion - ISRE 2024 Program</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./images/favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-33PP5XPV1R"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-33PP5XPV1R', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>
<meta property="og:title" content="ISRE 2024: Conference of the International Society for Research on Emotion - ISRE 2024 Program">
<meta property="og:description" content="">
<meta property="og:site_name" content="ISRE 2024 Belfast">
<meta name="twitter:title" content="ISRE 2024 Belfast">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@gmckeown">
<meta name="twitter:card" content="summary">
</head><body class="nav-fixed">\usepackage{array}
\usepackage{sectsty} \allsectionsfont{\centering}
\setkomafont{section}{\normalfont\Huge\bfseries}
\usepackage[default,scale=0.95]{opensans}
\renewcommand\seriesdefault{l}
\renewcommand\mddefault{l}
\renewcommand\bfdefault{sb}% or \renewcommand\bfdefault{m}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{eso-pic}
\usepackage{tikz}
\AtBeginDocument{\thispagestyle{empty}\begin{tikzpicture}[remember picture,overlay] \node at (current page.south) [yshift=6cm] {\includegraphics[width=0.25\paperwidth,height=0.25\paperheight,keepaspectratio]{images/ISREStarburstText.png}}; \node at (current page.center) [yshift=5cm] [anchor=north,yshift=-2cm] {\Huge\textbf{2024 Conference of the International}}; \node at (current page.center) [yshift=4cm] [anchor=north,yshift=-2cm] {\Huge\textbf{Society for Research on Emotion}}; \node at (current page.south) [yshift=5cm] [anchor=north,yshift=-2cm] {\normalsize\textbf{17 - 20 July 2024}}; \end{tikzpicture}\clearpage}


<link rel="stylesheet" href="styles.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/ISREStarburstTextWhiteNavBar.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./registration/index.html"> 
<span class="menu-text">Register</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-program" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Program</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-program">    
        <li>
    <a class="dropdown-item" href="./program/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./program/instructions.html">
 <span class="dropdown-text">Instructions for Presenters</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./program/days/july_18.html">
 <span class="dropdown-text">18 July</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./program/days/july_19.html">
 <span class="dropdown-text">19 July</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./program/days/july_20.html">
 <span class="dropdown-text">20 July</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://whova.com/portal/isrec_202407"> 
<span class="menu-text">Whova App</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.isre.org/news/668358/A-New-ISRE-Initiative---Emotion-Express-One-Minute-to-Inspire.htm"> 
<span class="menu-text">Emotion Express</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-pre-conferences" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Pre-conferences</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-pre-conferences">    
        <li>
    <a class="dropdown-item" href="./preconference/list/affective_computing.html">
 <span class="dropdown-text">Affective Computing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./preconference/list/cross_species.html">
 <span class="dropdown-text">Cross-Species Emotion Research</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./preconference/list/experience_regulation.html">
 <span class="dropdown-text">Keep Calm and Regulate On(line)?</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./preconference/list/emotions_relationships.html">
 <span class="dropdown-text">Emotions in Interpersonal Relationships</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./preconference/list/engaging_suffering.html">
 <span class="dropdown-text">Engaging with Other People’s Suffering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./preconference/list/emotional_development.html">
 <span class="dropdown-text">Emotional Development</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./preconference/list/laughter_workshop.html">
 <span class="dropdown-text">Laughter and Other Non-Verbal Vocalisations</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./people/index.html"> 
<span class="menu-text">People</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-location" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Location</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-location">    
        <li>
    <a class="dropdown-item" href="./location/Queens.html">
 <span class="dropdown-text">Queen’s University Belfast</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./location/Belfast.html">
 <span class="dropdown-text">Belfast City</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./location/Stormont.html">
 <span class="dropdown-text">Opening Reception</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./location/TitanicBelfast.html">
 <span class="dropdown-text">Banquet + Titanic Belfast</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./accommodation/index.html"> 
<span class="menu-text">Accomodation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./sponsorspage/index.html"> 
<span class="menu-text">Sponsors</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./contactus/index.html"> 
<span class="menu-text">Contact Us</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    <div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="ISRE2024_program.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ISRE 2024 Program</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div style="page-break-after: always;"></div>
<section id="acknowledgements" class="level1">
<h1>Acknowledgements</h1>
<p>We would like to thank the many people who have helped in the preparation of the conference.</p>
<p>Dissertation Award judges:</p>
<ul>
<li><p><strong>Phase 1</strong> - Initial Review: Andrea Scarantino, Ronnie de Sousa, Armindo Freitas-Magalhães, Karen Gasper, Manny Gonzalez, Pascal Hot, Elif Sandal Önal, Yoann Stussi, Eric Vanman, Eric Walle, Michelle Yik, and Vanda Zammuner.</p></li>
<li><p><strong>Phase 2</strong> - Detailed Review: Ronnie De Sousa, Manny Gonzalez, and Yoann Stussi.</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
<section id="organisation-committee" class="level1">
<h1>Organisation Committee</h1>
<p><strong>Conference Chairs:</strong></p>
<ul>
<li>Gary McKeown, Queens University Belfast</li>
<li>Magda Rychlowska, Queens University Belfast</li>
</ul>
<p><strong>Program Chairs:</strong></p>
<ul>
<li>Arvid Kappas, Constructor University Bremen</li>
<li>Yasemin Erbas, Tilburg University</li>
</ul>
<p><strong>Local Chairs:</strong></p>
<ul>
<li>Salvador Alvidrez, Queens University Belfast</li>
<li>Bronagh Allison, Queens University Belfast</li>
<li>Anna Hollis, Queens University Belfast</li>
</ul>
<p><strong>Early Career Team:</strong></p>
<ul>
<li>Kristina Šparemblek, Queens University Belfast</li>
<li>Elisabella Hohulin, Queens University Belfast</li>
<li>John Curry, Queens University Belfast</li>
<li>Sam Manson, Queens University Belfast</li>
<li>Zoi Polyzopoulou, University of Western Macedonia</li>
<li>Ana Milošič, Queens University Belfast</li>
</ul>
<p><strong>Publicity Chair:</strong></p>
<ul>
<li>Teerawat Monnor, Université de Genève</li>
</ul>
<p><strong>Career Development Chair:</strong></p>
<ul>
<li>Manuel Gonzalez, Queens University Belfast</li>
</ul>
<p><strong>Travel Awards Chair:</strong></p>
<ul>
<li>Bethany Corbett, Ulster University</li>
<li>Anna Hollis, Queens University Belfast</li>
</ul>
<p><strong>Sustainability Consultation:</strong></p>
<ul>
<li>Sam Drury Shore, Devizes Outdoor Celebratory Arts</li>
</ul>
<p><strong>Webmaster:</strong></p>
<ul>
<li>Damien Dupré, Dublin City University</li>
</ul>
<div style="page-break-after: always;"></div>
</section>
<section id="keynote-speakers" class="level1">
<h1>Keynote Speakers</h1>
<section id="july-yuri-miyamoto-930---1030" class="level3">
<h3 class="anchored" data-anchor-id="july-yuri-miyamoto-930---1030">18 July: Yuri Miyamoto (9:30 - 10:30)</h3>
<p>Yuri Miyamoto, a Professor in the field of social and personality psychology at Hitotsubashi University, is renowned for her pioneering research on the intricate interplay between culture and psychology. Through her scholarly work, she has unraveled the multifaceted ways in which culture influences our emotional and cognitive processes, with significant implications for our well-being (Miyamoto et al., in press).</p>
</section>
<section id="july-phoebe-ellsworth-1100---1200" class="level3">
<h3 class="anchored" data-anchor-id="july-phoebe-ellsworth-1100---1200">19 July: Phoebe Ellsworth (11:00 - 12:00)</h3>
<p>Phoebe Ellsworth is noted for her work in law and psychology. More specifically, she has done research on jury behavior and decision making, public opinion and the death penalty, and eyewitness identification. Her other main research interest is in emotions. Some areas of research in this topic include facial emotions, cognition and emotion, and interpretation of emotion. As a graduate student, she worked with Paul Ekman and Wallace Friesen to develop the photographs that were used in their research comparing perceptions of emotional faces across cultures. Phoebe Ellsworth is known for her contributions to appraisal theory, emotions and culture, challenges of emotion and language, and for her writing on William James. In much of her research, Phoebe Ellsworth has intertwined an interest in cultural differences. In particular, she has taken a look at the cultural differences in perceiving facial emotions (Masuda, Ellsworth, Mesquita, Leu, Tanida, and Van de Veerdonk, 2008).</p>
</section>
<section id="july-terry-maroney-1100---1200" class="level3">
<h3 class="anchored" data-anchor-id="july-terry-maroney-1100---1200">20 July: Terry Maroney (11:00 - 12:00)</h3>
<p>Terry Maroney investigates the intersection of law and emotion. She is also a scholar of criminal law, with specializations in wrongful convictions and in juvenile justice. Professor Maroney’s work on the role of emotion in judicial behavior and decision-making forms the backbone of her scholarly focus. Weaving legal analysis together with the psychology, sociology and philosophy of emotion, her work illuminates how emotional experiences, dynamics, and their management interact with the constraints and demands of varied judicial roles, with deep implications for judges and the public they serve. Maroney’s many publications in this area—which include “(What We Talk About When We Talk About) Judicial Temperament,” “Angry Judges,” “Emotional Regulation and Judicial Behavior” and “The Persistent Cultural Script of Judicial Dispassion”—have been widely read among the U.S. judiciary. She frequently consults with and presents to judicial audiences in both the United States and abroad. With Judge Jeremy Fogel (now retired) and the Federal Judicial Center, she co-founded a novel intensive seminar focused on the human side of judging, now offered regularly to mid-career federal judges.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="conference-locations" class="level1">
<h1>Conference Locations</h1>
<p>ISRE2024 will take place <strong>on the main Queen’s University Belfast campus</strong>, in the <a href="https://www.qub.ac.uk/events-at-queens/venues/whitla-hall/">Whitla Hall</a>, the <a href="https://www.qub.ac.uk/events-at-queens/venues/great_hall/">Great Hall</a>, and the Peter Froggatt Centre.</p>
<p><img src="images/buildings_map.png" class="img-fluid"></p>
<p>Download the campus map <a href="https://www.qub.ac.uk/home/Filestore/Filetoupload,1511241,en.pdf">here</a>.</p>
<p>Please note that <strong>Shimna: PFC/02/011</strong> is the quiet room during the main ISRE2024 conference.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="instructions-for-presenters" class="level1">
<h1>Instructions for Presenters</h1>
<section id="oral-presentations-flash-talks" class="level3">
<h3 class="anchored" data-anchor-id="oral-presentations-flash-talks">Oral Presentations &amp; Flash Talks</h3>
<p>For those giving Oral Presentations, you will be afforded a <strong>12-minute slot for your talk and two minutes for any audience questions</strong>.</p>
<p>For a Flash Talk, you will be afforded <strong>six minutes for your presentation and two minutes for brief questions</strong>. We will maintain a strict schedule, and you can expect the next speaker to begin to set up as you take questions.</p>
<p>Speakers can present using the computers in the rooms or their own laptops, and we will provide audio. In all rooms in the conference, the projection systems are in the 16:9 format.</p>
<p>Symposia will be moderated by the symposium organizers. Individual talks sessions will be assigned a moderator. Moderators will be communicated in the ISRE2024 program in the next weeks. For oral presentations, please make sure to contact your session moderator before your scheduled session. You may be asked to send your slides in advance.</p>
</section>
<section id="posters" class="level3">
<h3 class="anchored" data-anchor-id="posters">Posters</h3>
<p>You are strongly encouraged to set up posters in the morning before the first conference session. You are welcome to leave your poster up till the end of the day. The following are the guidelines for poster presentations:</p>
<ul>
<li><p>Poster size is limited to <strong>121cm x 121cm</strong> (4 x 4 ft, A0 format maximum). Landscape and portrait layouts are both supported. We will provide posterboards and stationery for attaching your poster.</p></li>
<li><p>The boards will contain the <strong>poster number</strong> assigned to your poster so that you will know which board to use.</p></li>
<li><p>Your poster must contain the abstract title and the name(s) of the poster author(s).</p></li>
<li><p>QR codes may be included on posters and handouts so long as the code does not lead to a website or materials promoting or marketing a company or product</p></li>
<li><p>You should bear in mind that your illustrations will be viewed from distances of 3 feet or more. All lettering should be sized accordingly.</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="pre-conferences-17-july" class="level1">
<h1>Pre-conferences (17 July)</h1>
<p><strong>Registration in Whitla Hall</strong></p>
<p>We are thrilled to offer an array of pre-conference events designed to enrich your experience and deepen your engagement with the topics at hand. Dive into specialized workshops, networking sessions, and interactive discussions led by experts in their respective fields:</p>
<ul>
<li><p><a href="https://www.isre2024.org/preconference/list/affective_computing.html">Affective Computing Pre-Conference at ISRE</a> (Bann: PFC/0G/024)</p></li>
<li><p><a href="https://www.isre2024.org/preconference/list/cross_species.html">Cross-Species Emotion Research</a> (Moyola: PFC/02/017)</p></li>
<li><p><a href="https://www.isre2024.org/preconference/list/experience_regulation.html">Keep Calm and Regulate On(line)?</a> (Shimna: PFC/02/011)</p></li>
<li><p><a href="https://www.isre2024.org/preconference/list/emotions_relationships.html">Emotions in Interpersonal Relationships</a> (Roe: PFC/02/018)</p></li>
<li><p><a href="https://www.isre2024.org/preconference/list/engaging_suffering.html">Engaging with Other People’s Suffering: Emotion, Empathy, Eudaimonia and Curiosity</a> (Farset: PFC/02/025)</p></li>
<li><p><a href="https://www.isre2024.org/preconference/list/emotional_development.html">Emotional Development</a> (Lagan: PFC/02/026)</p></li>
<li><p><a href="https://www.isre2024.org/preconference/list/laughter_workshop.html">Laughter and Other Non-Verbal Vocalisations Workshop</a> (Council Chamber)</p></li>
</ul>
<section id="evening-isre2024-welcome-reception-parliament-buildings" class="level4">
<h4 class="anchored" data-anchor-id="evening-isre2024-welcome-reception-parliament-buildings">Evening: ISRE2024 Welcome Reception, Parliament Buildings</h4>
<ul>
<li>18:15 Buses departure from University Road, facing the Lanyon Building Gates</li>
<li>19:00 - 22:00 Welcome Reception</li>
<li>21:00, 21:30, and 22:00 Buses to bring people back</li>
</ul>
<p><strong>Given the limited capacity and the regulations of Parliament Buildings, we can ensure entry only to 275 people who have previously expressed interest in attending the Welcome Reception (Qualtrics Questionnaire). If you did not complete the questionnaire and are not a keynote or a member of the ISRE board, your place is NOT GUARANTEED. Please reach out to ISRE24 organizers with any questions.</strong></p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="main-conference-overview" class="level1">
<h1>Main Conference Overview</h1>
<div style="page-break-after: always;"></div>
<section id="july" class="level3">
<h3 class="anchored" data-anchor-id="july">18 July</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td style="text-align: left; width: 1in;">from 08:00</td>
<td style="text-align: left; width: 3in;">Registration</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">9:15 - 9:30</td>
<td style="text-align: left; width: 3in;">Welcome and Opening</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">9:30 - 10:30</td>
<td style="text-align: left; width: 3in;">Keynote 1: Yuri Miyamoto</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">10:30 - 10:45</td>
<td style="text-align: left; width: 3in;">Coffee and Tea</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">10:45 - 12:00</td>
<td style="text-align: left; width: 3in;">Parallel Session 1</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">12:00 - 13:30</td>
<td style="text-align: left; width: 3in;">Lunch</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">12:15 - 13:15</td>
<td style="text-align: left; width: 3in;">Industry Salon: Michel Valstar</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">12:30 - 13:30</td>
<td style="text-align: left; width: 3in;">Poster Session 1</td>
<td style="text-align: left;">South Dining Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">13:30 - 14:45</td>
<td style="text-align: left; width: 3in;">Parallel Session 2</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">14:45 - 15:15</td>
<td style="text-align: left; width: 3in;">Coffee and Tea</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">15:15 - 16:30</td>
<td style="text-align: left; width: 3in;">Parallel Session 3</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">16.45 - 17.45</td>
<td style="text-align: left; width: 3in;">Flash Talks 1</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">19:00</td>
<td style="text-align: left; width: 3in;">ISRE2024 Early Career Event</td>
<td style="text-align: left;">QUB Great Hall</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
</section>
<section id="july-1" class="level3">
<h3 class="anchored" data-anchor-id="july-1">19 July</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td style="text-align: left; width: 1in;">from 08:00</td>
<td style="text-align: left; width: 3in;">Registration</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">9:15 - 10:30</td>
<td style="text-align: left; width: 3in;">Parallel Session 4</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">10:30 - 11:00</td>
<td style="text-align: left; width: 3in;">Coffee and Tea</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">11:00 - 12:00</td>
<td style="text-align: left; width: 3in;">Keynote 2: Phoebe Ellsworth</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">12:00 - 13:00</td>
<td style="text-align: left; width: 3in;">ISRE All Members Meeting</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">13:00 - 14:30</td>
<td style="text-align: left; width: 3in;">Lunch</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">13:15 - 14:15</td>
<td style="text-align: left; width: 3in;">Meet the Editors</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">13:30 - 14:30</td>
<td style="text-align: left; width: 3in;">Poster Session 2</td>
<td style="text-align: left;">South Dining Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">14:45 - 16:00</td>
<td style="text-align: left; width: 3in;">Parallel Session 5</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">16:00 - 16:30</td>
<td style="text-align: left; width: 3in;">Coffee and Tea</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">16.30 - 17.30</td>
<td style="text-align: left; width: 3in;">Flash Talks 2</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">Evening</td>
<td style="text-align: left; width: 3in;">ISRE2024 Conference Dinner</td>
<td style="text-align: left;">Belfast Titanic Museum</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
</section>
<section id="july-2" class="level3">
<h3 class="anchored" data-anchor-id="july-2">20 July</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td style="text-align: left; width: 1in;">from 08:30</td>
<td style="text-align: left; width: 3in;">Registration</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">9:15 - 10:30</td>
<td style="text-align: left; width: 3in;">Parallel Session 6</td>
<td style="text-align: left;">PFC / Whitla Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">10:30 - 11:00</td>
<td style="text-align: left; width: 3in;">Coffee and Tea</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">11:00 - 12:00</td>
<td style="text-align: left; width: 3in;">Keynote 3: Terry Maroney</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 1in;">12:00 - 12.30</td>
<td style="text-align: left; width: 3in;">Closing Session and Awards</td>
<td style="text-align: left;">Whitla Hall</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 1in;">from 12:30</td>
<td style="text-align: left; width: 3in;">Lunch</td>
<td style="text-align: left;">the Great Hall</td>
</tr>
</tbody>
</table>


</div>
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="main-conference-detailed" class="level1">
<h1>Main Conference Detailed</h1>
<div style="page-break-after: always;"></div>
<section id="july-3" class="level2">
<h2 class="anchored" data-anchor-id="july-3">18 July</h2>
<section id="from-0800-registration-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="from-0800-registration-whitla-hall">from 08:00 Registration (Whitla Hall)</h4>
</section>
<section id="welcome-and-opening-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="welcome-and-opening-whitla-hall">9:15 - 9:30 Welcome and Opening (Whitla Hall)</h4>
</section>
<section id="keynote-1-yuri-miyamoto-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="keynote-1-yuri-miyamoto-whitla-hall">9:30 - 10:30 Keynote 1: Yuri Miyamoto (Whitla Hall)</h4>
</section>
<section id="section" class="level4">
<h4 class="anchored" data-anchor-id="section"></h4>
<p><strong>Culture, Emotion, and Health: Dealing with Emotions in Sociocultural Contexts</strong></p>
<p>People generally want to increase positive emotions and decrease negative emotions. However, the extent to which individuals engage in such emotion regulation varies across cultures, partly due to differing beliefs about emotions. In this talk, I will present research highlighting cultural differences in dialectical versus predominantly adverse valuations of emotions. These variations in emotion valuations lead to cultural differences in emotion regulation and have health implications. I will also discuss sociocultural practices that support emotion beliefs and emotion regulation. By illuminating these processes, I will underscore the active role sociocultural contexts play in shaping emotions and their health implications.</p>
</section>
<section id="coffee-and-tea-the-great-hall" class="level4">
<h4 class="anchored" data-anchor-id="coffee-and-tea-the-great-hall">10:30 - 10:45 Coffee and Tea (the Great Hall)</h4>
</section>
<section id="parallel-session-1-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="parallel-session-1-pfc-whitla-hall">10:45 - 12:00 Parallel Session 1 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-483e39f6{}.cl-483a49fe{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-483a4a08{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-483c39bc{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-483c433a{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c433b{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c4344{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c4345{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c4346{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c4347{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c4348{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c434e{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c434f{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-483c4350{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-483e39f6"><thead><tr style="overflow-wrap:break-word;"><th class="cl-483c433a"><p class="cl-483c39bc"><span class="cl-483a49fe">Presenter</span></p></th><th class="cl-483c433b"><p class="cl-483c39bc"><span class="cl-483a49fe">Title</span></p></th><th class="cl-483c4344"><p class="cl-483c39bc"><span class="cl-483a49fe">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-483c4345"><p class="cl-483c39bc"><span class="cl-483a4a08">T1: Symposium - Beyond Poses: Perception of Genuine Emotional Expressions (Room Whitla Hall)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Yong-Qi Cong</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Differences in Emotion Perception from Posed and Spontaneous Facial Expressions</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">10:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Xia Fang</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">The Ingroup Advantage in Cross-Cultural Facial Expression Recognition: Influences of Spontaneity and Presentation Mode</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Anouschka van Dijk</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Emotion Recognition of and Facial Mimicry to Genuine Expressions - In Autism Spectrum Disorder and Social Anxiety Disorder</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-483c4345"><p class="cl-483c39bc"><span class="cl-483a4a08">T2: Symposium - Exploring the “dark” side of media:</span><br><span class="cl-483a4a08"> fascination with negative content in the digital age (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Anastassia Vivanco Carlevari</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Why Do People Engage with the Suffering of Strangers? Exploring Epistemic, Eudaimonic, Social and Affective Motives</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">10:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Ellen O’Donoghue</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Why Do We Read News? Identifying the Factors that Promote General and Specific News Consumption</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Lilian Suter</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Explaining Different Shades of Schadenfreude: Why People Feel Pleasure when the Media Show the Misfortunes of Others</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Corinna Perchtold-Stefan</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">“Murder is My Favorite Medium” Motives Behind and Outcomes of People’s Fascination with True Crime</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-483c4345"><p class="cl-483c39bc"><span class="cl-483a4a08">T3: Symposium - Emotions in Artificial Social Agents: Heavenly Bliss or Hellish Nightmare? (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Eva Hudlicka</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Setting the Stage: How to Frame Questions About Emotions in Artificial Social Agents (ASAs)</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">10:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Andrea Scarantino</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Emotions in Robots? Good for Us to Ascribe Them, Good for Them to Have Them</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Jonathan Gratch</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Social Functions of Machine Emotional Expressions</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Lydia Farina</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">How Could Robots Shape or Exploit Human Emotions?</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-483c4345"><p class="cl-483c39bc"><span class="cl-483a4a08">T4: Symposium - Innovations in measuring, understanding and improving emotion (regulation) dynamics across time (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Leonie Cloos</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Validating the Level and Timing of Affect Dynamics Through Continuous Affect Drawings</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">10:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Charlotte Vrijen</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Parental Optimism and Dyadic Affective Flexibility During Interactions Between Parents and their 2.5-Year-Old Children</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:05</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Eeske van Roekel</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">incReasIng poSitive Emotions (RISE Project): A Pilot Study on a Just-in-Time Adaptive Intervention in Daily Life</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:25</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Eeske van Roekel</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Discussion</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-483c4345"><p class="cl-483c39bc"><span class="cl-483a4a08">T5: Individual Talks - Cultural context (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Shannon M Brady</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Emotion Regulation Strategies in Diverse Contexts: Insights from Mexican and Yucatec Maya Children</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">10:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Yulia Chentsova-Dutton</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Emotion Regulation Strategies and Psychological Health Across Cultures</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Fantasy T Lozada</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">The Role of Afrocultural Ethos in African American Youth's Emotion Skill Development</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Katherine V Aumer</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Methodological and Cultural Considerations when Studying Emotions: A Perspective from Hawaiʻi</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Erika Roach</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Associations Between Parent Stress and Emotion Regulation and Child Socioemotional Adjustment in Chinese and Mexican American Immigrant Families</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-483c4345"><p class="cl-483c39bc"><span class="cl-483a4a08">T6: Individual Talks - Law and Order (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Janne van Doorn</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">The 'Emotional Defendant Effect': A Systematic Review of Experimental Studies</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">10:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Stina Bergman Blix</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">Rational Anger - Hostile Emotions in the Legal Procedure</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c4348"><p class="cl-483c39bc"><span class="cl-483a49fe">Nina Törnqvist</span></p></td><td class="cl-483c4346"><p class="cl-483c39bc"><span class="cl-483a49fe">In Judges We Trust – the Collective Dynamic of Epistemic Independence</span></p></td><td class="cl-483c4347"><p class="cl-483c39bc"><span class="cl-483a49fe">11:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-483c434e"><p class="cl-483c39bc"><span class="cl-483a49fe">Connor Powelson</span></p></td><td class="cl-483c434f"><p class="cl-483c39bc"><span class="cl-483a49fe">Social Stress, Support, and the Reproduction of Biased U.S. Policing</span></p></td><td class="cl-483c4350"><p class="cl-483c39bc"><span class="cl-483a49fe">11:30</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="lunch-the-great-hall" class="level4">
<h4 class="anchored" data-anchor-id="lunch-the-great-hall">12:00 - 13:30 Lunch (the Great Hall)</h4>
</section>
<section id="industry-salon-michel-valstar-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="industry-salon-michel-valstar-whitla-hall">12:15 - 13:15 Industry Salon: Michel Valstar (Whitla Hall)</h4>
</section>
<section id="section-1" class="level4">
<h4 class="anchored" data-anchor-id="section-1"></h4>
<p>The Emotion AI industry is at a very interesting junction. A small number of established start-ups exist and are looking to scale (Affectiva, BLUESKEYE AI, Hume), and the market is set to far exceed $50bn. At the same time, regulators and scientists are raising issues around privacy, evidence of effectiveness, and fairness, culminating in a partial ban of Emotion AI systems in the EU AI Act. In this salon, I will address the challenges and opportunities of creating a start-up in the area of Affective Computing.</p>
</section>
<section id="poster-session-1-south-dining-hall" class="level4">
<h4 class="anchored" data-anchor-id="poster-session-1-south-dining-hall">12:30 - 13:30 Poster Session 1 (South Dining Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-484cb846{}.cl-4848d78a{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4848d794{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-484a24a0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-484a24a1{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-484a2d9c{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-484a2d9d{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-484a2d9e{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-484a2da6{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-484a2da7{width:4in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-484a2da8{width:0.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-484cb846"><thead><tr style="overflow-wrap:break-word;"><th class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d78a">Presenter</span></p></th><th class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d78a">Title</span></p></th><th class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d78a">Nb</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Kaylee R Seddio</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Heightened Physiological Arousal and Emotional Transference: Prosocial Implications of Narrative Transportation among College Students</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Chelsea Rae Kelly</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Emotion Signals by Contemporary Relationship Labels: Modeling Relational Change with Affective Expectation</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Deborah Talmi</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Testing the Ecological Validity of Mechanistic Emotional Memory Models</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Manon Mulckhuyse</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Threat-Induced Prosocial Behavior: Enhanced Exogenous Attention to Protect Others from Harm</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Christian Becker-Asano</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Reporting on an Interactive, Public Installation of Android Andrea - Peoples' Reactions and Opinions</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Desmond C Ong</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Leveraging Large Language Models to Generate Targeted Reappraisals</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Asli Erdemli</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Uncovering the Neural Representation of Epistemic Emotions</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Lorna S Jakobson</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Sensory Processing Sensitivity Mediates the Relationship Between Externally Oriented Thinking and Fantasizing</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">8</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Rian Delaney</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Defining Resilience Following a Potentially Traumatic Event in Psychological Research: A Delphi Study</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">9</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Tatiana Pryakhina</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Types of Envy among Russian Speakers on Social Networks</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Natalia Espinosa</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Avoiding the Negativity: An Investigation on Avoided Affect in Mexicans</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">12</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Annika K Karinen</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Emotions and Behavioral Intentions in Response to Norm Violations</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">13</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Martin MK Kolnes</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Not Feeling It: No Emotion Effects on Breadth of Attention</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">14</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Nevin Solak</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">“Don’t Ruin the Balance of Nature”: Positive Awe and Threat-Based Awe About Nature and Support for Pro-Environmental Policies During the Pandemic</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Megan E Gornik</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Maternal and Preschooler Vocal Expression of Emotions</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">16</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Riya Mishra</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Understanding Microexpressions: The Science of Detecting Hidden Emotions</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">17</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Rachele Lievore</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Subjective and Physiological Responses to Social Stress in Pre-Teens with Autism and Specific Learning Disorders</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">18</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Rathi Adarshi Rammohan</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Scraping Auditory Hate Speech from Social Media: A Comparison of Keyword-Based and Channel-Based Approaches</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">19</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Nicole E. Henniger</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Specific Social Emotions Predict Tennessee Healthcare Providers’ Responses to Patients with Opioid Use Disorder</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">20</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Julia Folz</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">The Role of the Body in Altered Facial Emotion Perception in Autism and Social Anxiety</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">21</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Richard Lopez</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Novel Emotion Regulation Training to Reduce Contingent Self-Worth and Improve Mental Health in Daily Life</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">22</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Maria Anna Wasylkowska</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Let's Talk About Mindfulness: Assessing Mindfulness in Adolescents: A Polish Validation of the Child and Adolescent Mindfulness Measurement (CAMM)</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">23</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Alexander J Skolnick</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Disgust and Pain: If you can Tolerate the Pain, Do you also Tolerate the Gross?</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">24</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Megan Stutesman</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Children Dancing for Social-Emotional Skills: A Mixed Methods Study</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">25</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Martina Gnerre</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Vocal Emotional Expression in Parkinson’s Disease: Roles of Sex and Emotions</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">26</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Arina Pismenny</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Emotional Injustice: Emotion Policing</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">27</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Roisin Fallon</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Employing a Speech Act Framework to Examine the Negotiation of Deontic Authority During Episodes of Conflict in Acute Adult Mental Health Wards</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">28</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Mattia A. Fritz</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Towards a Collective, Theory-Agnostic, and Loosely Structured Database of Componential Emotions</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">29</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Kornelia Gentsch</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Investigating the Temporal Unfolding of Facial Muscle Responses of Emotion and Regulation</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Mylène Michaud</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Understanding Children’s Accuracy in Recognizing Facial Expressions of Pain</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">31</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Domicele Jonauskaite</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">“i Don’t Like this Positive Colour” but Why?</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">32</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Gerard Doran</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Assessing How Social Signals Differ Between Naturalistic and less Naturalistic Contexts</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">33</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Hritik Gupta</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">When I Think About Your Reaction to Pain: Theory of Mind Informed by Embodiment or Perceived Closeness?</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">34</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Bernd Dudzik</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">openVIMO: An Open Platform for Video-Based Interactions and Monitoring in Online Studies</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">35</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Aleksandra Jasielska</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Recognizing Facial Expressions of Emotions Made by Seniors While Controlling their Mental State</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">36</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Karolyn Cloutier</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">The Role of Encoder and Decoder Personality Traits in Smile Judgment</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">37</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Martina Nonni</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Emotion Components and Brain Networks: a Video Game Paradigm Testing Expectation and Uncertainty</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Andreia P. Costa</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">School Performance of Autistic Children: The Role of Socio-Emotional Skills</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">39</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Oksana Quinlan</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Differential Habituation to Positive and Negative Stimuli: Implications for Disgust Research and Practice</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">40</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Hyeonbo Yang</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Emotion Labels Modulate Prediction Error Response in Pre-Attentive Pre-Attentive Facial Emotion Processing: Evidence for the Role of Verbal Labels in Predictive Coding of Emotion Perception</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">41</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Marci Cottingham</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">"This Pandemic Challenged Our Oath to the Public”: Feeling Rules and Rule-Breaking in the Context of Nursing During Covid-19</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">42</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Malgorzata A Goclowska</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">How is State Awe Different from Interest and Curiosity?</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">43</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Rae-Anne Cohen</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Racialised Emotions and Research Methodology</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">44</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Jennifer C Lay</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Alone with My Thoughts: Using Natural Language Processing to Distinguish Lonely from Calm Aloneness</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Magdalena Rychlowska</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">The Social Influence of Emotions in Nested Social Dilemmas</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Thibaut Batal</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Interaction of Awe and Embodied Metaphor to Foster Creativity in Virtual Environment</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">47</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Bertille de Vlieger</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Antipathy as an Emotion</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">48</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Bronwyn D Laforet</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">An Abstract Mindset Favors more Positive Outgroup Emotion</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">49</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Radwa Khalil</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Signal or Consequence! How Does Insight Affect Emotion?</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">50</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Gary McKeown</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Social Signals in Therapeutic Listening: The Effect of Nods and Smiling on Empathy and Rapport</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">51</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Ruya Akdag</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Digital Interventions for Social Anxiety: Improving Negative Beliefs and Heart Rate Variability During Public Speaking</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">52</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Kutlu Kağan Türkarslan</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Can Guilt Feelings Enhance Nocebo Pain?</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">53</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Daniel Jonas Sutphin</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">The Two-Way Street of Interviews: Dyadic Interaction of Interviewer Mood and Applicant Impression Management Tactics</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Siyi Gu</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">How Do (Social Media) Influencers’ Emotion Expressions Affect their Popularity?</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">55</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Kostas Karpouzis</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Virtual Virtues and Shadows of Success: Digital Achievements Through the Lens of Plato and Aristotle</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">56</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Tomoko Koda</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Emotional Assessement of Assertive Feedback from a Job Interview Training Agent</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">57</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Tal Moran</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Are Members of Political Outgroups More Morally or Physically Disgusting?</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">58</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Alisa Balabanova</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Facial Expressivity and First Impressions During Online Social Interactions</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">60</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Andrew Buckee</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Oxytocin and Facial Expressivity</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">61</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Anna Maria Meneghini</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Exploring Emotion Regulation Strategies Across Four Emotions: Anger, Disgust, Fear and Sadness</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">62</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2da6"><p class="cl-484a24a0"><span class="cl-4848d794">Epicoco Déborah</span></p></td><td class="cl-484a2da7"><p class="cl-484a24a0"><span class="cl-4848d794">Why Do you Like some Colors and Dislike Others? Exploring Reasons Behind Color Preferences</span></p></td><td class="cl-484a2da8"><p class="cl-484a24a1"><span class="cl-4848d794">63</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-484a2d9c"><p class="cl-484a24a0"><span class="cl-4848d794">Ilaria Grazzani</span></p></td><td class="cl-484a2d9d"><p class="cl-484a24a0"><span class="cl-4848d794">Promoting Social and Emotional Learning (SEL) in Preschool Age: A Training Study</span></p></td><td class="cl-484a2d9e"><p class="cl-484a24a1"><span class="cl-4848d794">64</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="parallel-session-2-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="parallel-session-2-pfc-whitla-hall">13:30 - 14:45 Parallel Session 2 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4858a520{}.cl-4855765c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4855765d{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4856b792{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4856c052{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c053{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c05c{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c05d{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c05e{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c05f{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c066{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c067{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c068{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4856c070{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4858a520"><thead><tr style="overflow-wrap:break-word;"><th class="cl-4856c052"><p class="cl-4856b792"><span class="cl-4855765c">Presenter</span></p></th><th class="cl-4856c053"><p class="cl-4856b792"><span class="cl-4855765c">Title</span></p></th><th class="cl-4856c05c"><p class="cl-4856b792"><span class="cl-4855765c">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T1: Symposium - Situational, Social, and Cultural Moderators of Emotion Regulation Success (Room Whitla Hall)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Tom Hollenstein</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Hedonic and Perceived Success of Adolescent Emotion Regulation as a Function of Emotion Intensity and Polyregulation Repertoires</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Megan Wylie</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">What is the Relationship Between Emotion Intensity, Motivation, and Expressive Suppression Success?</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Tabea Springstein</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">A Matter of Fit? Investigating the Effects of Strategy-Situation Fit on Perceived Emotion Regulation Success</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Peter Koval</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Do People Regulate Their Emotions Flexibly in Daily Life and Does It Matter? Evidence from Four Intensive Longitudinal Studies</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Disa Sauter</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Emotion Regulation and Wellbeing: A Cross-Cultural Study Across 51 Countries</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T2: Symposium - Advancing Emotional Intelligence Research: From Human Hypersensitivity to Artificial Intelligence (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Marina Fiori</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Emotional Intelligence and Threshold of Perception of Emotional Expressions: Further Evidence of Emotional Hypersensitivity</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Christelle Gillioz</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Is Emotional Intelligence Associated with more Reaction to Emotions? a Study on Mimicry and Emotional Contagion.</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Nils R. Sommer</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Decoding Social Dynamics: The Impact of Emotion Recognition Ability on Nonverbal Behavior in Positive and Negative Interactions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Juliane Völker</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Putting the HEART to Use: A New Assessment of Emotional Competencies for Hospitality.</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Katja Schlegel</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Exploring ChatGPT’s Performance in Solving and Creating Emotional Intelligence Tests</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T3: Symposium - Virtual-based training programs in clinical domains (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Katja Kölkebeck</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Avatars in the Study of Emotion Processing in Patients with Mental Illnesses</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Evania Fasya</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Social Anxiety and the Perception of Virtual Human’s Emotional Expressions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Diego Arize</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">An Interactive Mobile Emotion Training Tool</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Dirk Heylen</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Virtual Reality Applications for Vulnerable People</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Katja Kölkebeck</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Discussion</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T4: Individual Talks - Expression and Perception (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Halszka K Bąk</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">In Two Minds but One Heart: Conceptualization of Basic Emotions in Bilingual Minds.</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Konstantinos Kafetsios</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">A Contextualized Emotion Perception Assessment Relates to Well-Being: Social Interaction as a Mediator</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Manuel F Gonzalez</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">How Ethnicity and Terminology Shape Attitudes Toward People Expressing Emotions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Akihiro Tanaka</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">JADMEED: Multimodal Emotional Expression Database for Cross-Cultural Research and Affective Computing</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T5: Individual Talks - Child and Parent (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Rachel Pétrin</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">The Role of Childhood Maltreatment on Maternal Cardiovascular Reactivity to Child Facial Expressions of Emotions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Marguerite Martel</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">The Role of Emotion Recognition and Alexithymia on the Relationship Between a History of Maltreatment and Parental Sensitivity.</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Christopher Riddell</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Emotions in Sync?: Children and Adults’ Cooperation and Interpersonal Liking During Face-to-Face Interactions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Gesine Jordan</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Profiles of Parental Intra- And Interpersonal Emotion Regulation in Academic Contexts</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Ashvini Varatharaj</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Investigating Child-Parent Emotional Discourse and Emotion Recognition Through Interactive Experiments</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T6: Individual Talks - Positive Emotions and Regulation (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Maria Krajuškina</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">A Two-Study Examination of the Efficacy and Mechanisms of Reappraisal to Increase Positive Emotions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Jolene Van der Kaap-Deeder</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Emotion Crafting: Individuals as Agents of their Positive Emotional Experiences</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Laura Sels</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Bi-Directional Associations Between Social Sharing and Emotion Differentiation in Everyday Life</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Chao Wang</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Suppressed Pleasure: Reinstating Pleasantness as a Causal Antecedent of Interest</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Ilka Mueller</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">The Paradox of Dampening Positive Emotions: Depressive Symptoms Explain Strategy Choice in Positive Emotional Contexts</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4856c05d"><p class="cl-4856b792"><span class="cl-4855765d">T7: Individual Talks - Physiology (Room Moyola: PFC/02/017)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Jens Johannes Gebele</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Beyond Deep Learning: Integrating Neuro-Symbolic AI for Enhanced Analysis of Facial Behavior of Emotions</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Dennis Küster</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Return of a Gold Standard: Electromyography-Based Facial Action Unit Recognition</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">13:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Marina Palazova</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">Electrophysiological Correlates of Intensity and Dynamic Information in Emotional Facial Expression Recognition</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c066"><p class="cl-4856b792"><span class="cl-4855765c">Till Kastendieck</span></p></td><td class="cl-4856c05e"><p class="cl-4856b792"><span class="cl-4855765c">A Walk in the Park: Measuring Emotional Mimicry with Electromyography in Virtual Reality</span></p></td><td class="cl-4856c05f"><p class="cl-4856b792"><span class="cl-4855765c">14:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4856c067"><p class="cl-4856b792"><span class="cl-4855765c">Helen Uusberg</span></p></td><td class="cl-4856c068"><p class="cl-4856b792"><span class="cl-4855765c">Does Distraction Foster Subsequent Reappraisal? an EMG and EEG Investigation into Strategy Sequencing</span></p></td><td class="cl-4856c070"><p class="cl-4856b792"><span class="cl-4855765c">14:30</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="coffee-and-tea-the-great-hall-1" class="level4">
<h4 class="anchored" data-anchor-id="coffee-and-tea-the-great-hall-1">14:45 - 15:15 Coffee and Tea (the Great Hall)</h4>
</section>
<section id="parallel-session-3-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="parallel-session-3-pfc-whitla-hall">15:15 - 16:30 Parallel Session 3 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4864c40e{}.cl-4861176e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48611778{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48625660{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48625fb6{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fc0{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fc1{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fc2{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fca{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fcb{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fcc{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fcd{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fd4{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48625fd5{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4864c40e"><thead><tr style="overflow-wrap:break-word;"><th class="cl-48625fb6"><p class="cl-48625660"><span class="cl-4861176e">Presenter</span></p></th><th class="cl-48625fc0"><p class="cl-48625660"><span class="cl-4861176e">Title</span></p></th><th class="cl-48625fc1"><p class="cl-48625660"><span class="cl-4861176e">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T1: Symposium - Emotion regulation in the interpersonal context: Reciprocal interactions between emotional and relational dynamic (Room Whitla Hall)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Haran Sened</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Shaping Others’ Emotions in Conversation: An Analysis of Temporal Dynamics</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Belen Lopez-Perez</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Distraction over Reappraisal Strategies in Interpersonal Emotion Regulation: Associations with Socio-Emotional Difficulties</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Luise Pruessner</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Dealing with Other People’s Feelings: Effectiveness of Extrinsic Interpersonal Emotion Regulation Strategies in Everyday Life</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Reuma Gadassi Polack</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Interpersonal Emotion Regulation is Associated with Parents’ and Adolescents’ Perceived Partner Responsiveness</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Reout Arbel</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">What Benefits Do Mothers Gain from Maternal Attunement? a Five-Wave Dyadic Study Across Preadolescence</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T2: Symposium - A Touch of Emotion (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Annett Schirmer</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">EEG Insights into the Neural Construction of Tactile Affect</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Francis McGlone</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Vitamin T</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Leehe Peled-Avron</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">The Effects of Psilocybin (‘magic Mushrooms’) on Social Touch Perception in Individuals with Resistant Major Depressive Disorder</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">India Morisson</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">The Neuroscience of Human Social Touch</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T3: Symposium - The Emerging Science of Awe and its Cognitive and Social Outcomes (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Chenxiao Zhao</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">The Effect of Positive-Awe and Threatening-Awe on Attentional Scope</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Brian Ostafin</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Many Paths to Presence: Mechanisms of the Relation Between Awe and Animism</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Özge Ugurlu</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Awe and Temporal Distancing</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Maria Monroy</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">The Influence of Awe on Social Integration</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Dacher Keltner</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Discussion</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T4: Individual Talks - Virtual Reality and Games (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Salvador Alvidrez</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Fostering Positive Emotions in VR Interactions Between Rival Groups: Prosociality over Common Ingroup Identity</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Christina Tornberg</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Avatar Emotions: Evaluation of Dynamic Facial Expressions Transferred from Human Actors to Embodied Agents</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Fabien Boucaud</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Social Acceptability of Being Touched by a Virtual Agent</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Tomás Ariel D'Amelio</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">From Virtual to Reality: Mapping Dynamic Emotions and Physiology in VR Environments</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T5: Individual Talks - Social Context (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Yochi Cohen-Charash</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">“I Can Do It(?)”: Examining How Self-Efficacy Shapes Reactions to Envy</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Roujia Feng</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Differences Between Happy-for and Schadenfreude: Insights from Structural Topic Modeling.</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Lukas Loreth</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">The Impact of Social Identity Threat on Loneliness among Unemployed People in Germany</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Bronagh Allison</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Socio-Communicative Interpretation of Facial Expressions Requires Social Context</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T6: Individual Talks - Language (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Mari Aguilera</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Interplay Between Emotion and Language: Evidence from Children with and without Developmental Language Disorder</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Khalid El asri</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Putting Feelings into Words: Do Moroccan Learners of English Describe Others’ Emotions as Native Speakers?</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Salomé Klein</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Detecting Emotions in the Speech of Patients with Acquired Brain Injury: a Feasibility Study</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Frédéric Tomas</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Shared Narratives: A Corpus-Based Study of Gendered Language in Depression Podcasts</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48625fc2"><p class="cl-48625660"><span class="cl-48611778">T7: Individual Talks - Theory and Function (Room Moyola: PFC/02/017)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Eithne Kavanagh</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Being Facially Expressive is Socially Advantageous</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Tamás Szűcs</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">A Systematic Examination of the Causal Determinants of Affect</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Yoann Stussi</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">Affective and Computational Mechanisms Underlying Pavlovian Learning Biases</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcc"><p class="cl-48625660"><span class="cl-4861176e">Sera Muto</span></p></td><td class="cl-48625fca"><p class="cl-48625660"><span class="cl-4861176e">A Heuristic Approach to Categorize Emotion Theories in Psychology</span></p></td><td class="cl-48625fcb"><p class="cl-48625660"><span class="cl-4861176e">16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48625fcd"><p class="cl-48625660"><span class="cl-4861176e">Christine Howes</span></p></td><td class="cl-48625fd4"><p class="cl-48625660"><span class="cl-4861176e">No Laughing Matter: Creating and Interpreting Emotions Through Interaction</span></p></td><td class="cl-48625fd5"><p class="cl-48625660"><span class="cl-4861176e">16:15</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="flash-talks-1-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="flash-talks-1-pfc-whitla-hall">16.45 - 17.45 Flash Talks 1 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48701d5e{}.cl-486cf52a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-486cf534{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-486e2530{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-486e2e2c{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e2d{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e36{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e37{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e38{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e39{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e40{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e41{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e42{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-486e2e4a{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48701d5e"><thead><tr style="overflow-wrap:break-word;"><th class="cl-486e2e2c"><p class="cl-486e2530"><span class="cl-486cf52a">Presenter</span></p></th><th class="cl-486e2e2d"><p class="cl-486e2530"><span class="cl-486cf52a">Title</span></p></th><th class="cl-486e2e36"><p class="cl-486e2530"><span class="cl-486cf52a">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-486e2e37"><p class="cl-486e2530"><span class="cl-486cf534">T1: Flash Talks - Development (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Marissa Ogren</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">The Early Emotional Environment: What Facial Configurations Do Infants Typically See in Natural Social Interactions?</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Neslihan Önay; Rimmele, Ulrike</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Negative Emotion Has a Disruptive Role in the Formation of Relational Memory in Different Age Groups</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:53</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Isabelle Bernard</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Exploring Content of Children’s Discussions Related to a Shared Book Reading Intervention for Emotion Comprehension</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:01</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Zeynep B Özden</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Children’s Perception of Appraisal Dimensions in Emotional Contexts</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:09</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Veronica Debora Toro</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Neurophysiological Correlates of Emotional Words Processing in Primary School Children Impacted by Covid 19 Emergency</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:17</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Kristina Šparemblek</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Pacifiers at Play: Understanding Facial Emotional Exchange in Mother-Infant Dyads</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:25</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-486e2e37"><p class="cl-486e2530"><span class="cl-486cf534">T2: Flash Talks - Music, Aesthetics, and Creativity (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Peter J Varga</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Mechanisms of Musical Emotion Transfer: Insights from Composers</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Ursula Beermann</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Measuring Aesthetic Emotions with the ShortAesthet</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:53</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Ilaria Telazzi</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">The Effect of Creativity on Cognitive Reappraisal Effectiveness in a Sample of Older Adults</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:01</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Yagmur Ozbay</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Beyond Beauty: Does Visual Art Facilitate Social Cognitive Skills?</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:09</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Xia Fang</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Communicating Emotions Through Drawing: Cross-Cultural Similarities and Differences</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:17</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-486e2e37"><p class="cl-486e2530"><span class="cl-486cf534">T3: Flash Talks - Specific Emotions (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Fabiola Diana</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Yawning Unveiled: The Elusive Interplay of Facial Mimicry and Contagious Yawning</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Cristina Soriano</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Frustration: A Language-Specific Concept?</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:53</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Shazza Ali</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">What Happens when We Witness Other’s Excellence? Exploring the (Dis)Similarities of Moral Elevation and Admiration in Children</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:01</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Phoebe McKenna-Plumley</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Exploring Loneliness as a Multidimensional Experience: Social, Emotional, and Existential Dimensions Across the Adult Lifespan</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:09</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Tom R Kupfer</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Is the Emotion Disgust Culturally Invariant?</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:17</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-486e2e37"><p class="cl-486e2530"><span class="cl-486cf534">T4: Flash Talks - Emotion, Perception and Expression (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Bridget M Waller</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Do the Six Archetypal Facial Expressions Exist in Spontaneous Social Interaction?</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Geraldine Klewes</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Navigating Truth: Unraveling the Impact of Emotional Expressions on News Credibility in the Era of Misinformation</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:53</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Stephan Verschoor</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Mimicking the Emotional Expressions of Others : Are all Expressive Features Made Equal?</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:01</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Haejin Kim</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Understanding the Process of Physiological Metonymy in Expressing Emotions</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:09</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Tobias Thejll-Madsen</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">A Systematic Evaluation Framework on Emotion Perception for Large Language Models Using Appraisal Theory</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:17</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-486e2e37"><p class="cl-486e2530"><span class="cl-486cf534">T5: Flash Talks - Emotions In Context (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Patrycja Chwilkowska</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Limited Impact of Synergistic Mindsets Intervention on Esports Performance: Preliminary Findings</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Mircea Zloteanu</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Emotional Witness Effect and Misinformation: Implications for Misidentification, Reliability, and Memory Accuracy in Forensic Contexts</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">16:53</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Fantasy T. Lozada</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Racial Differences in Emotion Socialization and Racial Socialization: The Need for an Integrated Lens</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:01</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Katie McGaughey</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">The Impact of Shame, Humiliation, and Criminal Justice Experiences on Revenge in Crime Victims</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:09</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e40"><p class="cl-486e2530"><span class="cl-486cf52a">Maciej Behnke</span></p></td><td class="cl-486e2e38"><p class="cl-486e2530"><span class="cl-486cf52a">Preliminary Evidence for Physiological Markers of Core Affective Experience: Results from a Team-Science Competition</span></p></td><td class="cl-486e2e39"><p class="cl-486e2530"><span class="cl-486cf52a">17:17</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-486e2e41"><p class="cl-486e2530"><span class="cl-486cf52a">Magdalena Bartlomiejczyk</span></p></td><td class="cl-486e2e42"><p class="cl-486e2530"><span class="cl-486cf52a">Activist Interpreting in Abortion Clinics: Emotional Challenges and Self-Care Strategies</span></p></td><td class="cl-486e2e4a"><p class="cl-486e2530"><span class="cl-486cf52a">17:17</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="evening" class="level4">
<h4 class="anchored" data-anchor-id="evening">Evening</h4>
<p><strong>19:00 ISRE2024 Early Career Event, QUB Great Hall</strong></p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="july-4" class="level2">
<h2 class="anchored" data-anchor-id="july-4">19 July</h2>
<section id="from-0800-registration-whitla-hall-1" class="level4">
<h4 class="anchored" data-anchor-id="from-0800-registration-whitla-hall-1">from 08:00 Registration (Whitla Hall)</h4>
</section>
<section id="parallel-session-4-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="parallel-session-4-pfc-whitla-hall">9:15 - 10:30 Parallel Session 4 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-487b8b26{}.cl-48780546{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48780550{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48793862{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48794122{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4879412c{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4879412d{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48794136{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48794137{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48794138{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48794140{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48794141{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48794142{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4879414a{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-487b8b26"><thead><tr style="overflow-wrap:break-word;"><th class="cl-48794122"><p class="cl-48793862"><span class="cl-48780546">Presenter</span></p></th><th class="cl-4879412c"><p class="cl-48793862"><span class="cl-48780546">Title</span></p></th><th class="cl-4879412d"><p class="cl-48793862"><span class="cl-48780546">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48794136"><p class="cl-48793862"><span class="cl-48780550">T1: Symposium - The Interplay of Intra- and Interpersonal Processes in Social Emotions (Room Whitla Hall)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Gerben van Kleef</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">How Music Teachers’ Emotional Expressions Shape Students’ Performance: “c’est Le Ton Qui Fait La Musique”</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Jan Crusius</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Chasing Dreams or Social Standards? How Internal and External Self-Relevance Shape Envy.</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Milica Nikolic</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Self-Conscious Emotional Arousal in Infancy and Early Childhood</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Gert-Jan Lelieveld</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">The Strategic Display of Supplication Versus Appeasement Emotions in Negotiations</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Yiftach Argaman</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">A Systematic Examination of Shame and Pride's Functions and Mechanisms Through Concealment and Exposure Behaviors</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48794136"><p class="cl-48793862"><span class="cl-48780550">T2: Symposium - Affective Experiences Across the Adult Lifespan: Age-Related Differences, Mechanisms, and Implications (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Antje Rauers</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Emotional Reactivity to 66 Film Clips from Adolescence to Old Age</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Maria Wirth</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Age Differences in Affect Dynamics: Testing Predictions of Socioemotional Selectivity Theory with the MIVA Model</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Shevaun D. Neupert</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Daily Subjective Aging and Affective Dynamics</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Michaela Riediger</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Affect-Health Coupling from Adolescence to Old Age: Evidence from a Longitudinal Experience- Sampling Study</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Dakota W. Cintron</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Trajectories of Affective Well-Being and Survival in Middle-Aged and Older Adults</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48794136"><p class="cl-48793862"><span class="cl-48780550">T3: Individual Talks - Conflict and Politics (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Ben Rudolph</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Contempt and Other Specific Emotions as Predictors of Support for Anti-Democratic Political Behavior</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Lara Ditrich</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Of Looming Threats: Affective and Behavioural Responses to Making Crises’ Consequences Salient</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Agneta Fischer</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Emotions at War: What can Emotion Science Offer?</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Michal Schwarz</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Emotions in Political Rituals and in Inner Asian Tributary Relations</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48794136"><p class="cl-48793862"><span class="cl-48780550">T4: Individual Talks - Text and AI (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Dominik Jakub Puchała</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Decrypting Auditory Hate Speech: The Development of the Warsaw Multimodal Hate Speech Data Base (WMHS)</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Xiuhui Li</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Using Artificial Intelligence to Understand People’s Interpersonal Emotion Regulation Strategies</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Xiaoyu Zhou</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Textual Emotion and the Veracity of News Headlines: The Roles of Valence, Arousal, and Words Position</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Andero Uusberg</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Appraisal Shifts in Reappraisal: Observations using Large Language Models</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Ben Bland</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Defining Emotions for Technology: Lessons Learned from Writing a Global Standard for Ethics in Empathic AI</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48794136"><p class="cl-48793862"><span class="cl-48780550">T5: Individual Talks - Dynamic perspectives (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Katey Workman</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">It Takes Two: Exploring the Temporal Interpersonal Emotion System of Parents and Adolescents During Conflict Discussions</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Youce Xiang</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Recalcitrant Emotions are Arational at the Moment and Prospectively Rational</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794140"><p class="cl-48793862"><span class="cl-48780546">Matthias Zerban</span></p></td><td class="cl-48794137"><p class="cl-48793862"><span class="cl-48780546">Investigating Resilient Emotion Regulation – the Role of Emotion Regulation Variability and Emotion Regulation Flexibility</span></p></td><td class="cl-48794138"><p class="cl-48793862"><span class="cl-48780546">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48794141"><p class="cl-48793862"><span class="cl-48780546">Christine Dworschak</span></p></td><td class="cl-48794142"><p class="cl-48793862"><span class="cl-48780546">Associations Between Attentional Disengagement from Distressed Infant Faces and CortisolReactivity are Moderated by Depressive Symptoms in Pregnant Women: An Eye-TrackingStudy</span></p></td><td class="cl-4879414a"><p class="cl-48793862"><span class="cl-48780546">10:00</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="coffee-and-tea-the-great-hall-2" class="level4">
<h4 class="anchored" data-anchor-id="coffee-and-tea-the-great-hall-2">10:30 - 11:00 Coffee and Tea (the Great Hall)</h4>
</section>
<section id="keynote-2-phoebe-ellsworth-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="keynote-2-phoebe-ellsworth-whitla-hall">11:00 - 12:00 Keynote 2: Phoebe Ellsworth (Whitla Hall)</h4>
</section>
<section id="section-2" class="level4">
<h4 class="anchored" data-anchor-id="section-2"></h4>
<p><strong>Convergence among Emotion Theories</strong></p>
<p>Although many scholars bemoan the lack of consensus among emotion theorists, current theories agree on several important ideas, such as the adaptiveness of emotions and their principal components, and there is increasing convergence on divisive issues, such as discrete categories vs.&nbsp;continuous dimensions and the role of biology vs.&nbsp;culture. In the future our goal should be to distinguish real from apparent differences and to identify differences that can be resolved empirically.</p>
</section>
<section id="isre-all-members-meeting-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="isre-all-members-meeting-whitla-hall">12:00 - 13:00 ISRE All Members Meeting (Whitla Hall)</h4>
</section>
<section id="lunch-the-great-hall-1" class="level4">
<h4 class="anchored" data-anchor-id="lunch-the-great-hall-1">13:00 - 14:30 Lunch (the Great Hall)</h4>
</section>
<section id="meet-the-editors-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="meet-the-editors-whitla-hall">13:15 - 14:15 Meet the Editors (Whitla Hall)</h4>
<p>With the presence of:</p>
<ul>
<li>Ursula Hess</li>
<li>Elise Kalokerinos</li>
<li>Katie Greenaway</li>
<li>Carolyn MacCann</li>
</ul>
</section>
<section id="poster-session-2-south-dining-hall" class="level4">
<h4 class="anchored" data-anchor-id="poster-session-2-south-dining-hall">13:30 - 14:30 Poster Session 2 (South Dining Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-488cd0fc{}.cl-4886adda{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4886ade4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-488801d0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-488801da{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48880b12{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48880b13{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48880b14{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48880b26{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48880b27{width:4in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48880b30{width:0.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-488cd0fc"><thead><tr style="overflow-wrap:break-word;"><th class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886adda">Presenter</span></p></th><th class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886adda">Title</span></p></th><th class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886adda">Nb</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Samuel E Day</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Asymmetry in Face-Context Integration</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">65</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Norm O'Rourke</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Demographic, Clinical and Psychosocial Predictors of Positive Aspects of Informal Epilepsy Care</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">66</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Carmen Nimtz</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Enhancing Context-Dependent Emotion Regulation in Adolescents: A Pilot for an Ecological Momentary Intervention</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">67</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Ariadni Tzafara</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">The Role of Empathy in Foreign Language Didactics: A Learning Scenario for Teaching German as a Foreign Language</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">68</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Vera Novković</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Assessing Prospect Theory’s Concepts: Loss and Gain Zones in Risky Choice Framing</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">69</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Khalid El asri</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Emotions in Contact: A Study of Arabic-English Contact</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">70</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Amel Achour-Benallegue</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Do We Pout at the Moai? the Influence of Cross-Cultural Facial Icons on Emotional Responses?</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">71</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Davide Pirrone</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Navigating Intimate Relationships: The Role of Emotion Dynamics in Dealing with Relational Needs Frustration</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">72</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Andrea Kanzler</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">How Emotions can Impact Consumer Behavior on Social Media</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">73</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Kristina Schaaff</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Cross-Cultural Comparison of ChatGPT’s Response Styles for Japanese and English</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">74</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Yoshikazu Fukui</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Categorical Versus Dimensional Models of Dissociation Part 1: Taxometric Analysis among Japanese Adolescents</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">75</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Frederike Stucke</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">The Emotional Reactions to Experienced (in)Tolerance as Potential Catalysts for Collective Action.</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">76</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Zuzana Ambrozkova</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Remorse in the Courtroom: A Content Analysis of Judgements About the Assessment of the Perpetrator's Remorse</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">77</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Insa M Borm</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Striking a Deal? a Meta-Analysis Investigating the Role of Specific Emotions in the Maintenance of Binge Eating</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">78</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Coral Mayo</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Are There Differences Between Implicit and Explicit Behavior in Real-Time Emotional Identification in School-Age Children?</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">79</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Dominic P Kelly</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Adolescent Emotional Behaviours and Self-Control: A 14-Year Longitudinal Study of Emotion Development in Family Context</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">80</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Christine A Flammia</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Curiosity as Integral to Feature Journalists’ Self-Concepts</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">81</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Pamela M Taylor</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">“Morbid Curiosity” is Associated with less Reactivity to Horrific Stimuli</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">82</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Daiana Colledani</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">The Use of Emotion Regulation Strategies Across Diverse Emotions: Exploring Age-Related Variations</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">83</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Amanda C. Benjamin</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">The Effects of Local Mobile Safety Alerts on Fear, Risk Perceptions, Behavior, and Punitiveness</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">84</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Ignacio Perezmontemayor Cruz</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Interpersonal Capitalization and Unmet Interpersonal Needs Among Adolescents at Varying Risk for Suicidal Ideation</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">85</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Dong Tang</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Neural Correlates of Emotion-Label vs. Emotion-Laden Word Processing in Late Bilinguals: Evidence from an ERP Study</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">86</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Teerawat Monnor</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Investigation of Interpersonal-Affective Motivation for Prosocial Behavior</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">87</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Alejandro Campero Oliart</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Psychophysiological Expressions of Neuroticism</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">88</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Ariel J Mosley</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Appraisals of Cultural Appropriation on Intergroup Anger and Affirmative Action Endorsement</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">89</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Qendresa Shaqiri</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Beyond Psychology : Understanding Emotions Through the Lenses of Anthropology</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">90</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Linli Zhou</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">The Positive Relationship Between Warm Glow and Pro-Environmental Behaviour</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">91</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Andreas Eder</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Fight or Flight? Pavlovian-to-Instrumental Transfer of Control over Fight-or-Flight Decisions</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">92</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Elizabeth M Jacobs</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Advancing Holistic Empathy Assessment in Virtual Reality</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">93</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Roxane Philips</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Do Anticipatory Affect and Time Pressure Interact in Decisions under Risk?</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">94</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Desmond Ong</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Empathy Unleashed: Exploring the Impact of Cultivating Unlimited Empathy Mindset on Engaging in Empathic Effortful Behaviors</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">95</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Lavinia Wuensch</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Differential Influence of Habitual Behavior Components on Compulsive and Problematic Reward-Seeking Behavior</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">96</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Axel Zinkernagel</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Measuring Facial Movements in Dyadic Interactions Using the blenderFace Method</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">97</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Adrianna Wielgopolan</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">I may be Ambiguous, but I Am Still in Control: The Influence of the Ambiguous Emotional Load in Words on the Performance in Emotional Stroop Task</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">98</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Sivenesi Subramoney</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">The Effects of Emotion Brokering Frequency and Gender on Maternal Relationship Quality</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">99</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Manasa Ganesh Kumar</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">The Eye of the Beholder: Perceiving Jealousy in Interpersonal Interactions</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">100</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Kenneth Tai</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">When is Envy Beneficial for Performance? Exploring the Curvilinear Relation Between Envy and Performance and the Moderating Role of Conscientiousness</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">101</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Richard Naar</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Feasibility of Using High-Frequency SSVEP in Probing Top-Down and Bottom-Up Contributions in Affective Attention</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">102</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Yiran Ge</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Relations Between Emotion Beliefs and Emotion Regulation in China and the UK</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">103</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Loreta Cannito</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Exploring the Interplay of Emotions and Metacognition in L2 Pronunciation: Evidence from Italian Primary School.</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">104</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Michaël P Romet</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Introducing and Validating a New Observational Paradigm for Assessing Triadic Family Interactions with Adolescents</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">105</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Amanda K Steele</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Reducing Hate: How Hatred may be Reduced by Changing People’s Appraisals</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">106</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Joshua T Royles</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Hume’s Square of Passions: Bumpy Emotions Stabilized by Habit</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">107</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Kiera L Adams</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Exploring Experiences of Anxiety, Alexithymia and Interoception in Autistic Adolescents: A Reflexive Thematic Analysis</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">108</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Fernanda Eliott</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Can Insights from the MAS' Coordination/Cooperation Dichotomy Enlighten Empathy Investigation?</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">109</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Martin Krippl</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Triumph - not pride - is the main emotion expressed after success in non-interactive sports</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">110</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Alexandra Main</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Parent Empathy and Adolescent Disclosure in the Context of Type 1 Diabetes Management</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">111</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Mari  Aguilera</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Emotion Regulation and Well-Being of Families with Children Who Have Learning Disorders</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">112</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Amanda McQuarrie</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Impact of Emotional Abuse on Empathy: The Mediating Roles of Alexithymia and Sensory Processing Sensitivity</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">113</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Nutankumar S Thingujam</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Religiosity and Emotion Regulation Strategies among the Hindus in India</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">114</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Patrick A. O'Connor</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Basic Symbolic Number Skills Longitudinally Predict Mathematics Anxiety in the First Years of Primary School</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">115</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Maram Saad</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Cognitive Reappraisal of Food Reduces Desire to Eat but at the Cost of Increasing Negative-Emotionality.</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">116</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Adele Gallant</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Eye-Movement Study of the Discrimination Between Facial Expressions of Fear and Surprise: Can Individuals be Trained?</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">117</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Peter Reschke</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Contextual Influence or Racial Bias? the Intersection of Emotion Perception and Emoter Race</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">118</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">W. Gerrod Parrott</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Two Types of Shame, and Why They Frequently Co-Occur</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">119</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Lukas Lopez</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Any-to-Any: How Moral Events Evoke Emotions by Way of Appraisals</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">120</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Julien Venni</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Aesthetics of Illustrations in Emotional Design: Effects on User Experience and Multimedia Learning.</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">122</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Francesco Pupillo</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">The Effect of Computationally-Derived Affective States on Memory</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">123</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Alan Voodla</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Metacognitive Confidence and Affect - Two Sides of the Same Coin?</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">124</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Catherine NM Ortner</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Emotion Regulation Choice under Cognitive Load</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">125</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Mariagrazia Monaci</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">Emotions Felt While Gambling: a Comparison Between Scratch Card, Slot Machines, and Casino Gamblers</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">126</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Lauren Edwards</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">The Power of Love</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">127</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b26"><p class="cl-488801d0"><span class="cl-4886ade4">Stephen D Smith</span></p></td><td class="cl-48880b27"><p class="cl-488801d0"><span class="cl-4886ade4">An Event-Related Potential Examination of the Neural Responses to Emotional and Movement-Related Images</span></p></td><td class="cl-48880b30"><p class="cl-488801da"><span class="cl-4886ade4">128</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48880b12"><p class="cl-488801d0"><span class="cl-4886ade4">Perry Johnson</span></p></td><td class="cl-48880b13"><p class="cl-488801d0"><span class="cl-4886ade4">Meaning, Modernity, and the Machine: Theories About Emotional Vectors and AI-Generated Images as Art</span></p></td><td class="cl-48880b14"><p class="cl-488801da"><span class="cl-4886ade4">129</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="parallel-session-5-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="parallel-session-5-pfc-whitla-hall">14:45 - 16:00 Parallel Session 5 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48989694{}.cl-48958558{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48958562{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4896be28{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4896c6ca{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6d4{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6d5{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6d6{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6de{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6df{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6e0{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6e8{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6e9{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4896c6ea{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48989694"><thead><tr style="overflow-wrap:break-word;"><th class="cl-4896c6ca"><p class="cl-4896be28"><span class="cl-48958558">Presenter</span></p></th><th class="cl-4896c6d4"><p class="cl-4896be28"><span class="cl-48958558">Title</span></p></th><th class="cl-4896c6d5"><p class="cl-4896be28"><span class="cl-48958558">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4896c6d6"><p class="cl-4896be28"><span class="cl-48958562">T1: Symposium - The Positive and Dark Side of Interpersonal Emotion Regulation (Room Whitla Hall)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Carolyn MacCann</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Avoidant Attachment Predicts Lower Use of High-Engagement Strategies to Regulate a Partner’s Emotions.</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Sarah A. Walker</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Situational Influences on Emotion Regulation Strategies Among Romantic Partners</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Shayne Polias</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Interpersonal Affect Worsening Scale (IAWS): Development and Validation of a New Questionnaire to Assess Regulation Strategies.</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Yuhui Chen</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Exploring the Temporal Dynamics of Motives and Strategies in Daily Interpersonal Affect Worsening</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4896c6d6"><p class="cl-4896be28"><span class="cl-48958562">T2: Symposium - Regulatory Mechanisms of Positive Emotions from Experimental Research to Real-World Dynamics (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Vanessa Mitschke</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Between Laughter and Restraint: Inhibition and Contagious Laughter During Humoristic Experiences</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Karolina Dyduch-Hazar</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Feeling Pleasure after Experiencing Pain: Self-Regulation in Benign Masochism</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Guillermo Recio</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Self-Regulation Strategies in Young Adults: Challenges and Benefits of Affective Feedback and Task Difficulty</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Anna Fischer</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Emotion Regulation Choices in Positive and Negative Situations: An Ecologically Valid Approach using Experience Sampling.</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Annika Ziereis</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Discussion</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4896c6d6"><p class="cl-4896be28"><span class="cl-48958562">T3: Symposium - Emotional Experiences and Skills in the Context of Social Exchange Processes and Interpersonal Relationships (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Jenny Jaquet</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Examining Adult-Age Differences in Interpersonal Motor Coordination Between Strangers</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Alissa von Großmann</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Follow Me and I Will Tell You More: Associations Between Interpersonal Motor Following and Self-Disclosure</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Beyza Sönmez</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Individual and Dyadic Correlates of Emotion Recognition Performance in Older Couples</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Cheryl L. Carmichael</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Love to Love You: Orgasm Communication and Sexual Pleasure Equity Through an Interdependence Lens</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Margund K. Rohr</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Let’s Talk, Honey! Age Differences in Emotional Experiences During Sad and Conflictual Couples’ Conversations</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4896c6d6"><p class="cl-4896be28"><span class="cl-48958562">T4: Individual Talks - Crises and Media (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Esther Niehoff</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">to Read or not to Read? Motives for Reading Negative COVID-19 News</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Susanne Stoll-Kleemann</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">The Impact of Emotions and Media Coverage on Behavior Change in the Climate Crisis</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Anna A Sach</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Emotions in Collective Climate Action: A Systematic Literature Review</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Robin Nabi</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Using Hope-Evoking Media to Increase Emotional Bandwidth and Decrease Stress: A Media Prescription Perspective</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4896c6d6"><p class="cl-4896be28"><span class="cl-48958562">T5: Individual Talks - Knowledge and Regulation (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Petri Laukka</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Emotion Recognition Accuracy and Appraisal Dimension Ratings of 44 Emotions from Dynamic Multimodal Expressions</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Or Segal</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Does Acceptance Lead to Change? Training in Radical Acceptance Improves Implementation of Cognitive Reappraisal</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Rika Oya</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Can Humans Perceive Emotions Just by Seeing Touching Hand?</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">James Floman</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Emotion Understanding, Emotion Regulation, and Mental Well-Being: Evidence from New Emotion Ability Tests</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Alexandra Main</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Predicting Emotion Regulation Strategies from Aspects of the Social Context in Everyday Life</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-4896c6d6"><p class="cl-4896be28"><span class="cl-48958562">T6: Individual Talks - Mechanisms of Emotion (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Christian Waugh</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Implicit Motivational Value of Experiences</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Mélody Mailliez</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">Appraisal of Certainty’s Effect on Information Processing: Attempted Replications of Tiedens and Linton (2011) Findings.</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e0"><p class="cl-4896be28"><span class="cl-48958558">Rashmi Gupta</span></p></td><td class="cl-4896c6de"><p class="cl-4896be28"><span class="cl-48958558">The Role of Contrast Emotions in Response Inhibition</span></p></td><td class="cl-4896c6df"><p class="cl-4896be28"><span class="cl-48958558">15:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4896c6e8"><p class="cl-4896be28"><span class="cl-48958558">Loïs Vanhée</span></p></td><td class="cl-4896c6e9"><p class="cl-4896be28"><span class="cl-48958558">Artificial Intelligence for Anxiety: Pathways for Transdisciplinary Research on Anxiety Sensitive Artificial Intelligence</span></p></td><td class="cl-4896c6ea"><p class="cl-4896be28"><span class="cl-48958558">15:30</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="coffee-and-tea-the-great-hall-3" class="level4">
<h4 class="anchored" data-anchor-id="coffee-and-tea-the-great-hall-3">16:00 - 16:30 Coffee and Tea (the Great Hall)</h4>
</section>
<section id="flash-talks-2-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="flash-talks-2-pfc-whitla-hall">16.30 - 17.30 Flash Talks 2 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48a4c428{}.cl-48a182d6{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48a182e0{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48a2cc4a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48a2d578{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d579{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d57a{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d582{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d583{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d584{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d58c{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d58d{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d596{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48a2d597{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48a4c428"><thead><tr style="overflow-wrap:break-word;"><th class="cl-48a2d578"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Presenter</span></p></th><th class="cl-48a2d579"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Title</span></p></th><th class="cl-48a2d57a"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T1: Flash Talks - Empathy and Perspective-taking (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Roujia Feng</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">The Impact of Empathic and Counter-Empathic Emotions on Social Evaluations</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Nadine Braun</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Effects of Emotion Recall Instructions and Valence on Self- And Other-Perceived Emotion Intensity and Empathy</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Katherine V Aumer</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Mixed Methods Comparison of Relationships with Love vs Those with Ambivalence</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Jie Gao</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Unveiling the Dynamics of “Seeing Afresh”: Enacted Perspective-Taking Through Role-Play Dialogues with Climate Emotions</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Callie S. Kalny</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Mapping Empathy's Oeuvre: Toward a Typology of Empathy in Media Selection, Processing, and Reception</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">17:02</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T2: Flash Talks - Emotion Understanding, Complexity and Theory (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Zhimeng Li</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Labeling Behaviors is Associated with Identification of Emotion Event</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Alexandra Ai Israelsson</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Accurate Perception of both Quality and Quantity of Blended Emotions Conveyed Through Dynamic Multimodal Expressions</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Aidan Feeney</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Anticipation of Positive and Negative Counterfactual Emotions Shape Behaviour</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Ongun Kılıç</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Practical Irrationality Mystified: A Reply to Agnes Moors</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Alessandra N. C. Yu</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">The Human Affectome</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T3: Flash Talks - Meta Emotions, Thoughts and Language (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Christopher M Dobmeier</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Feelings About Feelings: Accounting for Meta-Emotions in Persuasion</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Sibel Caliskan</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Looking into Meta-Emotions: The Manager-Employee Emotion Dialogue from Cross-Cultural Perspective</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Daniela Andrea Ortega Manchego</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Neural Correlates of Written Emotion Word Processing in Bilinguals: An fNIRS Study</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T4: Flash Talks - Psychopathology and Health (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Line A. Eriksen</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Boredom Proneness in Psychopathic Traits: Evidence from Clinical and Non-Clinical Samples</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Mari Aguilera</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Does Emotional Regulation Have an Impact on the Perception of Body Health and Eating in Food Science College Students?</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Lev K Avbersek</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Redefining OCD: A Novel Framework Integrating Anxiety, Compulsivity, and Decision-Making</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Yulia Chentsova Dutton</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Somatoaffective Responses to Emotional Films</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Alia Hussain</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Social-Emotional Outcomes in Emerging Adults with ADHD: Exploring Self-Compassion, Interpersonal Concerns, and Psychological Distress</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">17:02</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T5: Flash Talks - Virtual Emotions (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Nana Löchner</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Emotion Recognition in Cyberspace: Distinct Emotion Recognition Abilities and Underlying Mechanisms for Emojis and Faces</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Lisa MS Miller</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Associations Between Social Media Use and Negative Affect among Young, Middle-Aged, and Older Adults</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Grégoire Richard</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Exploring Sensory Modalities to Simulate Touch from a Virtual Agent</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T5: Flash Talks - Attention and Eye-tracking (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Lucrezia Lonardo</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Investigating Pupil Mimicry in Pet Dogs</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Mario Carlo M Severom</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Do Threatening Faces Hold Attention Automatically? Evidence from an Eye-Tracking Study</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">17:10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Amandine Guillin</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Emotion and Eye Contact as Joint Primers of the Gaze-Cueing Effect</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">17:18</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T6: Flash Talks - Behavior, Decision-Making, Intergroup (Room Moyola: PFC/02/017)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Maciej Pastwa</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Impact of Approach and Avoidance Behavioral Tendencies on Risky Decision Making</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Daphnée Sénécal</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">The Reduced Ability to Detect Pain Expressions on the Faces of Black Individuals is Linked with a Strict Decision Criterion Rather than Sensitivity to Visual Information</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:38</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Stephan Treiss</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Loss Aversion, not Risk Aversion: The Impact of Incidental Emotions</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:46</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T6: Flash Talks - Behavior, Decision-Making, Intergroup, Intergroup (Room Moyola: PFC/02/017)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Zeynep B Özden</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Infant-Centered Behavioral Response Patterns to Discrete Emotions</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">16:54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58c"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Cristhian A. Martínez</span></p></td><td class="cl-48a2d583"><p class="cl-48a2cc4a"><span class="cl-48a182d6">The Hateful People: Populist Attitudes Predict Interpersonal and Intergroup Hate</span></p></td><td class="cl-48a2d584"><p class="cl-48a2cc4a"><span class="cl-48a182d6">17:02</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48a2d582"><p class="cl-48a2cc4a"><span class="cl-48a182e0">T6: Flash Talks - Behavior, Decision-Making, Intergroup (Room Moyola: PFC/02/017)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48a2d58d"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Nikhil Masters</span></p></td><td class="cl-48a2d596"><p class="cl-48a2cc4a"><span class="cl-48a182d6">Do Emotional Carryover Effects Carry Over?</span></p></td><td class="cl-48a2d597"><p class="cl-48a2cc4a"><span class="cl-48a182d6">17:10</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="evening-1" class="level4">
<h4 class="anchored" data-anchor-id="evening-1">Evening</h4>
<p><strong>ISRE2024 Conference Dinner, Titanic Belfast</strong></p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="july-5" class="level2">
<h2 class="anchored" data-anchor-id="july-5">20 July</h2>
<section id="from-0830-registration-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="from-0830-registration-whitla-hall">from 08:30 Registration (Whitla Hall)</h4>
</section>
<section id="parallel-session-6-pfc-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="parallel-session-6-pfc-whitla-hall">9:15 - 10:30 Parallel Session 6 (PFC / Whitla Hall)</h4>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48b1731c{}.cl-48ae3bd4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48ae3bde{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48af7e72{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48af8746{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af8750{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af8751{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af875a{width:1.5in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af875b{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af875c{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af8764{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af8765{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af8766{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48af8767{width:0.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48b1731c"><thead><tr style="overflow-wrap:break-word;"><th class="cl-48af8746"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Presenter</span></p></th><th class="cl-48af8750"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Title</span></p></th><th class="cl-48af8751"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Time</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T1: Symposium - Rethinking theories of emotional processes: Goal-direction, relevance-detection and social orientation (Room Whitla Hall)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Agnes Moors</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Emotions as High-Impact Decisions</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Daniel Dukes</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Emotions and Relevance</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Brian Parkinson</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Emotions as Social Processes</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Andrea Scarantino</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Discussion</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T2: Symposium - How does alexithymia moderate emotion processing? Evidence from cognitive and biological markers (Room Bann: PFC/0G/024)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Elena Constantinou</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">The Effect of Alexithymia on Emotion Response Coherence During Positive and Negative Emotions</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Piero Porcelli</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">The Relationship Between Alexithymia and Gut Microbiota in Patients with Inflammatory Bowel Disease</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Katharina S. Goerlich</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Out of Sync: Disrupted Prefrontal Brain Synchronization During Bluffing in Alexithymia</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Marine Mas</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Alexithymia Moderates Salience Effects in Emotional Facial Expression Perception and Recognition</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T3: Symposium - Emotions in Daily Life: A Closer Look at What Participants Have to Say (Room Foyle: PFC/0G/007)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Evgeniya Vedernikova</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Emotion Words: What’s Inside People’s Affective Reports</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Katie Hoemann</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Diversity in Everyday Experiences of Emotion: A Natural Language Approach</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Roza Kamiloğlu</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">The Granularity of Good: Distinguishing Positive Emotional Experiences</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Leonie Schorrlepp</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">How Do People Decide How They Feel? Response Processes in Experience Sampling Method Studies</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Yasemin Erba≈ü</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Discussion</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T4: Individual Talks - Interpersonal Context (Room Lagan: PFC/02/026)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Anke Visscher</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Adolescents’ Regulation of Positive and Negative Emotions and Affect: Moderation of Peer Status and Affiliation</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Aurelia Lilly Scharmer</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">The Link Between Need Frustration and Empathic Accuracy in Romantic Relationships</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Alexander Tagesson</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Failed Empathy Interventions</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Filoumena Zlatanou</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Do Emotions Matter in Business Relationships?</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T5: Individual Talks - History and Aesthetics (Room Roe: PFC/02/018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Ronald B de Sousa</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Emotions and Values</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Manuela Irarrazabal</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Social Categories in the Dramatisation of Anger in Ancient Greek Comedy</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Piotr Winkielman</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Fluency, Prediction, and Motivation: Processing Ease, Expectations, and Goals Determine Emotional Reactions to Art</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T6: Individual Talks - Conflicts in Clinical Contexts (Room Farset: PFC/02/025)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Ignacio Perezmontemayor Cruz</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Interpersonal Capitalization and Unmet Interpersonal Needs Among Adolescents at Varying Risk for Suicidal Ideation</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Sarah (Shih-Hua) Chen</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">The Effects of Emotion on Harmful Health Behaviors: Opposing Effects of Incidental Versus Integral Sadness</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Ciara O'Neill</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Show No Fear: An Analysis of Staff Communication During Conflict Management in Acute Adult Inpatient Mental Health Settings.</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Guy Laban</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Coping with Emotional Distress via Self-Disclosure to Robots: Intervention with Caregivers</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Andreia P. Costa</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Parents’ Depressive Symptomatology and their Perception of their Autistic Children’s Emotion Regulation Difficulties</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td colspan="3" class="cl-48af875a"><p class="cl-48af7e72"><span class="cl-48ae3bde">T7: Individual Talks - Recognition and Perception (Room Moyola: PFC/02/017)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Joshua Baker</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">The Effects of Facial Feedback on the Automatic Discrimination of Facial Expressions</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Ana Milošič</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Judgments of Smile Genuineness in an Intergroup Context</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Leora Sevi</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Personality Information Shapes Judgment of Emotional Expressions</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">09:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8764"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Tanja S H Wingenbach</span></p></td><td class="cl-48af875b"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Embodied Emotion: Implicit Facial Muscle Response Patterns to Emotion Words Align with Prototypical Facial Emotional Expressions</span></p></td><td class="cl-48af875c"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48af8765"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Sebastian Korb</span></p></td><td class="cl-48af8766"><p class="cl-48af7e72"><span class="cl-48ae3bd4">Modulating Facial Emotion Recognition with Electrical Muscle Stimulation</span></p></td><td class="cl-48af8767"><p class="cl-48af7e72"><span class="cl-48ae3bd4">10:15</span></p></td></tr></tbody></table></div>
</div>
</div>
</section>
<section id="coffee-and-tea-the-great-hall-4" class="level4">
<h4 class="anchored" data-anchor-id="coffee-and-tea-the-great-hall-4">10:30 - 11:00 Coffee and Tea (the Great Hall)</h4>
</section>
<section id="keynote-3-terry-maroney-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="keynote-3-terry-maroney-whitla-hall">11:00 - 12:00 Keynote 3: Terry Maroney (Whitla Hall)</h4>
</section>
<section id="section-3" class="level4">
<h4 class="anchored" data-anchor-id="section-3"></h4>
<p><strong>What Judges Feel: Investigating the Emotional Elements of Judging</strong></p>
<p>A cultural script of judicial dispassion long has positioned reason and emotion as natural opposites, law as the sanctuary of reason, and judges as the emotionless guardians of that boundary. Our present “age of affectism” exposes that script as both inaccurate and counterproductive. But what lies beyond it? In this talk, Professor Maroney will present an overview of her multi-year, mixed-methods empirical study into the role of emotion and its regulation in the lives and work of judges in the United States, giving us an early view of portions of her forthcoming book, What Judges Feel: How Emotions Shape Justice.</p>
</section>
<section id="closing-session-and-awards-whitla-hall" class="level4">
<h4 class="anchored" data-anchor-id="closing-session-and-awards-whitla-hall">12:00 - 12.30 Closing Session and Awards (Whitla Hall)</h4>
</section>
<section id="from-1230-lunch-the-great-hall" class="level4">
<h4 class="anchored" data-anchor-id="from-1230-lunch-the-great-hall">from 12:30 Lunch (the Great Hall)</h4>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="symposium-abstracts" class="level1">
<h1>Symposium Abstracts</h1>
<div style="page-break-after: always;"></div>
<section id="parallel-session-1-t1" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-1-t1">Parallel Session 1 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48bdca2c{}.cl-48bb1d0e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48bc2da2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48bc355e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48bc3568{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48bc3572{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48bc3573{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48bc357c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48bc357d{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48bdca2c"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48bc355e"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Track</span></p></td><td class="cl-48bc3568"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48bc3572"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Type</span></p></td><td class="cl-48bc3573"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48bc3572"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Title</span></p></td><td class="cl-48bc3573"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Beyond Poses: Perception of Genuine Emotional Expressions</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48bc3572"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Time</span></p></td><td class="cl-48bc3573"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">10:45 - 11:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48bc3572"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Room</span></p></td><td class="cl-48bc3573"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Whitla Hall</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48bc357c"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Abstract</span></p></td><td class="cl-48bc357d"><p class="cl-48bc2da2"><span class="cl-48bb1d0e">Existing research on the perception of non-verbal emotion expressions has predominantly focused on posed or standardized emotional expressions, which usually do not reflect the genuine emotional experience of the expressers. Studying these artificially created emotional expressions gives researchers a high degree of experimental control. However, it is uncertain to what extent the perception of such stimuli is comparable to emotion perception processes in the real-world. This symposium presents a collective exploration into the perception of spontaneous and genuine emotional expressions. The studies presented here investigate emotion perception from different types of genuine expressions, and the process is investigated in cross-cultural contexts as well as clinical populations. Talk 1 provides a direct and systematic comparison between posed and spontaneous expressions from the same expressers, showing clear differences between the two. Talk 2 continues to demonstrate that real-life spontaneous expressions are poorly recognized, pointing to the important role of context in successful emotion identification. Talk 3 investigates cross-cultural emotion recognition from posed and spontaneous expressions and found spontaneity to influence the size of the ‚Äúin-group advantage‚Äù. Finally, talk 4 explores emotion perception of genuine expressions in two clinical populations, whose emotion recognition deficits have previously been established using only posed expressions. Together, these talks emphasize the importance of using ecologically valid stimuli and paradigms to study non-verbal emotion communication. Our symposium points to the need for the field to move beyond traditional methods of studying emotion perception from non-verbal expressions.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Differences in Emotion Perception from Posed and Spontaneous Facial Expressions</strong><br>
Time: 10:45-11:00<br>
Authors: <strong>Yong-Qi Cong, Lidya Yurdum, Agneta Fischer, Disa Sauter</strong><br>
Abstract: A widely used experimental paradigm in psychological research and clinical assessments involves identifying emotions from facial expressions, typically using posed expressions as stimuli. Perceptions of such stimuli are assumed to mirror those of naturally occurring emotional expressions. However, this assumption has been questioned because the perceptual equivalence of posed and spontaneous expressions has not been empirically established. To address this, we directly compared perceptual judgments of posed and spontaneous facial expressions produced by the same expressers in three pre-registered studies. A total of 2610 perceivers judged the emotions displayed in 1244 dynamic facial expressions of eight emotions (anger, disgust, fear, sadness, joy, pride, compassion, and love). Consistent with our main hypothesis, emotions were much better recognised from posed compared to spontaneous expressions, by both Western (Study 1, N=470) and non-Western perceivers (Study 2, N=438). This pattern was replicated in a cross-cultural context in Study 3 (N=1702). Furthermore, in all three studies, we found that negative emotions were better recognised than positive emotions from posed expressions, while the opposite was true for spontaneous expressions. Our findings present clear evidence that perceptions of posed and spontaneous facial expressions meaningfully differ, and raise questions about the generalisability of findings from existing research that uses posed emotional expressions.<br>
&nbsp;<br>
Title: <strong>The Ingroup Advantage in Cross-Cultural Facial Expression Recognition: Influences of Spontaneity and Presentation Mode</strong><br>
Time: 11:00-11:15<br>
Authors: <strong>Xia Fang, Youxun Ge</strong><br>
Abstract: In today’s globalized world, effective cross-cultural communication has become increasingly crucial. Nonverbal cues, particularly facial expressions, play a significant role in conveying emotions during interactions between individuals from different cultural backgrounds. Previous research has established the existence of an “ingroup advantage,” whereby individuals are more accurate at recognizing facial expressions displayed by individuals from their own cultural group compared to those from different cultural groups. However, most previous studies have focused on static posed expressions, with limited knowledge about the ingroup advantage in dynamic and spontaneous expressions. To investigate whether the ingroup advantage is modulated by the spontaneity (posed and spontaneous) and presentation mode (static and dynamic) of facial expressions, Chinese and Canadian/Dutch participants were recruited to identify posed and spontaneous angry and disgusted expressions by Chinese and Dutch actors (Experiment 1), as well as static and dynamic expressions of anger and disgust by Chinese and Dutch actors (Experiment 2). The results showed that in most cases, both posed and spontaneous expressions exhibited an ingroup advantage, with such advantage being significantly larger for posed expressions compared to spontaneous expressions. Moreover, both static and dynamic expressions demonstrated an ingroup advantage, with no significant difference between the two overall. These findings suggest that the ingroup advantage in facial expression recognition is influenced by the spontaneity of the expressions but remains unaffected by the presentation mode.<br>
&nbsp;<br>
Title: <strong>Emotion Recognition of and Facial Mimicry to Genuine Expressions - In Autism Spectrum Disorder and Social Anxiety Disorder</strong><br>
Time: 11:15-11:30<br>
Authors: <strong>Anouschka van Dijk, Mariska Kret, Eliska Prochazkova</strong><br>
Abstract: The ability to understand and mimic emotional expressions is crucial to navigate social environments. Patients with autism spectrum disorder (ASD) and social anxiety disorder (SAD) tend to have profound difficulties in the social domain and show deficits in expressing emotion, recognizing emotions and mimicry. Thus far, research into emotion has primarily focused on the perception of explicit, posed facial expressions of emotion. However, real-life emotions are expressed by the whole body, and are typically more ambiguous and can be more difficult to rapidly decipher. To better understand how patients with ASD and SAD perceive emotions in the real world , we chose to present patients with genuine whole-body emotional expressions and measured mimicry levels and emotion recognition. To measure mimicry, we measure facial EMG and skin conductance whilst participants passively view these stimuli, and are asked to label the stimuli afterwards. We are currently in the data collection phase, but will be able to present results during ISRE. We expect to find lower levels of mimicry and decreased emotion recognition for the patients with ASD compared to the typical population and significant differences in mimicry and emotion recognition between the patients with SAD and the typical population. Similarities and differences between the disorders will be discussed.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-1-t2" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-1-t2">Parallel Session 1 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48c84f7e{}.cl-48c5a6e8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48c6b57e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48c6bd4e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48c6bd4f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48c6bd58{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48c6bd59{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48c6bd5a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48c6bd62{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48c84f7e"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48c6bd4e"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Track</span></p></td><td class="cl-48c6bd4f"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48c6bd58"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Type</span></p></td><td class="cl-48c6bd59"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48c6bd58"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Title</span></p></td><td class="cl-48c6bd59"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Exploring the “dark” side of media:</span><br><span class="cl-48c5a6e8"> fascination with negative content in the digital age</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48c6bd58"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Time</span></p></td><td class="cl-48c6bd59"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">10:45 - 11:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48c6bd58"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Room</span></p></td><td class="cl-48c6bd59"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Bann: PFC/0G/024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48c6bd5a"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">Abstract</span></p></td><td class="cl-48c6bd62"><p class="cl-48c6b57e"><span class="cl-48c5a6e8">These days, our lives and interests are increasingly moving into the digital space. Yet, some of the media that people enjoy seems to be morbid, disturbing, or even sadistic. Examples include catastrophic news of war or injustice, social media profiles exposing the misfortune of celebrities, stories of real murder cases narrated in podcasts, or viral clips of people failing, hurting, or embarrassing themselves. Intuitively, consuming this negative content may evoke unpleasant emotions like fear, sadness, or worry, and it may be linked to low empathy, aggression, and other maladaptive outcomes. However, in this symposium, we discuss that there are adaptive and important psychological functions behind this engagement with negative content. Speakers will present work on the motives of people engaging with the suffering of strangers (presenter 1), consumption of news related to war and violence (presenter 2), the experience of schadenfreude evoked by media use (presenter 3), and people‚Äôs fascination with true crime content (presenter 4). We explore this topic using a wide range of methods including experiments, surveys and self-report, qualitative data, scale development, and neuroscience in order to explain the psychology of engaging with morbid content. In total, this interdisciplinary symposium will illuminate the underlying mechanisms, outcomes and potential benefits of this ‚Äò‚Äúdarker‚Äù side of media.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Why Do People Engage with the Suffering of Strangers? Exploring Epistemic, Eudaimonic, Social and Affective Motives</strong><br>
Time: 10:45-11:00<br>
Authors: <strong>Anastassia Vivanco Carlevari</strong><br>
Abstract: Reading about violent stories or watching a war documentary are examples in which people voluntarily engage with suffering even knowing that it can be disturbing. Through a mix-method approach, we aim to map the motives for exploring the suffering of distant people. Firstly, in a qualitative study (n=244) participants described situations of suffering and their reasons to engage. The results characterize who was the stranger, what was situations about, how the participant accessed to it and why they decided to do it. We identified four categories of motives: epistemic, eudaimonic, social and affective. Giving an overview of the perceived value of engaging with the situation. In a next step, we aimed to evaluate the relevance and generalizability of these motives depending on specific contexts of suffering and sources of information. Study 2 asked people (n=250) to recall situations in which they engaged with the suffering and then were presented with 32 items to rate how applicable these motives were to their decision. The results show that people engaged with strangers’ suffering to acquire knowledge (e.g.&nbsp;learn something about the world), for personal utility (e.g.&nbsp;to prepare for an emergency), for social utility (e.g.&nbsp;supporting others), and to feel positive (e.g.&nbsp;gratitude) and negative (e.g.&nbsp;outrage) emotions. People report that online media and cultural expressions (e.g., art, books, movies) are significantly more engaging than real-life encounters. These results are interesting to understand the deliberate exploration of human suffering as a motivated phenomenon.<br>
&nbsp;<br>
Title: <strong>Why Do We Read News? Identifying the Factors that Promote General and Specific News Consumption</strong><br>
Time: 11:00-11:15<br>
Authors: <strong>Ellen O’Donoghue</strong><br>
Abstract: In an age marked by increasing levels of news avoidance, the motivational factors that support news consumption are of interest to researchers, news providers, and consumers alike. Here, we took a data-driven approach toward identifying the factors that promote general news consumption (Experiment 1), as well as news consumption surrounding a specific, negatively valenced world event: the Russia-Ukraine War (Experiment 2). In Experiment 1, we created 24 questionnaire items to explore why people consume general news. Through factor analysis, we identified three distinct motivational factors: ‘Informational Updating’, ‘Understanding &amp; Sense-Making’, and ‘Affect Regulation’. Among them, ‘Informational Updating’ was the strongest predictor of consumption frequency: participants with stronger motivations to stay up-to-date consumed news more often. In Experiment 2, we asked whether these same factors would support news consumption surrounding the Russia-Ukraine War. Contrary to Experiment 1, ‘Understanding &amp; Sense-Making’ was the strongest predictor of consumption frequency. Additionally, exploratory analyses suggested a nonlinear relationship between ‘Affect Regulation’ and consumption frequency: participants with moderate motivations for ‘Affect Regulation’ consumed news surrounding the Russia-Ukraine War more frequently than participants with strong or weak motivations for ‘Affect Regulation’. Our findings suggest that the motivational factors supporting general and specific news consumption may differ, demonstrating a need for more topic- dependent research. Additionally, we highlight several factors that might lead people to seek and/or avoid negative news topics. Continued research surrounding these factors could aid the promotion of healthy news hygiene.<br>
&nbsp;<br>
Title: <strong>Explaining Different Shades of Schadenfreude: Why People Feel Pleasure when the Media Show the Misfortunes of Others</strong><br>
Time: 11:15-11:30<br>
Authors: <strong>Lilian Suter</strong><br>
Abstract: Schadenfreude is “the pleasure at the misfortunes of others” (van Dijk &amp; Ouwerkerk, 2014, p.&nbsp;6). In this talk, I will distinguish different subtypes of schadenfreude, as the pleasure can be grounded in different needs and concerns. I therefore argue that a differentiation is necessary to fully understand the phenomenon of schadenfreude. In this theoretical contribution, I will build on existing work (e.g., Wang et al., 2019; Smith et al., 2009) but also add another layer of differentiation in which I distinguish superficial from profound schadenfreude (cf.&nbsp;Moers, 1930). In profound schadenfreude, different psychological needs and concerns fuel the appraisal of deservingness of a misfortune that is closely linked to the emotion of schadenfreude. This is the area where most scholarly work has been done in the past. In superficial schadenfreude, the definition of “pleasure at the misfortunes of others” still holds true, but the mechanism of pleasure is not grounded in deservingness but more in humor and the violation of expectations. In profound schadenfreude, people feel pleasure because of harm. In superficial schadenfreude, people feel pleasure despite of harm. Finally, I will show how these different subtypes of schadenfreude play a role in certain media formats (fail video clips, sports competitions, reality TV etc.) and how the emotion of schadenfreude can therefore contribute to watching negative content.<br>
&nbsp;<br>
Title: <strong>“Murder is My Favorite Medium” Motives Behind and Outcomes of People’s Fascination with True Crime</strong><br>
Time: 11:30-11:45<br>
Authors: <strong>Corinna Perchtold-Stefan</strong><br>
Abstract: People’s fascination with true crime – the depiction of real-life crime on TV, social media, or in podcasts seems like a morbid hobby. Yet, true crime media are booming, with the majority of consumers being women. Theories treat enjoyment of true crime either as a maladaptive interest (exposure to violence cultivates fear and aggression) or an adaptive coping mechanism (reduced uncertainty, emotion regulation practice). Given the lack of empirical work on this topic, we conducted a multi-part study on 300-600 true crime fans and not-fans, which included MRI resting-state scans of brain activity to help explain why some people are drawn to true crime, and some are not. Our goal was to answer two central questions: 1) What motives do people report for true crime consumption, and 2) how is it linked to well-being? Our results showed that the primary motive for consuming true crime was making sense of “evil” (~70%), followed by unspecified curiosity (~30%), and interest in the justice system (~27%). Women reported more true crime consumption than men, and a stronger motive of defensive vigilance. Interestingly, true crime consumption was uncorrelated to perceived likelihood of victimization in women, but showed a positive link to feeling unsafe in men. Moreover, true crime consumption showed no meaningful relationships with stress, anxiety, or worry, but was positively linked to problem-oriented reappraisal and negatively to acceptance as emotion regulation strategies. Altogether, our behavioral and neuroscience work suggests that there may be less pathology and more adaptivity in “murder as one’s favorite medium”.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-1-t3" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-1-t3">Parallel Session 1 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48d2350c{}.cl-48cfa4c2{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48d0a8cc{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48d0b06a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48d0b06b{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48d0b06c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48d0b074{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48d0b075{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48d0b076{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48d2350c"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48d0b06a"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Track</span></p></td><td class="cl-48d0b06b"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48d0b06c"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Type</span></p></td><td class="cl-48d0b074"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48d0b06c"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Title</span></p></td><td class="cl-48d0b074"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Emotions in Artificial Social Agents: Heavenly Bliss or Hellish Nightmare?</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48d0b06c"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Time</span></p></td><td class="cl-48d0b074"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">10:45 - 11:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48d0b06c"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Room</span></p></td><td class="cl-48d0b074"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Foyle: PFC/0G/007</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48d0b075"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">Abstract</span></p></td><td class="cl-48d0b076"><p class="cl-48d0a8cc"><span class="cl-48cfa4c2">In the movie ‚ÄúHer‚Äù, Theodore meets Samantha, an A.I. assistant whose sultry voice reveals a playful and sensitive personality. Although they start as friends, the relationship soon deepens into ‚Äúlove‚Äù. Samantha is talking to thousands of people synchronously, and appears to be in love with many of them. Once Theodore discovers it, he feels bitterly disappointed. His love for Samantha, however, continues to feel very real. The movie raises two central questions. First, can artificial social agents have emotions? Author 1 begins by introducing basic conceptual distinctions useful for discussing artificial emotions, including the distinction between merely mimicking emotions and actually having them, and the distinction between computational, algorithmic, and implementational challenges to embedding emotions in artificial creatures. Author 2 then offers two reasons to think that robots ought to have emotions: ascribing emotions to them may be helpful to increase our ability to predict their behavior, and having emotions may help robots deal with the emergencies they face. Second, can artificial social agents communicate emotions they do not necessarily have, and shape and potentially manipulate the emotions of humans? Author 3 presents a social-functional perspective on emotional expressions, arguing that designers of expressive machines should avoid connecting expressions to feelings, and focus instead on realizing the social functions of expressions in human‚Äìmachine interactions  Author 4 concludes by discussing two ways robots can affect the emotions of humans: directly through interactions that generate emotional affordances, and indirectly through shaping the human informational environment.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Setting the Stage: How to Frame Questions About Emotions in Artificial Social Agents (ASAs)</strong><br>
Time: 10:45-11:00<br>
Authors: <strong>Eva Hudlicka</strong><br>
Abstract: As ASAs capabilities to display human-like emotions improve, we are increasingly asking whether they can and should have emotions. As computational affective modeling continues to progress, we will soon also begin asking whether these artificial agents do have emotions. And yet we still lack sufficiently precise definitions of emotions that would enable a systematic exploration of these questions. In this talk, I introduce distinctions and concepts that can support a more systematic approach to the topic of emotions in ASAs. First, we need to distinguish between the phenotype (external manifestations) and the genotype (internal implementation) of ASA emotions. Second, we need to distinguish between simulation (reproducing functionality) and emulation (reproducing actual mechanisms) of biological emotions in artificial agents. Third, we need to develop more precise terminology, where different affective state types (emotions, moods) and processes (emotion generation, emotion effects) are defined in terms of the cognitive-affective architectures capable of producing them,asproposedbySloman. Fourth,weneedtodistinguishbetweendescriptiveandmechanistic affective theories. Whereas descriptive theories focus on static characterizations of affective states in terms of their components, mechanistic theories aim to characterize the nature of affective processes. Lastly, to facilitate clearer cross-disciplinary communication and model design, we need to distinguish among different levels of explanation, in both theories and models: computational, algorithmic and implementational, as proposed by Marr and Pylyshyn. I will conclude with some thoughts regarding the importance of characterizing the design space of cognitive-affective architectures that can accommodate both biological and synthetic emotions.<br>
&nbsp;<br>
Title: <strong>Emotions in Robots? Good for Us to Ascribe Them, Good for Them to Have Them</strong><br>
Time: 11:00-11:15<br>
Authors: <strong>Andrea Scarantino</strong><br>
Abstract: Should we ascribe emotions to socially interactive robots? In this talk, I will answer that we should, quite independently of whether robot psychology includes causal structures that are anything like human emotions. This Emotional Stance argument is inspired by Dan Dennett’s Intentional Stance, according to which mental states are to be ascribed to a creature X if that helps us better predict X’s behavior. On the other hand, we must give up on Dennett’s assumption of ‘ideal rationality’ – emotions are going to be usefully ascribed to robots insofar as their behaviors manifest the combination of advantages and occasional rationality failures of emotional behavior. The second part of my talk focuses on a different, Architectural Argument for why robots may need emotions. I begin from Herbert Simon’s proposal that robots need emotions understood as ‘interrupt systems’ to handle emergencies. Simon’s account points us in the right direction, but it misses a key element, namely that emotions do not just interrupt ongoing goal-pursuits, but also provide guidance/instructions for achieving emotion-specific relational goals, in cooperation with higher cognition. I will characterize emotions in robots as ‘notice, interrupt and guide’ computational systems. I conclude by investigating the role consciousness may play in systems of this sort, and what limitations robots who have emotions, but no consciousness of them, may face.<br>
&nbsp;<br>
Title: <strong>Social Functions of Machine Emotional Expressions</strong><br>
Time: 11:15-11:30<br>
Authors: <strong>Jonathan Gratch, Celso de Melo, Stacy Marsella &amp; Catherine Pelachaud</strong><br>
Abstract: Socially interactive agents frequently generate behaviors that human observers naturally see as expressing emotion, yet almost never do these expressions reflect something analogous to the machine’s internal “emotional” state. While some fret this is inherently deceptive, many human emotional expressions similarly do not reflect underlying feelings, but rather are produced to achieve important social functions. For example, an expression of guilt signals a commitment to repair the relationship after a transgression and an expression of surprise signals an expectation violation, but these function can be served without positing a connection to some underlying human or synthetic emotional state. Embracing a social-functional perspective on emotional expressions, we argue that designers of expressive machines should avoid attempts to connect expressions something like a “feeling”, but rather focus on formalizing and realizing these interactional functions. We review psychological findings on how emotional expressions achieve important social functions in human relationships and highlight that artificial emotional expressions can serve analogous functions in human–machine interaction. We then review computational methods for determining what expressions make sense to generate within the context of interaction and how to realize those expressions across multiple modalities, such as facial expressions, voice, language, and touch.<br>
&nbsp;<br>
Title: <strong>How Could Robots Shape or Exploit Human Emotions?</strong><br>
Time: 11:30-11:45<br>
Authors: <strong>Lydia Farina</strong><br>
Abstract: In this talk, I discuss two ways in which robots could shape human emotions: (1) directly through human/robot interactions by eliciting emotional responses deemed suitable to the context of interaction and (2) indirectly through controlling the informational environments humans dwell in. Because humans tend to adjust emotional behaviour in accordance with environmental affordances, interacting with social robots in a certain context can directly lead to eliciting empathy towards a humanoid robot. In a similar way, in the context of assistive robots, being ‘cared for’ may elicit feelings towards robotic care-takers (Studley and Meacham 2017). In the case of disembodied machines, the indirect shaping can take place by the machines selecting the informational cues one receives relating to news, world affairs etc., which encourages or discourages specific emotional reactions and narratives. In the final part of my talk, I argue that the ability of robots to shape or exploit human emotions does not hinge on robots being agents in any strong sense or on robots having a capacity to experience emotions themselves. Instead, I suggest that the following conditions are necessary: 1) robots must be trained to recognize emotional narratives in the sense of matching stimuli or behavioural expression with emotional performances and 2) robots must be trained to give appropriate context-dependent responses to encourage/discourage emotional narratives. I conclude that the degree of shaping depends on the volume of our interaction with robots, and on the specific purposes (e.g.&nbsp;commercial, educational etc.) of using robots in these environments.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-1-t4" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-1-t4">Parallel Session 1 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48dc6ac2{}.cl-48d9ca6a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48dad6e4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48dade82{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48dade8c{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48dade8d{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48dade8e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48dade96{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48dade97{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48dc6ac2"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48dade82"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Track</span></p></td><td class="cl-48dade8c"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48dade8d"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Type</span></p></td><td class="cl-48dade8e"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48dade8d"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Title</span></p></td><td class="cl-48dade8e"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Innovations in measuring, understanding and improving emotion (regulation) dynamics across time</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48dade8d"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Discussant</span></p></td><td class="cl-48dade8e"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Eeske van Roekel</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48dade8d"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Time</span></p></td><td class="cl-48dade8e"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">10:45 - 12:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48dade8d"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Room</span></p></td><td class="cl-48dade8e"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Lagan: PFC/02/026</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48dade96"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">Abstract</span></p></td><td class="cl-48dade97"><p class="cl-48dad6e4"><span class="cl-48d9ca6a">The regulation of emotions plays a central role in our well-being. Although a core feature of emotions is that they change over time and those dynamics contain important information about how individuals regulate their emotions, emotion regulation is still often studied as a stable concept. The current multi-method symposium brings together four speakers who emphasize the importance of dynamics in the study of emotions and emotion regulation. The presentations range from methodological contributions to improve the measurement of emotions over research on inter- individual and contextual influences on emotion regulation to novel intervention techniques to improve positive emotions. The first presentation introduces an innovative method for capturing emotion dynamics in Experience Sampling Method (ESM) studies through continuous affect drawings and how this approach enhances the investigation of emotional episodes and regulation processes in daily life. The second presentation showcases how interindividual differences in parental optimism can shape emotion regulation in children. Using observational data on parents and their young children, the study addresses whether interindividual differences in parental optimism are related to dyadic affective flexibility. The third presentation highlights the importance of contextual influences on emotion regulation and presents findings from a daily diary study that assessed emotional context and emotion regulation strategies across 60 days in young adults. The fourth presentation addresses how emotion regulation can be fostered with targeted interventions and presents a study on just-in- time adaptive interventions to improve positive emotion regulation. The discussant will highlight future directions to further advance the study of emotion (regulation) dynamics.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Validating the Level and Timing of Affect Dynamics Through Continuous Affect Drawings</strong><br>
Time: 10:45-11:05<br>
Authors: <strong>Leonie Cloos</strong><br>
Abstract: Experience sampling methods promise the measurement of affect dynamics through repeated assessments. Yet, these are limited to several momentary affect assessments, which may not occur or not be answered when affective events happen. The resulting data may lack important information on affective events and emotion episodes. This has implications for studies aiming to capture emotional experiences and regulation processes. We present an alternative response format that allows participants to draw their affective changes between assessments. With this method, we can obtain time-continuous data in form of a drawing depicting affective responses and regulation. Our research question is to determine periods when the data is most informative. In a one-week experience sampling study, 115 participants rated their momentary positive and negative affect six times a day. From the second assessment onwards they drew their positive and negative affect changes since the previous assessment, reported positive and negative events, and received a daily measurement burst between two random assessments. The goal of the current study is to extract relevant information from the data. Particularly, applying the peak rule we first examine if the maximum and minimum scores of the burst data and the drawing correspond. Secondly, we map self-reported event intensity to the maximum intensity in the drawings. Moreover, applying the end rule, we first study whether the overlap between the burst and drawing strengthens toward the end of a drawing; and secondly how the timing of an event influences the overlap between event intensity and the maximum intensity of the drawing.<br>
&nbsp;<br>
Title: <strong>Parental Optimism and Dyadic Affective Flexibility During Interactions Between Parents and their 2.5-Year-Old Children</strong><br>
Time: 11:05-11:25<br>
Authors: <strong>Charlotte Vrijen</strong><br>
Abstract: There is evidence that optimists experience better physical and mental health and a higher quality of life compared to pessimists. The benefits of optimism may even transmit to the next generation. Our aim is to study to what extent and how parental optimism shapes the lives of offspring. We hypothesize that optimistic parents are generally more effective in regulating their emotions and transmit these skills to the next generation. To test this hypothesis, we study whether parental optimism predicts more dyadic affective flexibility during interactions between parents and their young children (~ age 2.5). Parent-child dyadic affective flexibility refers to the ability of a parent and child to adjust to contextual demands by shifting between emotional states together and is an early precursor of adaptive emotion regulation. Data are used from a large-scale longitudinal cohort study. Parental optimism is assessed with the self-report Life Orientation Test (LOT-R). Videotaped observations of parent-child interactions during goal-directed tasks that include a frustration are used to code child and parent affect (negative externalizing, negative internalizing, neutral, interest, and positive) with an adapted version of the SPecific Affect (SPAFF) coding system. Dyadic affective flexibility is derived from state space grids in Mangold INTERACT. Videos are currently being coded and first results based on ~ 80 child-parent dyads will be presented and discussed at the symposium. If parent-child dyadic affective flexibility is indeed higher for more optimistic parents, this may indicate important advantages of optimism for the next generation.<br>
&nbsp;<br>
Title: <strong>incReasIng poSitive Emotions (RISE Project): A Pilot Study on a Just-in-Time Adaptive Intervention in Daily Life</strong><br>
Time: 11:25-11:45<br>
Authors: <strong>Eeske van Roekel</strong><br>
Abstract: Improving positive emotion regulation is essential in preventing mental health problems and increasing well-being. An effective way to improve positive emotions (PE) is through positive psychology interventions. While previous Experience Sampling Method (ESM) studies demonstrated that providing one-time personalized ESM-based feedback increases PE, there is large heterogeneity in effectiveness. An important next step is to further personalize interventions through “just-in-time adaptive interventions” (JITAI), by identifying the optimal timing and content of the intervention. The present study examines the feasibility of providing micro-interventions during low versus high positive emotion moments in a sample of first-year university students (N = 139). Participants enrolled in a 15-day baseline period, after which they were randomly assigned to the intervention group (N = 70) who continues with the ESM for another 14 days and receives the JITAI, or an active control group (N= 69) who only continues with the ESM. Subsequently, all participants continued with another 15 days of ESM. The initial cohort (N = 52) showed high compliance with the ESM (75%), and with the interventions (90-95%). Compared to the control group, the intervention group reported to be better able to cope with negative emotions, and to feel better about themselves due to the study. Changes in outcome variables will be presented during the conference, as data from the ongoing second cohort are currently collected. This research underscores the potential of personalized, timely micro-interventions in amplifying positive emotions and well-being, offering valuable insights for mental health interventions.<br>
&nbsp;<br>
Title: <strong>Discussion</strong><br>
Time: 11:45-12:00<br>
Authors: <strong>van Roekel, Eeske</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-1-t5" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-1-t5">Parallel Session 1 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48e68c8c{}.cl-48e3f51c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48e4febc{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48e50650{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48e5065a{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48e5065b{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48e50664{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48e50665{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48e5066e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48e68c8c"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48e50650"><p class="cl-48e4febc"><span class="cl-48e3f51c">Track</span></p></td><td class="cl-48e5065a"><p class="cl-48e4febc"><span class="cl-48e3f51c">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48e5065b"><p class="cl-48e4febc"><span class="cl-48e3f51c">Type</span></p></td><td class="cl-48e50664"><p class="cl-48e4febc"><span class="cl-48e3f51c">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48e5065b"><p class="cl-48e4febc"><span class="cl-48e3f51c">Title</span></p></td><td class="cl-48e50664"><p class="cl-48e4febc"><span class="cl-48e3f51c">Cultural context</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48e5065b"><p class="cl-48e4febc"><span class="cl-48e3f51c">Time</span></p></td><td class="cl-48e50664"><p class="cl-48e4febc"><span class="cl-48e3f51c">10:45 - 12:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48e50665"><p class="cl-48e4febc"><span class="cl-48e3f51c">Room</span></p></td><td class="cl-48e5066e"><p class="cl-48e4febc"><span class="cl-48e3f51c">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotion Regulation Strategies in Diverse Contexts: Insights from Mexican and Yucatec Maya Children</strong><br>
Time: 10:45-11:00<br>
Authors: <strong>Brady, Shannon M; Shneidman, Laura; Chay Cano, Cornelio Azarias; Davis, Elizabeth</strong><br>
Abstract: As children age, they refine regulatory skills, generally moving from reliance on behavioral strategies (e.g., turning away from undesirable stimuli) to a combination of cognitive and behavioral strategies (e.g., reappraising an upsetting situation). Existing literature, however, is often based on WEIRD (Western, Educated, Industrialized, Rich, Democratic) contexts—which raises questions about generalizability of results. To provide more information from majority-world contexts, this project examines the emotion regulation strategies present in children (6 and 10 years of age) from Mexico City (N = 43) and from small-scale indigenous Yucatec Maya communities around Chemax, Mexico (N = 39). Children were asked to recall memories of when they recently felt sad, angry, scared, or embarrassed before being asked what they did to make themselves feel better. Responses were later transcribed and coded for different emotion regulation strategies. Results from between subjects ANOVAs for age group and sample demonstrated that older children reported using a broader general repertoire [F(1, 78) = 4.79, p = .03, η = .06] and a greater number of regulatory attempts for sad memories [F(1, 78) = 6.42, p = .01, η = .08] than younger children. Furthermore, Yucatec Maya children reported more instances of attempts at goal change than children from Mexico City, F(1, 78) = 8.67, p = .004, η = .10. Planned analyses will further explore links between specific strategies and discrete emotion contexts. While more work is necessary, this study provides novel information about children’s emotion regulation strategy use outside of Western contexts.<br>
&nbsp;<br>
Title: <strong>Emotion Regulation Strategies and Psychological Health Across Cultures</strong><br>
Time: 11:00-11:15<br>
Authors: <strong>Tamir, Maya; Miyamoto, Yuri; Chentsova-Dutton, Yulia</strong><br>
Abstract: Emotion regulation is important for psychological health, and can be achieved by implementing various strategies. How one regulates emotions is critical for maximizing psychological health. Few studies, however, tested the psychological correlates of different emotion regulation strategies across multiple cultures. In a pre-registered cross-cultural study (N=3,960, 19 countries), conducted during the COVID-19 pandemic, we assessed associations between the use of seven emotion regulation strategies (situation selection, distraction, rumination, cognitive reappraisal, acceptance, expressive suppression, emotional support seeking) and four indices of psychological health (life satisfaction, depressive symptoms, perceived stress, and loneliness). Model comparisons based on Bayesian Information Criteria provided support for cultural differences in 36% of associations, with very strong support for differences in 18% of associations. Strategies that were linked to worse psychological health in individualist countries (e.g., rumination, expressive suppression) were unrelated or linked to better psychological health in collectivist countries. Cultural differences in associations with psychological health were most prominent for expressive suppression and rumination, and also found for distraction and acceptance. In addition, we found evidence for cultural similarities in 46% of associations between strategies and psychological health, but none of this evidence was very strong. Cultural similarities were most prominent in associations of psychological health with emotional support seeking. These findings highlight the importance of considering the cultural context to understand how individuals from diverse backgrounds manage unpleasant emotions.<br>
&nbsp;<br>
Title: <strong>The Role of Afrocultural Ethos in African American Youth’s Emotion Skill Development</strong><br>
Time: 11:15-11:30<br>
Authors: <strong>Lozada, Fantasy T</strong><br>
Abstract: The current research on African American youth’s emotional development yields an incomplete understanding of the cultural influences that shape their emotion-related. To understand the emotional development of African American youth, we must explore emotion-related skills in ways that are inclusive of African American’s multiple cultural experiences. We must also be clear that the exploration of minoritized cultural experiences (e.g., racism, racial socialization, and racial coping) do not capture the whole or even always the most salient aspects of African American experiences regarding emotional development. Although understanding the role of racism in African American youth’s emotional lives is of the utmost importance (Lozada et al., 2022), the exclusive focus on racism limits the building of a developmental affective science that reflects the full range of emotional experiences of African American youth. In the current paper, I consider Boykin (1986) and colleagues’ (1985) articulation of the Triple Quandary Theory as the framework for multiple cultural influences: a mainstream cultural influence (reflective of white, European American values), a minority cultural influence (reflective of the navigation and coping with racial oppression), and a Black cultural influence (reflective of Afrocultural values intergenerationally transmitted from various Western African philosophies). I also discuss Afrocultural ethos (see Figure 1) as an aspect of African American cultural experiences that shapes African American emotional development, using affect and orality as examples that can be explored within emotional development research and leveraged for future efforts to address African American youths’ emotional health and wellness (see Table 1).<br>
&nbsp;<br>
Title: <strong>Methodological and Cultural Considerations when Studying Emotions: A Perspective from Hawaiʻi</strong><br>
Time: 11:30-11:45<br>
Authors: <strong>Aumer, Katherine V; Blake, Robert; Gray, Kristin; Ford, Keʻala</strong><br>
Abstract: Several studies provide strong evidence for the influence of contextual factors with emotion perception and question the robustness of evidence supporting the universality of emotions; suggesting that the evidence may be an artifact of the method (Gendron, 2017; Gendron et al., 2015; Hoemann et al.&nbsp;2019). Most may agree that emotion perception is a complex interplay of various processes across cultures. In this talk, we present three lessons learned while studying love and hate in Hawaiian culture. This talk is intended to bolster the process of cross-cultural studies of emotion as well as highlight pragmatic considerations when studying emotions in cultures with less representation in the emotion science literature. The three lessons we will discuss are: (1) Identity, (2) History, and (3) Trust. First, identity will be discussed both as a factor of the researchers and in terms of group membership when defining culture. Many places conflate, combine, or provide unwritten rules about cultural group membership that can make identification of population challenging. History will be discussed in relation to the emotions investigated. For example, in Hawaiʻi love and hate have complex meanings that not only have a linguistic translation, but a political and religious translation. This is not unique to Hawaiʻi and being informed about the history of an emotion in an area is important to informing the design of the study. Finally, trust will be discussed in terms of recruitment of participants and the intellectual humility involved in studying concepts that are not traditionally investigated.<br>
&nbsp;<br>
Title: <strong>Associations Between Parent Stress and Emotion Regulation and Child Socioemotional Adjustment in Chinese and Mexican American Immigrant Families</strong><br>
Time: 11:45-12:00<br>
Authors: <strong>Roach, Erika</strong><br>
Abstract: Introduction: Children’s socioemotional adjustment is positively associated with developmental outcomes including peer relationships, academic outcomes, and psychological wellbeing. Research has demonstrated that parental emotion regulation and positive expressivity are positively associated with child emotion regulation, while parent stress and negative expressivity are negatively associated with child emotion regulation. Given the influence of culture on emotion values and expression, these findings warrant investigation on a cross-cultural level. The present study examined relations between parental stress, emotion regulation and emotional expression, and child socioemotional adjustment in 90 parent-child dyads from low-income Chinese American (CA) and Mexican American (MA) immigrant families –two of the largest and fastest growing immigrant populations in the U.S. Method: Participants included 44 CA and 46 MA parents and their children. Parents completed validated measures assessing parental stress, parental emotion regulation, and child socioemotional adjustment, as well as sociodemographic variables. Parental emotion expression during an interactive parent-child puzzle task was coded by bilingual coders of Chinese and Mexican descent. Results: Parental use of cognitive reappraisal was positively associated with child prosocial behavior in CA children and negatively associated with internalizing behavior in MA children and externalizing behavior in CA children. Cognitive reappraisal was not associated with parent distress in either CA or MA parents but was negatively associated with parent-child dysfunctional interaction in CA parents. Interestingly, while expressive suppression was not associated with parent distress in either CA or MA parents, it was positively associated with parent-child dysfunctional interaction in CA dyads and with internalizing behavior in CA children. Conclusion: Immigrant families face unique stressors and it is important to identify potential buffers against poor psychological outcomes in this population. Our findings indicate that culturally appropriate interventions to support parental use of cognitive reappraisal may be beneficial for children’s socioemotional outcomes in CA and MA immigrant families. Furthermore, clinicians might consider supporting parents in weighing the advantages and disadvantages of engaging in expressive suppression, given its association with child socioemotional difficulties.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-1-t6" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-1-t6">Parallel Session 1 : T6</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48f0d50c{}.cl-48ee3b80{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48ef44ee{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48ef4c8c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48ef4c96{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48ef4c97{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48ef4c98{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48ef4ca0{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48ef4ca1{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48f0d50c"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48ef4c8c"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Track</span></p></td><td class="cl-48ef4c96"><p class="cl-48ef44ee"><span class="cl-48ee3b80">T6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48ef4c97"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Type</span></p></td><td class="cl-48ef4c98"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48ef4c97"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Title</span></p></td><td class="cl-48ef4c98"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Law and Order</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48ef4c97"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Time</span></p></td><td class="cl-48ef4c98"><p class="cl-48ef44ee"><span class="cl-48ee3b80">10:45 - 11:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48ef4ca0"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Room</span></p></td><td class="cl-48ef4ca1"><p class="cl-48ef44ee"><span class="cl-48ee3b80">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The ‘Emotional Defendant Effect’: A Systematic Review of Experimental Studies</strong><br>
Time: 10:45-11:00<br>
Authors: <strong>Doorn, Janne van; Kunst, Maarten</strong><br>
Abstract: Emotions such as remorse, regret, or anger are often experienced and expressed by defendants in court. Although a vast amount of qualitative literature has discussed the (un)desirable impact of emotions on sentencing decisions, it is currently unknown what empirical research has revealed about the influence of a defendant’s emotions on legal decisions. Furthermore, where discussion about defendants’ emotions mainly centers around remorse, the role that emotions other than remorse play remains unclear. The goal of the current systematic literature review is to fill these knowledge gaps. More specifically, this review aims to scrutinize the available literature to see whether defendants’ emotions influence guilt and sentencing decisions. As such, this systematic review aims to explore whether an ‘emotional defendant effect’ exists. A synthesis of the literature suggests that the expression of emotion by defendants might be beneficial in terms of guilt and sentencing decisions as compared to showing no emotion. However, this finding does not account for all emotions. Furthermore, the effect of a defendant’s emotionality on legal decisions includes a set of boundary conditions (moderators), and is almost exclusively found in student samples. It is important for legal professionals to be able to gain knowledge about the rich palette of emotions defendants can experience, how they arise, and how they are expressed, to make informed decisions.<br>
&nbsp;<br>
Title: <strong>Rational Anger - Hostile Emotions in the Legal Procedure</strong><br>
Time: 11:00-11:15<br>
Authors: <strong>Bergman Blix, Stina; Törnqvist, Nina</strong><br>
Abstract: Anger plays a peculiar role in modern legal systems. On the one hand, anger strongly links with appraisals of wrongdoing and attributions of blame, forming a core rationale for legal decision-making. On the other hand, anger is associated with irrational behaviour and biased decisions, and thus poses an immediate threat to objectivity and legal professionalism. The forthcoming book that this presentation builds on, explores the role anger plays in the legal process by comparing how anger emerges, evolves and is resolved in the work of judges and prosecutors in Italy, Sweden and USA. Drawing on observations, interviews, and shadowing of legal professionals we demonstrate how anger and other hostile emotions are entangled with legal thought and come into play in legal practices. While anger is often conceived of as spontaneous and irrational, we elucidate the moral, temporal, and framing aspects of legal institutionalized anger that often goes unnoticed and becomes disassociated from its emotional foundation. The interplay between anger and legal processes is of particular interest since a well-functioning judicial system depends on people’s trust in objective and rational justice and, as we will show, anger is both inherent to and threatens this process. The comparative approach allows us to identify differences across countries but also link the way anger is approached, displayed and employed beyond the national emotional regime of each country. The study builds on sociological emotion theory and a social interactionist framework in dialogue with the growing socio-legal field of law and emotions.<br>
&nbsp;<br>
Title: <strong>In Judges We Trust – the Collective Dynamic of Epistemic Independence</strong><br>
Time: 11:15-11:30<br>
Authors: <strong>Törnqvist, Nina; Bergman Blix, Stina</strong><br>
Abstract: Autonomy and independence are key features of legal decision-making. Yet, decision-making in court is fundamentally interactional and collective, both during the information gathering phase of hearings, and in evaluations during deliberations. Depending on legal system and type of court, deliberations can include different constellations of lay judges, jurors, or judge panels. Here, we explore how judges in Sweden organize the decision-making process in order to integrate independent decision-making within a collective social order. In particular, we focus on the emotional undercurrents of the decision-making process — how emotions such as trust, mistrust, doubt, and certainty, guide the interaction rituals involved and motivate rational inferences. Theoretically, the paper departs from an emotive-cognitive judicial framework, which understands emotion and reason as intersecting and continuous. By adding an interactionist perspective, we unveil the collaborative efforts of objective decision-making and critical assessments of evidence. How do legal decision-makers secure independence while seeking consensus? The analysis builds on extensive ethnographic fieldwork in Sweden, including shadowing and interviews with judges as well as observations during court proceedings and deliberations. The paper actualizes the importance of objectivity work as a joint accomplishment and contributes with a nuanced account of how the decision-making process unfolds in the criminal justice process.<br>
&nbsp;<br>
Title: <strong>Social Stress, Support, and the Reproduction of Biased U.S. Policing</strong><br>
Time: 11:30-11:45<br>
Authors: <strong>Powelson, Connor</strong><br>
Abstract: Studies of police emotions often focus on the management of feelings associated with traumatic, tragic, and dangerous events. However, a growing source of stress for police, particularly in the U.S., comes from increasing public outcries for accountability and reform. Examining how officers’ social identities and emotional workplace experiences are reciprocally related to perceptions of public scrutiny, the present study considers how interactions between emotion cultures shape organizational practices. The identities and feelings of police and nonpolice weave unexpected networks of friends and foes and guide how each should be treated. Drawing upon more than 60 in-depth interviews conducted with police officers before, during, and after the George Floyd protests (2020), I explore how officer social identities and perceptions of the protests pattern the types of social stressors they are exposed to and the social support that is available to them. Findings reveal how relations to emotion cultures pattern emotional inequalities. Emotion processes reproduce racialized and gendered status hierarchies within and beyond the policing institution and contribute to shared understandings of police as biased. Ultimately, this work speaks to an understanding of police agencies as racialized organizations that maintain an emotional substructure that patterns inequitable rules, resources, and their justifications (Ray 2019).<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t1" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t1">Parallel Session 2 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-48facc1a{}.cl-48f83e50{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-48f94322{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-48f94b2e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48f94b38{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48f94b39{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48f94b42{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48f94b43{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-48f94b44{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-48facc1a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-48f94b2e"><p class="cl-48f94322"><span class="cl-48f83e50">Track</span></p></td><td class="cl-48f94b38"><p class="cl-48f94322"><span class="cl-48f83e50">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48f94b39"><p class="cl-48f94322"><span class="cl-48f83e50">Type</span></p></td><td class="cl-48f94b42"><p class="cl-48f94322"><span class="cl-48f83e50">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48f94b39"><p class="cl-48f94322"><span class="cl-48f83e50">Title</span></p></td><td class="cl-48f94b42"><p class="cl-48f94322"><span class="cl-48f83e50">Situational, Social, and Cultural Moderators of Emotion Regulation Success</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48f94b39"><p class="cl-48f94322"><span class="cl-48f83e50">Time</span></p></td><td class="cl-48f94b42"><p class="cl-48f94322"><span class="cl-48f83e50">13:30 - 14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48f94b39"><p class="cl-48f94322"><span class="cl-48f83e50">Room</span></p></td><td class="cl-48f94b42"><p class="cl-48f94322"><span class="cl-48f83e50">Whitla Hall</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-48f94b43"><p class="cl-48f94322"><span class="cl-48f83e50">Abstract</span></p></td><td class="cl-48f94b44"><p class="cl-48f94322"><span class="cl-48f83e50">Emotion regulation scholars generally agree that whether or not a particular regulatory strategy was deployed is less important than the degree of effectiveness in modulating emotions in the moment. Thus, attention has turned toward a better understanding of the relative success of using one or more strategies beyond frequency of use. The presentations in this symposium are all attempts to advance our understanding of how success may vary as a function of situational (intensity, controllability, motivations), social, and cross-cultural factors. Presentation 1 begins by examining success in two ways and how this is impacted by using multiple regulation strategies in combination. Presentation 2 examines one strategy, expressive suppression more thoroughly to reveal that motivation to protect self and other both predicted regulatory success. The next 2 presentations consider strategy-situation fit and regulatory flexibility. Presentation 3 found that both strategy type and situational characteristics impact success, but not the interaction of the two. Presentation 4 combines four studies that provide evidence challenging the theoretical expectation that strategy-situation fit and flexibility result in better regulation. Presentation 5 expands this line of inquiry to compare strategy use and success across 51 countries. Taken together, these studies illuminate various aspects of successful emotion regulation in ways that both add to the body of empirical findings in the field as well as work toward improvements in theory.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Hedonic and Perceived Success of Adolescent Emotion Regulation as a Function of Emotion Intensity and Polyregulation Repertoires</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Tom Hollenstein</strong><br>
Abstract: Unlike adult emotion regulation strategy research, adolescent research remains limited and oversimplified. Specifically, there has been little consideration of the relative success of various strategies. Further, despite research on strategy repertoires, there have been no examinations of polyregulation, or the use of multiple strategies during the same emotional event. Hence, we do not yet understand the maturation of these process or their effectiveness. As a first step in this direction, we present experience sampling data on 154 13–15-year-olds who provided 4 reports/day for 14 days (6216 observations) on: emotional intensity of most negative event since last prompt, regulatory effort for each of 6 strategies (1-10 scale), current emotional intensity, and Perceived Success (1-10). Hedonic Success was calculated as initial minus current intensity. Polyregulation was calculated as a Sum Index (sum of 6 ratings). Correlations between Hedonic and Perceived Success were .19 (within) and .26 (between), indicating these indices may reflect different aspects of success. We ran 2 multilevel mediation models with Initial Intensity as predictor, Sum Index as mediator, and either Hedonic or Perceived Success as outcome. For Perceived Success, there was a within-level indirect effect, but no between-level indirect effect. For Hedonic Success there was both a between-level and within-level indirect effect of the Sum index. Findings indicate youth distinguish between changes in emotional intensity and how they perceive their relative success (i.e., not escalating may be perceived as successful). Importantly, polyregulation seems to have an impact on both hedonic change and perceptions of success.<br>
&nbsp;<br>
Title: <strong>What is the Relationship Between Emotion Intensity, Motivation, and Expressive Suppression Success?</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Megan Wylie</strong><br>
Abstract: Successful expressive suppression (ES) has been linked to emotion intensity, as more intense emotions are more difficult to suppress. However, other situational aspects of ES use, such as motivation, might also play an important role in ES success. We considered two motivational possibilities: motivation to protect oneself (e.g., from judgements about emotions) and motivation to protect others (e.g., from hurt feelings). Greater ES success might be linked to greater motivation overall, but also more closely to a specific type of motivation. The primary aim of this study was to use experience- sampling to capture situational changes in emotion intensity and two ES motivations as predictors of ES success. Undergraduates (N = 156, 92.3% women) were prompted on their smartphones to complete four ESM questionnaires per day for 10 days, including questions about emotion intensity, motivation (to protect self and other), and success for negative and positive events. Multilevel models revealed that for negative events, emotion intensity did not predict success, but motivation to protect self (b = .09, p &lt; .001) and protect others (b = .16, p &lt; .001), and the interaction between emotion intensity and protect others (b = -.03, p = .02) predicted success. For positive events, emotion intensity (b = .13, p &lt; .001), and motivation to protect self (b = .08, p = .02) and protect others (b = .13, p &lt; .001) predicted success. These findings expand our understanding of ES use and highlight the role that motivation plays in ES success across different contexts.<br>
&nbsp;<br>
Title: <strong>A Matter of Fit? Investigating the Effects of Strategy-Situation Fit on Perceived Emotion Regulation Success</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Tabea Springstein</strong><br>
Abstract: Research on emotion regulation (ER) flexibility has shown that using ER strategies in situation dependent ways might be beneficial for long-term well-being. Theories on ER flexibility propose that flexible individuals are those who select ER strategies that help them successfully regulate their emotions by achieving their situation-specific momentary ER goals. ER is driven by goals to up- or down-regulate positive or negative emotions, sometimes for specific superior motives (e.g., to make a good impression). In daily life, ER success is often assessed by whether positive emotions are maximized and negative emotions are minimized, which can miss occasions in which goals do not center on maximizing hedonic benefits. Assessing people’s perceptions of their ER success more closely captures whether or not their idiosyncratic ER goals were achieved and helps thoroughly test the momentary benefits of situation-specific ER. Therefore, our study investigated whether individuals report being more or less successful in their momentary ER when the strategy they select corresponds to situational demands. In an experience sampling study with 216 individuals, we asked 7 times a day for 14 consecutive days about use of 8 ER strategies, 9 situational appraisals, and perceived ER success over the past 2 hours. While some predicted effects emerged, such as minimizing being more detrimental for ER success in controllable (vs.&nbsp;uncontrollable) situations, results largely indicate that ER success depends on strategies or situations but not on their interactions. Our results will be discussed in the context of short-term versus long-term consequences of ER and ER flexibility.<br>
&nbsp;<br>
Title: <strong>Do People Regulate Their Emotions Flexibly in Daily Life and Does It Matter? Evidence from Four Intensive Longitudinal Studies</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Peter Koval</strong><br>
Abstract: Recent emotion regulation theories have eschewed traditional distinctions between ‘healthy’ and ‘unhealthy’ strategies. Instead, many scholars consider flexibility as the basis of optimal emotion regulation. A key component of regulatory flexibility involves context-sensitive use of regulation strategies to match situational demands: strategy- situation fit. We examined whether people match emotion-regulation efforts to daily contexts and the proposed benefits of strategy-situation fit. We conducted a 14-day diary study (N=254), two observational experience-sampling studies (Ns=179 &amp; 123), and an experimental experience-sampling study (N=181), in which participants reported momentary/daily affect, use of several emotion-regulation strategies, and appraisals of events/contexts (Total N=737). Analyses focussed on strategy-situation fit for (a) reappraisal with controllability; (b) reappraisal and distraction with intensity; and (c) expressive suppression and social sharing with social support. Regulation strategies varied systematically across contexts, although not always as hypothesized. As predicted, greater social support predicted less suppression and more sharing. However, contrary to theory, distraction did not increase in more intense contexts, and reappraisal did not increase in more intense or more controllable situations. Further, we found virtually no evidence for context-dependent effects of regulation strategies on affect, or associations between individual differences in strategy-situation fit and well-being. Findings suggest that although people’s use of some emotion-regulation strategies may be context-dependent, this does not always match theory. Further, context-sensitive strategy use does not appear to influence either short-term affective consequences, or to have longer-term advantages for well-being. Overall, findings cast doubt on the theorized benefits of strategy-situation fit and, more generally of flexible emotion regulation.<br>
&nbsp;<br>
Title: <strong>Emotion Regulation and Wellbeing: A Cross-Cultural Study Across 51 Countries</strong><br>
Time: 14:30-14:45<br>
Authors: <strong>Disa Sauter</strong><br>
Abstract: The ability to effectively manage negative emotions is crucial for healthy psychological functioning. However, knowledge on how emotion regulation relates to wellbeing is primarily based on lab studies, focused on a subset of emotion regulation strategies, and conducted among individuals from a very limited range of cultures. Here, we report the most comprehensive study to date of the relationship between emotion regulation and wellbeing. We examined the unique contributions of the use of six key emotion regulation strategies to wellbeing among 23,865 participants from 51 countries, using a wide variety of cultural orientations. In line with our pre-registered hypotheses, acceptance and reappraisal predicted higher wellbeing, while rumination and suppression predicted lower wellbeing. Social sharing and distraction yielded more mixed findings. Acceptance and rumination were particularly strong predictors of wellbeing, thus emerging as the promise and peril of emotion regulation. These effects were largely replicated in two separate representative samples (N = 2000). Finally, there was a great degree of cross-cultural consistency in both the use of emotion regulation strategies, and in their associations with wellbeing. These findings demonstrate that emotion regulation strategies – particularly acceptance and rumination – are key to wellbeing across cultures.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t2" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t2">Parallel Session 2 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49055018{}.cl-490228c0{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49032b80{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-490332e2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490332ec{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490332ed{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490332ee{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490332f6{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490332f7{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49055018"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-490332e2"><p class="cl-49032b80"><span class="cl-490228c0">Track</span></p></td><td class="cl-490332ec"><p class="cl-49032b80"><span class="cl-490228c0">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490332ed"><p class="cl-49032b80"><span class="cl-490228c0">Type</span></p></td><td class="cl-490332ee"><p class="cl-49032b80"><span class="cl-490228c0">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490332ed"><p class="cl-49032b80"><span class="cl-490228c0">Title</span></p></td><td class="cl-490332ee"><p class="cl-49032b80"><span class="cl-490228c0">Advancing Emotional Intelligence Research: From Human Hypersensitivity to Artificial Intelligence</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490332ed"><p class="cl-49032b80"><span class="cl-490228c0">Time</span></p></td><td class="cl-490332ee"><p class="cl-49032b80"><span class="cl-490228c0">13:30 - 14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490332ed"><p class="cl-49032b80"><span class="cl-490228c0">Room</span></p></td><td class="cl-490332ee"><p class="cl-49032b80"><span class="cl-490228c0">Bann: PFC/0G/024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490332f6"><p class="cl-49032b80"><span class="cl-490228c0">Abstract</span></p></td><td class="cl-490332f7"><p class="cl-49032b80"><span class="cl-490228c0">These five talks provide a coherent and comprehensive view of recent advancements in the study of Emotional Intelligence (EI) and suggest critical directions for future research. Presenters will discuss multiple competencies that are part of ability-EI models, providing both original theoretical reflections (notably, the relationship between EI and hypersensitivity, as well as the role of social context in emotion recognition) and innovative ideas in the measurement of EI, with the introduction of new theory-driven context-specific measures, and testing the potential contribution of artificial intelligence. The first two talks present studies that test the original theoretical hypothesis that high EI individuals are characterized by hypersensitivity toward emotional stimuli; more precisely, these studies investigate how EI relates to the perceptual threshold for identifying emotional expressions and how it influences emotional mimicry. Their results are discussed in the context of the hypersensitivity hypothesis and the implications for the conceptualization and applications of EI. The symposium continues by deepening on the role of the social context on emotion recognition ability (ERA), and how ERA can predict synchronization of nonverbal behavior during dyadic interactions. The last two presentations expand the focus by suggesting new directions for the measurement of EI. The fourth talk introduces an innovative instrument for measuring EI that strongly integrates emotion theory and applies to a specific and understudied real-world context: hospitality. The last talk presents a series of surprising studies that show how well artificial intelligence can perform emotionally intelligent tasks and what this may imply for the future of EI.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotional Intelligence and Threshold of Perception of Emotional Expressions: Further Evidence of Emotional Hypersensitivity</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Marina Fiori, Christelle Gillioz, &amp; Maroussia Nicolet-Dit-Félix</strong><br>
Abstract: A recent theoretical framework posits that emotional intelligence (EI) is profoundly shaped by an individual’s responsiveness to emotional stimuli, suggesting that high EI is contingent upon heightened emotional sensitivity. Aligned with this idea, initial evidence show that high EI individuals have an attentional bias towards emotional faces, and that they provide more polarized perceptions of emotional expressions. The current study aims to test an additional feature of the hypersensitivity of high EI individuals, namely the perceptual threshold for effective discrimination of emotional expressions. By manipulating the quantity of signal available in static and dynamic faces, we hypothesized that the signal threshold needed to correctly categorize an expression would be lower for high EI individuals. One hundred three participants executed an emotion recognition task in which the six basic emotions were shown with varying noise applied on the face. For each participant, a detection threshold was computed, which corresponds to an evaluation of the percentage of information needed to recognize the face with 44% accuracy (16% = chance). Linear mixed effects models were employed to predict the perception threshold. Preliminary results show a lower threshold of accurate discrimination of blurred emotional expressions in high EI individuals. Effects appear stronger for the emotion recognition facet, marginally significant for emotion understanding, and significant for emotion management in interaction with different emotions. Results are discussed in light of the hypersensitivity hypothesis according to which EI is greatly influenced by one’s level of emotional sensitivity.<br>
&nbsp;<br>
Title: <strong>Is Emotional Intelligence Associated with more Reaction to Emotions? a Study on Mimicry and Emotional Contagion.</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Christelle Gillioz, Maroussia Nicolet-Dit-Félix, &amp; Marina Fiori</strong><br>
Abstract: We investigated whether and how emotional intelligence (EI) influences emotional contagion and mimicry. Participants (144 females) watched positive and negative videos in three different conditions: with no specific instructions (natural condition), with the instructions to put themselves in the character’s shoes (internal condition) and with the instructions to distinguish themselves from the character (external condition). Participants took part in all conditions. The activity of the corrugator supercilii and zygomaticus major muscles was recorded and after each video, the participants reported the arousal and valence corresponding to their emotion during the video. The EI facets emotion recognition (ER), emotion understanding (EU), and emotion management (EM) were measured. Participants’ arousal and mimicry increased in the internal condition compared to the natural condition and then decreased in the external condition. Although there was no effect of EI on reported arousal and valence, EI, specifically EU and EM, influenced mimicry during the task. In the natural and internal conditions, EU predicted a greater difference in zygomaticus activation between positive and negative videos, suggesting that individuals high on this EI facet may react more to emotion of others. In all conditions, EM predicted less corrugator activation when watching negative videos, suggesting that individuals high on this EI facet may spontaneously regulate their negative emotions. Results will be discussed according to the hypersensitivity hypothesis, which states that EI enhances emotional experience.<br>
&nbsp;<br>
Title: <strong>Decoding Social Dynamics: The Impact of Emotion Recognition Ability on Nonverbal Behavior in Positive and Negative Interactions</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Nils R. Sommer &amp; Katja Schlegel</strong><br>
Abstract: Emotion recognition ability (ERA), a key component of emotional intelligence, is expected to be beneficial for managing social interactions. Previous studies have shown that higher ERA is linked to more facial mimicry, producing more accurate nonverbal expressions, and better social interaction outcomes. However, limited research has explored ERA’s impact on nonverbal behavior in social contexts. Our study addresses this gap by investigating ERA within positive and negative social interactions involving friendly and unfriendly confederates, respectively. We employed three measures to evaluate participants’ nonverbal behavior: Observer ratings, computerized facial action recognition using OpenFace, and the synchrony of movements between participants and confederates (nonverbal synchrony). We hypothesized that individuals with higher ERA would exhibit greater overall nonverbal synchrony and demonstrate more positive facial expressivity in positive interactions and increased negative facial expressivity in negative interactions due to heightened emotional mimicry. One hundred fifty participants took part in videotaped interactions with either friendly or unfriendly confederates in the laboratory. Our results revealed that higher ERA predicted increased nonverbal synchrony between interactants. However, ERA did not significantly influence observer-rated expressivity in positive or negative interactions. This study contributes essential evidence to enhance our understanding of the relationship between ERA and nonverbal behavior in social interactions, shedding light on the nuanced dynamics of emotional intelligence in social contexts.<br>
&nbsp;<br>
Title: <strong>Putting the HEART to Use: A New Assessment of Emotional Competencies for Hospitality.</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Juliane Völker &amp; Marcello Mortillaro</strong><br>
Abstract: Endeavours to measure emotional intelligence (EI) in workplace contexts have flourished over the past years, yet no measure is so far available that is specialised to hospitality workplaces. Past research has shown that fashioning an assessment tool to its intended context is crucial. Therefore, we created a test of emotional competencies for hospitality employees: the HEART (Hospitality’s Emotional &amp; Affective Resources Test). Founded on ability EI theory, we used a multimodal and situational judgment-based test design to assess four emotional competencies: emotion recognition, understanding, regulation of own emotions, and management of emotions of others. We created original, realistic scenario-based items from interviews with 47 industry professionals and recorded new videos with professional actors. We conducted seven validation studies (total N = 699) with samples of hospitality students and professionals in Germany, Switzerland, and the US. HEART modules were sufficiently consistent for a performance-based test (mean McDonald’s ω = .527 on the single modules across studies, mean ω = .713 for the whole test). Performance on the HEART was strongly associated with other measures of EI (STEM-B, STEU-B, WLEIS) and moderately associated with cognitive intelligence (CFT). We found weak to moderate associations with self-reported adaptive emotion regulation (CERQ) and Conscientiousness, Agreeableness, and Openness (TIPI). A strong association was found with job satisfaction. Results will be discussed in the light of future applications and refinements of the test.<br>
&nbsp;<br>
Title: <strong>Exploring ChatGPT’s Performance in Solving and Creating Emotional Intelligence Tests</strong><br>
Time: 14:30-14:45<br>
Authors: <strong>Katja Schlegel, Nils R. Sommer, &amp; Marcello Mortillaro</strong><br>
Abstract: Despite their expertise in various knowledge domains, Large Language Models (LLMs) such as ChatGPT are often believed to lack empathy and emotional intelligence (EI). This study aimed to explore this assumption by assessing ChatGPT’s performance in solving and creating test items for two components of EI – emotion understanding (identifying emotions in vignettes) and emotion management (identifying the most effective way to regulate an emotion in oneself or others). Initially, ChatGPT (GPT-4) outperformed human participants on the Geneva Emotion Knowledge Test (GEMOK-Blends), Situational Tests of Emotion Understanding (STEU) and Emotion Management (STEM) and Geneva Emotional Competence Test (GECo – Emotion Regulation and Emotion Management subtests), correctly solving 86% of items versus the human average of 56% in the original validation studies. In a second step, ChatGPT generated new items for each of these five tests. Across five studies with 467 participants, both the original and ChatGPT-created tests were compared. Results showed that the original and ChatGPT-created versions were similar in difficulty (62% vs.&nbsp;63% correct) and reliability (mean Cronbach’s alpha = .54 vs.&nbsp;.50). Both versions were substantially correlated (mean r =.44) and perceived as equally clear and realistic, although the item content of the ChatGPT- created test versions was judged as less diverse (small effect). The original tests had marginally stronger correlations with external EI and vocabulary measures. These results demonstrate ChatGPT’s capacity to solve and create EI test items effectively, challenging the notion that LLMs lack human interaction skills.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t3" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t3">Parallel Session 2 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-490f4348{}.cl-490c08f4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-490d1262{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-490d1a0a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490d1a14{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490d1a15{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490d1a1e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490d1a1f{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-490d1a20{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-490f4348"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-490d1a0a"><p class="cl-490d1262"><span class="cl-490c08f4">Track</span></p></td><td class="cl-490d1a14"><p class="cl-490d1262"><span class="cl-490c08f4">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490d1a15"><p class="cl-490d1262"><span class="cl-490c08f4">Type</span></p></td><td class="cl-490d1a1e"><p class="cl-490d1262"><span class="cl-490c08f4">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490d1a15"><p class="cl-490d1262"><span class="cl-490c08f4">Title</span></p></td><td class="cl-490d1a1e"><p class="cl-490d1262"><span class="cl-490c08f4">Virtual-based training programs in clinical domains</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490d1a15"><p class="cl-490d1262"><span class="cl-490c08f4">Discussant</span></p></td><td class="cl-490d1a1e"><p class="cl-490d1262"><span class="cl-490c08f4">Katja Kölkebeck</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490d1a15"><p class="cl-490d1262"><span class="cl-490c08f4">Time</span></p></td><td class="cl-490d1a1e"><p class="cl-490d1262"><span class="cl-490c08f4">13:30 - 14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490d1a15"><p class="cl-490d1262"><span class="cl-490c08f4">Room</span></p></td><td class="cl-490d1a1e"><p class="cl-490d1262"><span class="cl-490c08f4">Foyle: PFC/0G/007</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-490d1a1f"><p class="cl-490d1262"><span class="cl-490c08f4">Abstract</span></p></td><td class="cl-490d1a20"><p class="cl-490d1262"><span class="cl-490c08f4">With advances in human-computer interaction technology, many recent applications can be very useful in clinical domains. For example, virtual agents that detect people‚Äôs health problems early and could help them find relevant clinical practices, or virtual reality exposure therapy that trains people with phobias to face their fear gradually in a safe environment. This symposium consists of four presentations related to this topic and it will be followed with a discussion. We will first present the research findings related to emotion in clinical groups. What specific traits do patients have? How avatars can be used in studying emotion processing in patients? Second, we will present practical findings on how people perceive virtual human‚Äôs emotional expressions and the influence of social anxiety. Third, we will present a new project about the development of an emotion training tool that makes use of non-acted emotion expression data. As the final presentation, we will show virtual reality applications for vulnerable groups, including how they could be designed and the challenges that exist when researching such applications. After all the presentations, we will have a discussion session where we could discuss the conclusions and future research, and answer some final questions.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Avatars in the Study of Emotion Processing in Patients with Mental Illnesses</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Katja Kölkebeck</strong><br>
Abstract: In people with mental illness, interaction problems can frequently be identified. It was theorized that reasons for problems in social interaction in patients with mental illness can be found in the disturbed perception and processing as well as imitation (mimicry) of body signals. In the last years, specifically for people with autism, avatars have been used to create more ecologically valid paradigms to investigate interaction problems including the measurement of bodily signals in reaction to the complex interactions. We will present a study where we examined patients with social anxiety disorder (SAD) as well as autism spectrum disorders (ASD). Here, marker signals for social exchange during interactional tasks (emotion recognition, trust/investment game) were measured: muscle movements in the face using an electromyography (EMG) examination, pupil size and skin conductance of the participants. This included also the use of an avatar in a social task. Moreover, we will present an ongoing project that uses avatars to create environments for social interaction as a means to gather biological signals to identify specific markers for the autistic spectrum as compared to other mental illnesses. Our research serves to identify theoretical foundations of social interaction and to test new theories on the connection between body signals and the development of attachment, but in the long term also to improve the way we deal with patients and train their social interaction skills.<br>
&nbsp;<br>
Title: <strong>Social Anxiety and the Perception of Virtual Human’s Emotional Expressions</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Evania Fasya, Esther van den Bos, Dirk Heylen, Mariska Kret</strong><br>
Abstract: There are increasing applications of virtual humans, such as in healthcare or virtual assistance, which require humans to interact with virtual humans. This then raises questions; how do people perceive the virtual human’s emotional expressions? Do individual differences such as social anxiety play a role in the interaction? In this talk, we present a few studies that are related to these questions. We investigate how people perceive the virtual human’s emotional expressions, in terms of mimicry, liking, and trust. We also explore the social effects of subtle emotional cues such as pupil dilations. We made use of different experimental tasks; a listening task where participants listened and watched virtual humans telling a story, and a speaking task where participants gave a speech to a virtual audience. In the speaking task, we investigate how the virtual audience’s condition, such as encouraging or critical, could influence the participant’s evaluations of the virtual audience and anxiety during the task.<br>
&nbsp;<br>
Title: <strong>An Interactive Mobile Emotion Training Tool</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Diego Arize, Mariska Kret</strong><br>
Abstract: Various training applications have extensively explored emotional expressions. However, there exists a notable gap regarding the nuanced expressions encountered in everyday life especially in relation to subtle emotional cues. Such subtle emotional indicators as pupil dilation or blushing, present considerable challenges in emotion recognition, particularly for individuals with social anxiety and autism spectrum disorders who often encounter obstacles in comprehending emotions within real- world contexts. In this project, we aim to develop a tool that can teach people to recognize subtle, real- world expressions that will help them understand and trust others better. We plan to train the users on emotion processing in three steps: emotion regulation, emotion recognition, and interoception, so they can not only understand their emotions, but other people’s ones, and their reflections. It makes use of Machine Learning models that help identify users’ emotional state during a training session. This tool is catered as a mobile serious game which targets a broad group of users, including patients, as they could benefit from online help as a first step to practicing social skills in a safe home environment and at their own pace. Next to the functionalities and flow, we will also present the development challenges and some preliminary results from our pilot study.<br>
&nbsp;<br>
Title: <strong>Virtual Reality Applications for Vulnerable People</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Dirk Heylen</strong><br>
Abstract: In many of our studies on virtual reality and other interfaces such as robots for teaching, training and behavior change, we have often dealt with special, vulnerable groups such as young children on the autism spectrum, elderly diagnosed with Alzheimer, low-literate people with a substance addiction, or people suffering from various forms of social anxieties. Designing and researching VR applications for such groups of people poses various challenges. One can think of the design, the on-boarding, consent, the way questionnaires need to be formulated or other ways to collect data, but also other ethical aspects of data collection and the analysis. In this talk we present these challenges by illustrating them with some of the cases that we have been studying.<br>
&nbsp;<br>
Title: <strong>Discussion</strong><br>
Time: 14:30-14:45<br>
Authors: <strong>Kölkebeck, Katja</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t4" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t4">Parallel Session 2 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4919313c{}.cl-4915fe9a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4917a150{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4917a95c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4917a966{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4917a967{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4917a968{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4917a969{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4917a970{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4919313c"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4917a95c"><p class="cl-4917a150"><span class="cl-4915fe9a">Track</span></p></td><td class="cl-4917a966"><p class="cl-4917a150"><span class="cl-4915fe9a">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4917a967"><p class="cl-4917a150"><span class="cl-4915fe9a">Type</span></p></td><td class="cl-4917a968"><p class="cl-4917a150"><span class="cl-4915fe9a">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4917a967"><p class="cl-4917a150"><span class="cl-4915fe9a">Title</span></p></td><td class="cl-4917a968"><p class="cl-4917a150"><span class="cl-4915fe9a">Expression and Perception</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4917a967"><p class="cl-4917a150"><span class="cl-4915fe9a">Time</span></p></td><td class="cl-4917a968"><p class="cl-4917a150"><span class="cl-4915fe9a">13:30 - 14:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4917a969"><p class="cl-4917a150"><span class="cl-4915fe9a">Room</span></p></td><td class="cl-4917a970"><p class="cl-4917a150"><span class="cl-4915fe9a">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>In Two Minds but One Heart: Conceptualization of Basic Emotions in Bilingual Minds.</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Bąk, Halszka K</strong><br>
Abstract: In recent years there has been a number of studies into the semantic structure of emotion concepts as lexicalized across languages but focused mainly on native monolingual populations. Our understanding of how bi- and multilingual individuals conceptualize specific emotions (rather than generalized affect) is limited – even though recent estimates show that more than half of the global population is bilingual. This ongoing study investigates the conceptualization of basic emotions in Polish-English bilinguals in both their languages. The conceptualizations are measured using subjective evaluations of words denoting basic emotions using common affective (valence, arousal, dominance) and cognitive (concreteness, imageability, context availability) dimensions on 9-point Likert scales. Bilingual Polish-English participants evaluate words denoting basic emotions (anger, disgust, fear, sadness, joy, surprise) in Polish and in English on either the affective or the cognitive dimensions. The evaluations are compared against baseline conceptualizations from monolingual populations. Preliminary results suggest that bilinguals conceptualize basic emotions as lexicalized in Polish and in English significantly differently on the cognitive but not the affective dimensions. Furthermore, the bilinguals’ conceptualizations, even those evaluated in their native Polish, differ from those of the monolingual controls. Intriguingly, these early results show that bilinguals also conceptualize emotions lexicalized as cognates (words which derive from the same lexical root and convey similar meanings in both languages) differently in Polish and in English. Combined, these results suggest that the differences in how emotions are conceptualized by bilinguals may be driven by the cognitive rather than the affective components of meaning.<br>
&nbsp;<br>
Title: <strong>A Contextualized Emotion Perception Assessment Relates to Well-Being: Social Interaction as a Mediator</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Kafetsios, Konstantinos; Hess, Ursula; Dostal, Daniel; Seitl, Martin; Sulejmanov, Filip; Hypsova, Petra; Hareli, Shlomo; Consortium, the PERWELL</strong><br>
Abstract: Emotion Recognition Accuracy (ERA), the accurate assessment of others’ emotional expressions and feelings, is a core human skill which is crucial for the regulation of relationships and for social functioning more generally (Fischer &amp; Manstead, 2008; Niedenthal &amp; Brauer, 2012). Yet, evidence documenting the social interaction consequences and well-being effects of emotion perception is sparse. In two studies we demonstrate that the Assessment of Contextualized Emotions, an ERA method that involves social context, multiple emotions and the simultaneous distinguishing between accuracy and bias is meaningfully related with well-being and social interaction quality. In an online survey across twelve cultures that utilized the ACE-short (N = 2400, ages 18-36), accuracy was associated with higher well-being (Diener et al., 2009) and life satisfaction and higher bias was associated with more loneliness. In a second, social interaction event sampling study in Germany (N = 115), that utilized the full version of the ACE, a composite index of well-being -comprising life satisfaction, Diener’s well-being measure and loneliness- was positively associated with ACE accuracy and negatively associated with ACE bias. These effects were partially mediated by social interaction quality in social and personal relationships the week preceding the well-being assessments. In both studies a standard hit rates assessment of ERA and the ACE did not unveil meaningful relationships with well-being or social interaction quality. The studies advance our understanding of ERA, and open up the possibility to pose and empirically test new questions about ERAs social functions.<br>
&nbsp;<br>
Title: <strong>How Ethnicity and Terminology Shape Attitudes Toward People Expressing Emotions</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Gonzalez, Manuel F; Cohen-Charash, Yochi</strong><br>
Abstract: We examined how terminology influences attitudes toward emotions and people expressing them, and whether one’s cultural origin moderates these influences. People often label emotions as “positive” and “negative,” which, we suggest, creates value-judgments in favor of emotions described as “positive” and against emotions described as “negative,” in comparison to using other descriptive terminologies or not using such descriptive at all. We theorize that terminology shapes these value-judgments through mechanisms such as connotations (e.g., “positive” is a synonym for “good”) and priming. Furthermore, one’s cultural origin can shape (a) the meanings, associations, and connotations of words, and (b) how one perceives and understands emotions. Thus, cultural origin influences associations and connotations, and thus might moderate the influence of terminology on perception. We compared the influence of terminology on perceptions of pride (generally more valued among non-Asians) and guilt (generally more valued among Asians). An ethnically diverse sample of 185 US-based participants read definitions of pride and guilt, described as either “positive”/“negative”, “pleasant”/“unpleasant”, or using neither descriptor. We found that cultural origin (Asian/non-Asian) significantly interacted with terminology, such that Asian participants perceived proud people as more competent and warmer when pride was discussed using no terminology, relative to using “pleasant” or “positive.” However, non-Asian participants’ attitudes were unaffected by terminology. Terminology and cultural origin did not influence perceptions of guilt. Cultural origin may thus represent an important boundary condition for terminology’s effects on value-judgments toward emotions and those expressing them.<br>
&nbsp;<br>
Title: <strong>JADMEED: Multimodal Emotional Expression Database for Cross-Cultural Research and Affective Computing</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Tanaka, Akihiro; Takagi, Sachiko; Huis In ’t Veld, Elisabeth; de Gelder, Beatrice</strong><br>
Abstract: Emotions are expressed through different sensory channels, such as a face and voice, and are perceived by integrating information from these channels in natural settings. Previous studies reported considerable cultural differences in the expression and the perception of emotion from facial and vocal channels. Recently, several databases have been developed which include both facial and vocal expressions mainly from native speakers of Western languages. However, there have been no databases which include dynamic facial and vocal expressions from multiple cultures/languages, although some include vocal stimuli from multiple languages. We introduce JADMEED (Japanese and Dutch Multimodal Emotional Expressions Database), a new audiovisual database of dynamic emotional expressions of faces and voices, which includes expressions from both East Asian (Japanese) and Western (Dutch) language speakers. JADMEED includes audiovisual movies, which are recorded from eight Japanese and eight Dutch speakers, speaking four semantically neutral short phrases with six basic emotions plus neutral. Facial and vocal expressions were separately validated by Japanese and Dutch students. Results showed that accuracies for facial expressions were above 60% except for fear in both Japanese and Dutch expressions. Although the facial and vocal expressions were recorded simultaneously, accuracies for vocal expressions were not so high as facial expressions. We expect JADMEED to be a useful open resource for researchers comparing between facial and vocal emotion perception, and those comparing unisensory and/or multisensory emotion perception between cultures in the field of psychology and neuroscience, as well as those in the field of affective computing.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t5" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t5">Parallel Session 2 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49232cbe{}.cl-49207fe6{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49219e44{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4921a5e2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4921a5e3{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4921a5e4{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4921a5ec{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4921a5ed{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4921a5ee{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49232cbe"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4921a5e2"><p class="cl-49219e44"><span class="cl-49207fe6">Track</span></p></td><td class="cl-4921a5e3"><p class="cl-49219e44"><span class="cl-49207fe6">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4921a5e4"><p class="cl-49219e44"><span class="cl-49207fe6">Type</span></p></td><td class="cl-4921a5ec"><p class="cl-49219e44"><span class="cl-49207fe6">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4921a5e4"><p class="cl-49219e44"><span class="cl-49207fe6">Title</span></p></td><td class="cl-4921a5ec"><p class="cl-49219e44"><span class="cl-49207fe6">Child and Parent</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4921a5e4"><p class="cl-49219e44"><span class="cl-49207fe6">Time</span></p></td><td class="cl-4921a5ec"><p class="cl-49219e44"><span class="cl-49207fe6">13:30 - 14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4921a5ed"><p class="cl-49219e44"><span class="cl-49207fe6">Room</span></p></td><td class="cl-4921a5ee"><p class="cl-49219e44"><span class="cl-49207fe6">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The Role of Childhood Maltreatment on Maternal Cardiovascular Reactivity to Child Facial Expressions of Emotions</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Pétrin, Rachel; Bérubé, Annie; St-Pierre, Émilie; Blais, Caroline</strong><br>
Abstract: Childhood maltreatment experiences alter parents’ physiological responses to children’s emotional cues. Previous studies have explored parents’ cardiovascular reactions to children’s vocalized expressions of emotions, but little is known about their responses to children’s facial expressions of emotions. This study aimed to determine if viewing facial expressions of emotions in children induces cardiovascular changes in mothers, and whether this differs based on childhood maltreatment. A total of 79 mothers were recruited from community organizations that provide services to vulnerable families and from the university. Childhood maltreatment experiences were measured using the Childhood Trauma Questionnaire. Participants underwent a task during which they viewed a landscape video as a baseline, and images of children’s faces displaying various emotions. Electrocardiogram signals were recorded, and heart rate variability (HRV) was used as an indicator of parasympathetic reactivity. Two distinct physiological profiles were observed in mothers: increased or decreased HRV in response to children’s facial expressions of emotions. Mothers who had experienced childhood emotional abuse were more likely to exhibit an increased HRV when watching children’s emotional facial expressions, which could indicate lower levels of behavioral engagement. Physiological dysregulation caused by childhood maltreatment may pose a risk for maladaptive parenting behaviors. This study emphasizes the importance of providing targeted interventions to help parents, particularly those with histories of childhood maltreatment, manage their physiological and behavioral responses to facial expressions of emotions in children.<br>
&nbsp;<br>
Title: <strong>The Role of Emotion Recognition and Alexithymia on the Relationship Between a History of Maltreatment and Parental Sensitivity.</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Martel, Marguerite; Bérubé, Annie</strong><br>
Abstract: Child maltreatment is a global crisis, with estimates indicating that nearly 1 billion children under the age of 17 experienced abuse and neglect within the past year (World Health Organization, 2022). Research indicates that a parent with a history of maltreatment is more likely to be less sensitive to their child’s needs (Savage et al., 2019). Moreover, maltreatment can lead to difficulties for children in understanding, perceiving, and interpreting emotions (Pollak, 2012). These difficulties can be present in adulthood, resulting in alexithymia (Assed et al., 2020; Ditzer et al., 2023). Although current research allows us to understand that alexithymia is related to difficulties in recognizing emotions in others, few studies have specifically investigated this relationship while considering the influence of maltreatment and the repercussions of these interactions on parental sensitivity. Furthermore, few studies have specifically focused on the recognition of emotions in children’s faces. This research aims to examine how maltreatment is related to parental sensitivity and how this relationship is influenced by alexithymia and emotion recognition. The sample consists of 60 dyads composed of a child aged between 2 and a half and 5 years and their parent recruited in community organizations, at the university, and on social media in the province of Quebec, Canada. Maltreatment experienced by the parent was measured using the short French version of the Childhood Trauma Questionnaire (CTQ) (Paquette et al., 2004). Alexithymia was measured using the French version of the Toronto Alexithymia Scale (TAS-20) (Bagby et al., 2020). Emotion recognition was assessed through a recognition task involving images displaying the six fundamental emotions on the faces of two Caucasian children. Images were generated using FantaMorph software’s morphing technique. Accuracy scores were derived from that task. Finally, parental sensitivity was measured by coding a 15-minute interaction between parent and child according to Feldman’s grid (1998). A moderated-moderation analysis indicated that parental sensitivity is predicted by the interaction between alexithymia, emotion recognition, and history of maltreatment (Hayes, 2022). The nature of the interaction was interpreted with simple slope tests analysis. Results indicate that for mothers with average or good emotion recognition abilities and no symptoms of alexithymia, parental sensitivity decreases as the history of maltreatment increases in severity. However, for mothers with alexithymia, no matter the ability to recognize emotions in children faces, the relationship between a history of maltreatment and parental sensitivity remains low. This research offers a more in-depth understanding of the factors involved in the challenges related to dealing with children emotions for parents with a history of maltreatment. It offers a new understanding of the intergenerational cycle of maltreatment.<br>
&nbsp;<br>
Title: <strong>Emotions in Sync?: Children and Adults’ Cooperation and Interpersonal Liking During Face-to-Face Interactions</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Riddell, Christopher; Nikolic, Milica; van Bockstaele, Bram; Kret, Mariska</strong><br>
Abstract: Previous research in adults has linked synchrony (of both emotional facial expressions and physiological signals) during live interactions to increased cooperation and interpersonal liking. However, the extent to which synchrony influences children’s cooperative behaviour and liking, and whether this differs from adults, is currently unclear. In this study, we investigated the effects of the synchrony of both emotional facial expressions and physiological activity (skin conductance level, heart rate variability and blush) on cooperation and liking. Dyads of N = 240 children and N = 214 adults participated in a real-life Prisoner’s dilemma game with an unfamiliar interaction partner and completed a questionnaire on interpersonal liking. As of the time of submission, we have analysed the smile and skin conductance level data and will perform the rest of the analyses before the conference date. We found that adults synchronised their smiles and skin conductance level significantly above chance, whereas children did not. Notably, neither synchrony in smiles nor skin conductance level predicted cooperation across both age groups, although the gender composition of the dyad emerged as a significant predictor in children. In adults, but not in children, the synchrony of smiles predicted greater interpersonal liking. The results of this work may suggest that the positive adaptive function of synchrony in naturalistic emotional interactions may be more complex than previous lab-based studies suggest.<br>
&nbsp;<br>
Title: <strong>Profiles of Parental Intra- And Interpersonal Emotion Regulation in Academic Contexts</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Jordan, Gesine; Greiff, Samuel ; Teuber, Ziwen</strong><br>
Abstract: Parenting is an emotion-eliciting experience, especially when it comes to the offspring’s educational paths. Parents’ emotional characteristics pertain their habitual use of emotion regulation (ER) strategies to regulate their own and their children’s emotions. Strong evidence suggests that parental ER crucially impacts their children’s ER and adjustment. However, patterns of parents’ intra- and interpersonal ER remain unexplored to date. Moreover, parents’ ER impacts their stress responses and wellbeing, e.g., parental burnout. To tackle these gaps in the literature, we investigated profiles of parents’ intra- and interpersonal ER. Our preregistered 3-wave study targets US parents of 6-9 graders. Current analyses were based on wave1 of the data collection and will be extended once all waves are completed (May 2024). The sample consisted of 1110 US parents, recruited via Prolific and balanced on gender. To test the research questions, we employed Latent profile analyses which revealed five profiles of parental intra- and interpersonal ER strategies. We could identify one profile using rather adaptive and another rather maladaptive intra- and interpersonal ER strategies. Two profiles showed low intensity for all ER strategies, alongside a distinct profile demonstrating lower usage of intrapersonal and strong usage of interpersonal ER strategies. After the completed data collection, we will explore the stability of the profiles, predictors (socioeconomic variables) and outcomes (parental burnout, adolescences academic adjustment). Conclusions from the study have the potential to provide deeper insights into the complex emotional processes and consequences of parenting, specifically regarding academic contexts.<br>
&nbsp;<br>
Title: <strong>Investigating Child-Parent Emotional Discourse and Emotion Recognition Through Interactive Experiments</strong><br>
Time: 14:30-14:45<br>
Authors: <strong>Varatharaj, Ashvini; Brehm, Laurel</strong><br>
Abstract: Emotion socialization, the process by which caregivers influence children’s understanding, expression, and regulation of emotions, is crucial for psychological development (Eisenberg et al.&nbsp;1998). Successful emotion expression is linked to reduced risk of psychopathologies in children (Chaplin and Cole 2005). This study explores the dynamics of emotion-related conversations between children and their parents, shedding light on the acquisition of adult-like emotional language and understanding in children. We designed interactive experiments hosted at a local children’s museum to elicit parent-child emotion-related conversations and analyzed these using a mixed methods approach. One component involved children using puppets to enact and explain emotions, followed by parents interpreting these emotions. This method offers unique insights into children’s conceptualization of emotions and parents’ perspectives on their emotional understanding. Additionally, we introduced scenarios, through vignettes and an AI-generated interface in ChatGPT-4 where children guessed the emotions of characters being simulated by ChatGPT-4 by asking questions, allowing us to discern their ability to recognize emotions in others and themselves. Their interactions with ChatGPT-4, especially the questions they ask and their emotional guesses, unveil their underlying emotional concepts. This work contributes to a deeper understanding of emotion socialization and its implications for children’s mental health through a linguistics lens. This study’s innovative approach, blending traditional methods with AI-assisted interaction, marks a step forward in emotion research, particularly in understanding the interplay of language and emotion in child development.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t6" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t6">Parallel Session 2 : T6</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-492d2fe8{}.cl-492a9562{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-492ba6a0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-492bae52{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-492bae53{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-492bae5c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-492bae5d{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-492bae5e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-492bae66{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-492d2fe8"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-492bae52"><p class="cl-492ba6a0"><span class="cl-492a9562">Track</span></p></td><td class="cl-492bae53"><p class="cl-492ba6a0"><span class="cl-492a9562">T6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-492bae5c"><p class="cl-492ba6a0"><span class="cl-492a9562">Type</span></p></td><td class="cl-492bae5d"><p class="cl-492ba6a0"><span class="cl-492a9562">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-492bae5c"><p class="cl-492ba6a0"><span class="cl-492a9562">Title</span></p></td><td class="cl-492bae5d"><p class="cl-492ba6a0"><span class="cl-492a9562">Positive Emotions and Regulation</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-492bae5c"><p class="cl-492ba6a0"><span class="cl-492a9562">Time</span></p></td><td class="cl-492bae5d"><p class="cl-492ba6a0"><span class="cl-492a9562">13:30 - 14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-492bae5e"><p class="cl-492ba6a0"><span class="cl-492a9562">Room</span></p></td><td class="cl-492bae66"><p class="cl-492ba6a0"><span class="cl-492a9562">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>A Two-Study Examination of the Efficacy and Mechanisms of Reappraisal to Increase Positive Emotions</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Krajuškina, Maria; Uusberg, Andero; Naar, Richard; Gross, James J.; Uusberg, Helen</strong><br>
Abstract: In two complementary studies, we examined the implementation of reappraisal with the goal to increase positive emotions in negative, neutral, and positive contexts. To clarify the mechanisms of reappraisal, we investigated whether appraisal shifts, or changes in cognitive evaluations of a situation, predict changes in affective experience. In an online study, 158 participants (75 men; mean age 27.66 years, SD = 8.06; Prolific Academic) rated their affective experience and reported their appraisals while viewing and reappraising negative, neutral, and positive images. An ongoing laboratory replication (N = 70) also incorporates electroencephalographic and electromyographic measures as objective markers of affective experience. Linear mixed models showed that in the online study, reappraisal with the goal to increase positive emotions enhanced subjective positive affect but also reduced subjective negative affect in all three valence contexts (p’s &lt; .001). Linear regression models revealed that appraisal shifts predicted changes in affective experience, but different appraisal dimensions were significant predictors depending on the valence context. For example, reappraisal-related increase in subjective positive affect was predicted by changes in congruence (β = .45, p &lt; .001) and outlook congruence (β = .31, p &lt; .001) in the negative context, but changes in certainty in the neutral context (β = .38, p &lt; .001). These results suggest that appraisal shifts provide a useful framework for understanding the psychological mechanisms of reappraisal, and that these mechanisms may vary depending on the valence context.<br>
&nbsp;<br>
Title: <strong>Emotion Crafting: Individuals as Agents of their Positive Emotional Experiences</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Van der Kaap-Deeder, Jolene</strong><br>
Abstract: Emotion regulation (ER) – the processes individuals use to determine which emotions they have, when they have them, and how they experience or express them – is one of the key determinants of well-being. Most of the extant research has focused on how people reactively engage in regulatory processes in response to specific emotional events, thereby focusing mostly on negative emotions. However, individuals not only respond to (anticipated) emotion-loaded stimuli but can also actively and purposely initiate and direct their emotional experiences. Recently, it has been proposed that ER can occur either prior (proactive ER) or after (reactive ER) the onset of an emotional stimulus. Similarly, Self-Determination Theory maintains that individuals have the innate need to be the authors of their own lives—the ones who proactively and autonomously shape their functioning and life circumstances. Despite these theoretical considerations and the vast literature on emotion regulation, little is known about the proactive regulation of positive emotions. In this talk, I will highlight the importance of positive emotions and the role of agency in the domain of emotion regulation by introducing the concept of emotion crafting. Emotion crafting indicates the degree to which individuals are aware of positive emotion-inducing contexts (awareness) and proactively act upon this awareness (action) to increase their positive emotions. Recent research will be presented on the validation of the Emotion Crafting Scale and on how emotion crafting relates to key indicators of individuals’ psychological functioning.<br>
&nbsp;<br>
Title: <strong>Bi-Directional Associations Between Social Sharing and Emotion Differentiation in Everyday Life</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Sels, Laura; Erbas, Yasemin I; O’Brien, Sarah; Verhofstadt, Lesley; Clark, Margaret; Kalokerinos, Elise</strong><br>
Abstract: Laypeople believe that sharing their emotional experiences with others will improve their understanding of those experiences, but no clear empirical evidence supports this belief. To address this gap, we used data from four daily life studies (N total = 659) with student and community samples to explore the association between social sharing and subsequent emotion differentiation (labelling emotions with a high degree of complexity) and vice versa. We found that when people experienced specific, stressful negative events and did not ruminate about them, social sharing was linked to greater subsequent emotion differentiation. In contrast, when people experienced such events and ruminated about them, social sharing was linked to lower emotion differentiation. Additionally, this relationship was reciprocal: lower emotion differentiation was linked to greater subsequent social sharing.<br>
&nbsp;<br>
Title: <strong>Suppressed Pleasure: Reinstating Pleasantness as a Causal Antecedent of Interest</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Zhou, Haotian; Wang, Chao; Li, Ziqian; Yang, Yu</strong><br>
Abstract: The current article reexamines the debate between Smith and Ellsworth’s classic model (SE Model; Smith &amp; Ellsworth, 1985) and Silvia’s model (2005) on the appraisal structure of interest as an emotion. The SE Model suggests that perceiving an event as pleasant is essential for experiencing interest, while Silvia’s model argues that interest can arise independently of pleasantness. This research critically assesses Turner and Silvia’s (2006) study (TS experiment), which supported Silvia’s perspective but is potentially flawed methodologically. We first identified a significant methodological limitation in the TS experiment. Despite this, our two exact replications of the TS experiment, intentionally preserving the identified flaw, replicated the original study’s null finding, seemingly discrediting the SE Model’s stance on pleasantness. However, when applying appropriate statistical controls, our analysis of the very same data suggested evidence in favour of the SE Model. Further, we conducted a Monte Carlo simulation demonstrating that the TS experiment had less than a 33% chance of detecting a causal relationship between pleasantness and interest, even if one exists. Extending our inquiry, we employed computational linguistics and natural language processing techniques in two novel studies. Study 4 utilized word embeddings to show that the positivity of a word is positively correlated with its proximity to interest-related words. Study 5 leveraged deep neural networks to analyse natural language statements, revealing a consistent association of interest with pleasant experiences. These findings collectively challenge the TS experiment’s conclusions and provide support for the SE Model, suggesting a positive relationship between pleasantness and interest.<br>
&nbsp;<br>
Title: <strong>The Paradox of Dampening Positive Emotions: Depressive Symptoms Explain Strategy Choice in Positive Emotional Contexts</strong><br>
Time: 14:30-14:45<br>
Authors: <strong>Mueller, Ilka; Pruessner, Luise; Holt, Daniel V.; Zimmermann, Verena; Schulze, Katrin; Strakosch, Ana-Maria; Barnow, Sven</strong><br>
Abstract: Although most people aim to enhance their positive emotions, some employ strategies that have been associated with a dampening of pleasurable emotional experiences. Unfavorable strategy choice in positive emotional contexts might occur especially in depressive disorders, characterized by anhedonia. This ecological momentary assessment study investigated a) how effective different emotion regulation strategies are to regulate positive emotions and b) how the severity of depressive symptoms predicts their selection. We analyzed data from 1,066 participants who a) completed the Beck-Depression-Inventory-II at baseline and b) were notified five times daily for seven consecutive days to complete a smartphone survey assessing their predominant emotions, strategies to regulate them, and emotional outcomes. Findings show that strategies effective in handling negative emotions, namely reappraisal and problem-solving, were associated with deteriorated emotional outcomes when used to regulate positive emotions. In contrast, strategies such as acceptance and savoring were more effective when regulating positive emotions. Importantly, people with more severe depressive symptoms were more likely to use strategies linked to the dampening of positive emotional experiences and less prone to choose strategies to effectively up-regulate positive emotions. Our findings emphasize the importance of deficits in the selection of strategies to regulate positive emotions for our understanding of the etiology and maintenance of depression. Thus, context-specific interventions to enhance positive emotion regulation may be a promising approach to improve the treatment of affective disorders. Further studies should address the underlying processes, such as emotional beliefs, that drive this maladaptive strategy choice.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-2-t7" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-2-t7">Parallel Session 2 : T7</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-493731a0{}.cl-4934a91c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4935adb2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4935b550{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4935b551{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4935b55a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4935b55b{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4935b55c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4935b564{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-493731a0"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4935b550"><p class="cl-4935adb2"><span class="cl-4934a91c">Track</span></p></td><td class="cl-4935b551"><p class="cl-4935adb2"><span class="cl-4934a91c">T7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4935b55a"><p class="cl-4935adb2"><span class="cl-4934a91c">Type</span></p></td><td class="cl-4935b55b"><p class="cl-4935adb2"><span class="cl-4934a91c">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4935b55a"><p class="cl-4935adb2"><span class="cl-4934a91c">Title</span></p></td><td class="cl-4935b55b"><p class="cl-4935adb2"><span class="cl-4934a91c">Physiology</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4935b55a"><p class="cl-4935adb2"><span class="cl-4934a91c">Time</span></p></td><td class="cl-4935b55b"><p class="cl-4935adb2"><span class="cl-4934a91c">13:30 - 14:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4935b55c"><p class="cl-4935adb2"><span class="cl-4934a91c">Room</span></p></td><td class="cl-4935b564"><p class="cl-4935adb2"><span class="cl-4934a91c">Moyola: PFC/02/017</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Beyond Deep Learning: Integrating Neuro-Symbolic AI for Enhanced Analysis of Facial Behavior of Emotions</strong><br>
Time: 13:30-13:45<br>
Authors: <strong>Gebele, Jens Johannes; Brune, Philipp; von Mammen, Sebastian; Schwab, Frank</strong><br>
Abstract: In two empirical studies, we evaluated the annotation quality of facial emotion recognition data. We trained diverse Convolutional Neural Networks (CNNs) on three databases: FER-2013, RAF-DB, and AffectNet, each annotated based on Ekman’s theory of seven discrete emotions. Our comparative analysis of similar CNN models reveals significant inconsistencies in annotations, especially within AffectNet. This variability, coupled with limitations of Ekman’s theory, underscores the challenge for AI systems in accurately capturing the complexity of human emotions through facial behavior. Current research relies predominantly on Deep Learning (DL), often overlooking fundamental issues and instead focusing on developing increasingly complex DL models. Such models use multi-layered interconnected nodes (similar to neurons) to process large amounts of data. While DL has achieved significant success, its increasing architectural complexity leads to a lack of explainability and reliability. DL models depend on large datasets annotated with theoretical concepts that may lack robust scientific validation. To address these intertwined challenges, we propose combining advanced DL models with traditional Symbolic AI, known for its logical reasoning and symbolic knowledge representation. This synthesis forms Neuro-Symbolic AI, an area of AI research gaining increasing interest. We consider this area as a pathway to establish a bidirectional mapping between knowledge (graphs) encoded in a trained DL model, and knowledge representations, such as FACS, grounded in emotion psychology. This enhances explainability and reliability of DL, while moving beyond discrete facial emotion recognition to a more nuanced analysis of facial behavior of emotions. This progress is key to emotionally intelligent human-computer interaction.<br>
&nbsp;<br>
Title: <strong>Return of a Gold Standard: Electromyography-Based Facial Action Unit Recognition</strong><br>
Time: 13:45-14:00<br>
Authors: <strong>Küster, Dennis; Veldanda, Abhinav; Liu, Hui; Krumhuber, Eva; Koschke, Rainer; Schultz, Tanja</strong><br>
Abstract: For decades, facial Electromyography (EMG) and the Facial Action Coding System (FACS) were regarded as laboratory gold standards in emotion research. Where the former featured supreme temporal resolution and sensitivity for otherwise invisible muscle responses, the latter offered a comprehensive expert-based coding of facial muscle activity. Meanwhile, automated action unit recognition (AUR) has revolutionized video-based FACS-coding. In contrast, few studies to date have explored how action units (AUs) could be classified from EMG instead of video data. We present a proof-of-concept study with one subject imitating four AUs (AU1, AU2, AU4, AU9) and concurrent bi-polar EMG recordings from the Corrugator Supercilii and lateral Frontalis sites. Using five-fold cross-validation, four out of six widely used machine- and deep learning models achieved near perfect AUR accuracies (&gt;.95) based on data from both EMG channels. A random forest model outperformed the other models using single-channel data, as well as in an initial near real-time test of our AUR system. Presently, we are collecting data for a second study targeting a sample of 20 lay participants, eight AUs, four EMG recording sites, with validation data for peak images via manual expert FACS-coding. Based on these preliminary results, EMG-based AUR systems might soon be able to compete with, if not outperform, current camera-based approaches. Illustrated by new use-cases in virtual reality, real-time interaction with embodied conversational agents, or privacy-sensitive measurement, we discuss how recent advances could lead to a renaissance of EMG in emotion research.<br>
&nbsp;<br>
Title: <strong>Electrophysiological Correlates of Intensity and Dynamic Information in Emotional Facial Expression Recognition</strong><br>
Time: 14:00-14:15<br>
Authors: <strong>Palazova, Marina; Mückstein, Marie; Stürmer, Birgit</strong><br>
Abstract: Most research on emotion recognition from facial expressions has utilized static pictures showing the apex of the emotional display. Recent evidence suggests that the intensity of emotional facial expressions as well as dynamic information modulate emotion processing. However, both factors have not been studied simultaneously yet. In the present study we seek to replicate intensity and dynamic information effects on emotion recognition and examine basic aspects of both factors simultaneously while recording the EEG. Participants (n = 105) performed an emotion categorization task on static and dynamic images of four facial expressions (anger, fear, happiness and neutral) in two intensities (60% and 100 %). Emotion recognition was modulated by both, intensity and dynamic information. In event-related brain potentials, effects of intensity were first evident in the EPN component whereas effects of dynamic presentation started earlier with the P1 component. While emotion effects in the N170 were reduced in the dynamic condition, dynamic presentation augmented emotion effects in the EPN, specifically for the 60 % intensity condition. Such a visual processing boost compared with static expressions might explain why dynamic facial expressions are often rated to be more intense than static facial expressions. Since in everyday life emotional expressions are genuinely dynamic, more subtle, and strongly controlled than static images used in laboratory conditions, the study of less intense dynamic facial expressions might increase ecological validity. Further, the large sample delivers a strong basis for examining individual differences in emotion recognition. ps: a talk would be preferred.<br>
&nbsp;<br>
Title: <strong>A Walk in the Park: Measuring Emotional Mimicry with Electromyography in Virtual Reality</strong><br>
Time: 14:15-14:30<br>
Authors: <strong>Kastendieck, Till; Huppertz, Daniel; Mauersberger, Heidi; Hess, Ursula</strong><br>
Abstract: Research on contextualized approaches to emotion and emotion communication, including the automatic but goal-dependent imitation of the interaction partner’s emotional expressions, known as emotional mimicry, has made remarkable progress over the years. An important aspect of context is situational and spatial embeddedness, emphasizing that the affective fit of faces and places influences mimicry. However, emotional mimicry has never been studied in highly immersive virtual reality surroundings. In a laboratory experiment, 75 participants wore head-mounted displays with integrated electromyography (EMG) sensors that measured the corrugator supercilii (associated with a negative affect), orbicularis oculi, zygomaticus major (positive affect), as well as frontalis. In line with emotional mimicry in social context theory (Hess &amp; Fischer) and broaden-and-build theory (Fredrickson), participants mimicked joyful expressions in pleasant audio-visual contexts (park area with greenery, bird song) more than in unpleasant contexts (park area with construction site, loud construction site noise), as shown by linear mixed modeling. In line with predictions of the former theory, according to a multilevel mediation model, emotion perception and perceived interpersonal closeness (i.e., self-other overlap, inclusion of other in the self) were negatively associated with the change from pleasant to unpleasant contexts and positively associated with joy mimicry. Moreover, unpleasant contexts intensified reactions to distressed faces but only at an earlier stage of the expression episode. The findings are the first to provide EMG evidence gathered in virtual reality on emotional mimicry, supporting accounts that highlight the embedded nature of emotion communication and strengthening top-down perspectives on this important social regulator.<br>
&nbsp;<br>
Title: <strong>Does Distraction Foster Subsequent Reappraisal? an EMG and EEG Investigation into Strategy Sequencing</strong><br>
Time: 14:30-14:45<br>
Authors: <strong>Uusberg, Helen; Kolnes, Martin MK</strong><br>
Abstract: Reappraisal is a widely studied and generally effective as well as adaptive emotion regulation strategy. However, it has been shown to be used less frequently and to work less effectively than distraction in situations characterized by high emotional intensity. This suggests that it might be advantageous to use distraction and reappraisal in a sequence to first lower the intensity of an emotion and then leverage the adaptiveness of reappraisal. To test the hypothesis that distraction fosters subsequent reappraisal in downregulating high intensity negative affect, we conducted a laboratory experiment where 67 participants (mean age 26.11 years, SD = 10.54) were presented with neutral, low intensity negative, and high intensity negative images and instructed to use different combinations of the following instructions: view, distraction, and reappraisal. Simultaneously, we recorded participants’ electroencephalography (EEG) and facial electromyography (EMG). The results showed that initial distraction did not improve the effect of subsequent reappraisal. Instead, reappraisal reduced negative affect in response to high intensity negative images more effectively when participants initially simply viewed the images, as indexed by corrugator supercilii activity. The LPP amplitude during subsequent reappraisal was decreased when participants first implemented distraction; however, this effect was limited to very early latencies (approximately 260-450 ms), indicating altered stimulus recognition. The discrepancy between EMG and LPP dynamics points to methodological challenges when using laboratory experiments incorporating pictorial stimuli and LPP measurement to study the effects of strategy sequencing. I will discuss these challenges in light of other methodologically similar studies from our group and beyond.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t1" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t1">Parallel Session 3 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49413092{}.cl-493ea1ec{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-493fa6fa{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-493fae7a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-493fae84{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-493fae85{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-493fae86{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-493fae8e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-493fae8f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49413092"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-493fae7a"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Track</span></p></td><td class="cl-493fae84"><p class="cl-493fa6fa"><span class="cl-493ea1ec">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-493fae85"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Type</span></p></td><td class="cl-493fae86"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-493fae85"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Title</span></p></td><td class="cl-493fae86"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Emotion regulation in the interpersonal context: Reciprocal interactions between emotional and relational dynamic</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-493fae85"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Time</span></p></td><td class="cl-493fae86"><p class="cl-493fa6fa"><span class="cl-493ea1ec">15:15 - 16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-493fae85"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Room</span></p></td><td class="cl-493fae86"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Whitla Hall</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-493fae8e"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Abstract</span></p></td><td class="cl-493fae8f"><p class="cl-493fa6fa"><span class="cl-493ea1ec">Emotions find their place within the dynamics of our interactions with others. The way we respond emotionally is frequently influenced by the interpersonal setting, such as engaging in emotional discussions or experiencing interpersonal emotion regulation. These emotional reactions, in turn, play a role in shaping the relationship and our sentiments towards it; for instance, sharing moments of joy can foster a sense of closeness between individuals. This symposium examines the complex interplay between emotions and interpersonal relationships using diverse methodologies. The first talk employs linguistic analysis of conversations between strangers to learn how conversational structure relates to changes in positive affect. The second presentation examines how different interpersonal emotion regulation strategies are linked to social-emotional outcomes for the regulator using questionnaires and task-based assessments. The third talk presents two ecological momentary assessment studies examining the effectiveness of different interpersonal emotion regulation strategies in everyday life and shows the advantage of strategies that focus on relational aspects (vs. those that do not). The fourth presentation uses a dyadic daily diary to examine how parents‚Äô and adolescents‚Äô interpersonal emotion regulation relates to how regulator and regulatee perceive their relationship partners as responsive. The fifth talk employs five waves of a dyadic ecological momentary assessment to show the bi-directional, within-dyad associations between maternal attunement and negative and positive emotions. The current symposium will advance our understanding of how interpersonal emotion regulation can contribute to healthier relationships and how fostering healthier and more resilient connections across various relationship types contributes to emotional well-being.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Shaping Others’ Emotions in Conversation: An Analysis of Temporal Dynamics</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Haran Sened</strong><br>
Abstract: Conversations are a powerful way for people to shape others’ emotions. Simply through speak- ing, one person can shift another person’s internal emotion state. What is it about one person’s words that can make another feel better? Prior work shows that paralinguistic characteristics, such as the length of each speech turn, and semantic characteristics, such as similarity in emotional content, are associatedwith better conversation outcomes. The current study ex- amines whether these characteristics are associated with better outcomes uniformly across the conversation or whether their importance changes over time. We analyzed 400 transcripts of 30-minute online conversations between strangers. We measured speech turn length by counting characters and emotional similarity using a word embedding model. Analyses exam- ined how changes in these characteristics over time are associatedwith emotional change – defined as increased positive emotions from before to after the conversation. Results revealed that conversations have a reliable temporal dynamic. Speech turns grew longer fromthe begin- ning to the middle of conversations, and then started to decline (i.e., a quadratic effect for time). Emotional similarity showed a similar n-shaped dynamic. The conversations with the most exaggerated n-shapes showed more positive emotional change. Our findings suggest that people startconversations by converging to a similar emotional state. They then explore a wider emotional space, with more extensive turns, a process that leads to positive emotional change. This work suggests thatattempts at interpersonal emotional regulation, in which peo- ple aim for emotional change intentionally, might be more effective if they follow these patterns. Conversations are a powerful way for people to shape others’ emotions. Simply through speak- ing, one person can shift another person’s internal emotion state. What is it about one person’s words that can make another feel better? Prior work shows that paralinguistic characteristics, such as the length of each speech turn, and semantic characteristics, such as similarity in emotional content, are associatedwith better conversation outcomes. The current study ex- amines whether these characteristics are associated with better outcomes uniformly across the conversation or whether their importance changes over time. We analyzed 400 transcripts of 30-minute online conversations between strangers. We measured speech turn length by counting characters and emotional similarity using a word embedding model. Analyses exam- ined how changes in these characteristics over time are associatedwith emotional change – defined as increased positive emotions from before to after the conversation. Results revealed that conversations have a reliable temporal dynamic. Speech turns grew longer fromthe begin- ning to the middle of conversations, and then started to decline (i.e., a quadratic effect for time). Emotional similarity showed a similar n-shaped dynamic. The conversations with the most exaggerated n-shapes showed more positive emotional change. Our findings suggest that people startconversations by converging to a similar emotional state. They then explore a wider emotional space, with more extensive turns, a process that leads to positive emotional change. This work suggests thatattempts at interpersonal emotional regulation, in which peo- ple aim for emotional change intentionally, might be more effective if they follow these patterns.<br>
&nbsp;<br>
Title: <strong>Distraction over Reappraisal Strategies in Interpersonal Emotion Regulation: Associations with Socio-Emotional Difficulties</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Belen Lopez-Perez</strong><br>
Abstract: When aiming to change the emotions of others, not all strategies might be equally beneficial. While some may elaborate on the target’s emotional response (engagement), others may not address the emotional needs (diversion). Distraction (as a diversion strategy) has been sug- gested as less effective than reappraisal (engagement) to regulate emotions. We argue that if it is less effective, the predominant use of distraction over reappraisal to change others’ emo- tions might be problematic. To evaluate this, we conducted three studies in which we assessed people’s tendency to use distraction over reappraisal through questionnaires (Studies 1 and 2) and through different scenarios describing the target as experiencing different emotions (Study 3). In detail, in Study 1 (n = 274) and Study 2 (n = 202), we used a difference score to assess individuals’ dominant use of distraction over reappraisal. The tendency to use distrac- tion over reappraisal to change others’ emotions was linked to more difficulties in identifying and describing feelings and greater experience of personal distress (Study 1) and to more emotion dysregulation and socio-emotional problems (Study 2). In Study 3 (n = 121), based on latent class analysis, we identified a class of people who consistently used distraction to change others’ anger, sadness, and anxiety over engagement strategies. Importantly, this class scored higher in difficulties at identifying and describing feelings and experiential avoid- ance. The obtained results suggest that the consistent use of diversion over engagement strat- egies to change others’ emotions might be associated with more socio-emotional difficulties in the regulator.<br>
&nbsp;<br>
Title: <strong>Dealing with Other People’s Feelings: Effectiveness of Extrinsic Interpersonal Emotion Regulation Strategies in Everyday Life</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Luise Pruessner</strong><br>
Abstract: While we can effectively alter our own emotional states by employing strategies like cognitive reappraisal, distraction, or problem-solving, it remains unclear if these approaches can be suc- cessfully extended to regulating the emotions of those around us. Existing emotion regulation research has primarily focused on examining the success of intrinsic, self-focused strategies, leaving a gap in our understanding of the effectiveness of extrinsic, other-focused emotion regulation strategies. Therefore, we conducted two ecological momentary assessment studies (Ns = 131 and 204) testing the effectiveness of extrinsic interpersonal emotion regulation strat- egies for achieving other-focused regulatory goals in daily social interactions from the regula- tor’s perspective. We examined a comprehensive set of 15 extrinsic regulatory strategies rep- resenting all stages of the emotion regulation process (situation selection and modification, attentional deployment, cognitive change, and response modulation). Remarkably, our find- ings from both studies revealed that strategies considered effective for managing one’s own emotions, such as reappraisal, distraction, and problem-solving, were perceived as ineffective when applied with the goal of influencing the affective states of others. In contrast, the regula- tors reported that validation, soothing, or affectionate touch were linked to higher levels of mod- ulating their interaction partner’s emotions as intended. These findings highlight the importance of distinguishing between self-focused and other focused emotion regulation goals when ex- amining the effectiveness of regulatory strategies. Understanding how to successfully modu- late the emotions of those we interact with is fundamental for fostering healthier relationships and enhancing the emotional well-being of ourselves and the people around us.<br>
&nbsp;<br>
Title: <strong>Interpersonal Emotion Regulation is Associated with Parents’ and Adolescents’ Perceived Partner Responsiveness</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>Reuma Gadassi Polack</strong><br>
Abstract: The way in which parents respond to their children’s emotions (interpersonal emotion regula- tion; IER) is important for child social-emotional development and well-being. However, it is less known how IER is associated with outcomes to the parent-child relationship (e.g., perceived responsiveness). Additionally, only a handful of studies examined children’s IER of their par- ents. We address these gaps by examining parent and adolescent IER and perceived partner responsiveness using the Actor Partner Interdependence Model. For 28 days, 112 parent-ad- olescent (age 12-18) dyads completed a dyadic diary, reporting their IER to dyad members’ negative and positive emotions as well as the degree to which they perceive their partner as responsive. Results show that on days in which parents used IER to improve their children’s positive or negative affect, both they and adolescents perceived the other as more responsive. Similarly, on days in which adolescents used IER to improve their parents’ positive or negative affect, both they and their parents perceived the other as more responsive. Conversely, on days in which parents or children used IER to make their dyad partner’s affect worse, the regulator perceived their partner as less responsive. When adolescents tried to make their parents pos- itive affect decrease, parents perceived their child as less responsive. Similarly, on days par- ents tried to increase their children’s negative affect, adolescents perceived them as less re- sponsive. These results demonstrate that perceiving dyad members as responsive is related, in addition to the partner’s behaviors, to how you behave towards your partner.<br>
&nbsp;<br>
Title: <strong>What Benefits Do Mothers Gain from Maternal Attunement? a Five-Wave Dyadic Study Across Preadolescence</strong><br>
Time: 16:15-16:30<br>
Authors: <strong>Reout Arbel</strong><br>
Abstract: This study explored what affective benefits (if any) mothers gain by being attuned to a pread- olescent child and, in turn, whether these benefits help mothers maintain attuned caring. We used a six-wave longitudinal investigation to test the bi-directional temporal associations be- tween child-reported maternal attunement and mothers’ self-reported well-being, including mood and self-esteem. Our sample included 202 ethnically diverse mother [Mage at baseline = 40.1 years (SD = 6.1)] and child [Mage at baseline=10.1 (SD = .90), 51% girls] dyads. We used five 7-day waves of Ecological Momentary Assessment, with each wave separated by 6 months. Up to eight random times per day, mothers reported on two state-level positive emo- tions (PE; happy, calm/relaxed) and three negative emotions(NE; angry, sad, stressed). We used a random-intercept cross-lagged panel model (RI-CLPM) to test within- and between- person effects. At the within-person level, increased NE was negatively associated with ma- ternal attunement within the same wave, and increased attunement on a given wave predicted mothers’ decreased negative emotions on the next. Same-wave or across-wave associations with PE or perceived stress were weak and non-significant. At the between-person level, av- erage levels of maternal attunement did not significantly correlate with average levels of PE or NE or with perceived stress. Results suggest that increased sensitive care for an adolescent child is associated with less distress for mothers. This suggests a reinforcing mechanism of maternal sensitive caring. Results were largely unchanged when we controlled for child sex, maternal global perceived stress, and mothers’ reported child internalized or externalized prob- lems.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t2" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t2">Parallel Session 3 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-494b2b10{}.cl-49489a6c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4949a02e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4949a7c2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4949a7cc{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4949a7cd{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4949a7d6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4949a7d7{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4949a7d8{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-494b2b10"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4949a7c2"><p class="cl-4949a02e"><span class="cl-49489a6c">Track</span></p></td><td class="cl-4949a7cc"><p class="cl-4949a02e"><span class="cl-49489a6c">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4949a7cd"><p class="cl-4949a02e"><span class="cl-49489a6c">Type</span></p></td><td class="cl-4949a7d6"><p class="cl-4949a02e"><span class="cl-49489a6c">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4949a7cd"><p class="cl-4949a02e"><span class="cl-49489a6c">Title</span></p></td><td class="cl-4949a7d6"><p class="cl-4949a02e"><span class="cl-49489a6c">A Touch of Emotion</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4949a7cd"><p class="cl-4949a02e"><span class="cl-49489a6c">Time</span></p></td><td class="cl-4949a7d6"><p class="cl-4949a02e"><span class="cl-49489a6c">15:15 - 16:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4949a7cd"><p class="cl-4949a02e"><span class="cl-49489a6c">Room</span></p></td><td class="cl-4949a7d6"><p class="cl-4949a02e"><span class="cl-49489a6c">Bann: PFC/0G/024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4949a7d7"><p class="cl-4949a02e"><span class="cl-49489a6c">Abstract</span></p></td><td class="cl-4949a7d8"><p class="cl-4949a02e"><span class="cl-49489a6c">Research into social touch holds paramount significance in understanding emotional well-being. The first talk will discuss peripheral nerve fiber evidence that implicates C-tactile (CT) and AŒ≤ afferents in signaling touch-related information. Through ERPs and EEG oscillations, forearm stroking stimuli have been examined, revealing differential neural responses linked to various stroking velocities. The sN400 ERP component mirrored CT and AŒ≤ afferent firing patterns, showing associations with individual touch preferences, indicating biases towards implicit and explicit processes influenced by these afferents. The second talk will discuss affiliative touch's role in stress modulation and emotional well-being highlighting cutaneous low-threshold mechanoreceptors (CLTMs) as potential regulators of stress resilience. These receptors, sensitive to gentle, dynamic touch, project to emotion-processing brain regions, proposing them as a vital substrate for emotional regulation‚Äîa concept termed 'Vitamin-T,' emphasizing the importance of touch to emotional as well as physical health. The third talk will examine insights from psilocybin's effects on individuals with depression and will discuss a potential therapeutic avenue, indicating improved emotional attitudes towards social touch post-administration. This suggests a mechanism through which psilocybin may alleviate depressive symptoms by positively influencing social touch perceptions. The final talk will delve into oxytocin's modulation during affiliative touch-mediated interactions highlight its context-dependent neural regulation, emphasizing the dynamic interplay between brain-hormone co-modulation and social touch in shaping relational dynamics. These studies collectively illuminate tactile perception's neural intricacies, stress modulation, and therapeutic implications, showcasing the nuanced interplay between tactile experiences, neural mechanisms, and emotional well-being.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>EEG Insights into the Neural Construction of Tactile Affect</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Annett Schirmer</strong><br>
Abstract: Evidence from peripheral nerve fibers suggests that the pleasantness of a caress depends on the activation of C-tactile (CT) and Aβ afferents in the skin and their signaling input to the brain. Yet, how this input is processed and integrated with other brain mechanisms to inform the implicit and explicit value of touch is currently unknown. We pursued this issue by examining both event-related potentials (ERPs) and EEG oscillations to slow stroking stimuli delivered via a soft brush to the forearm. The stimuli varied in velocity and were rated on a pleasantness scale. Stroking elicited a negative ERP component around 400 ms following touch onset over contra-lateral somatosensory cortex. This sN400 was larger for intermediate when compared with slower and faster velocities reminiscent of the firing pattern of CT afferents. Additionally, faster velocities dampened somatosensory Rolandic rhythms in line with the known firing pattern of Aβ afferents. sN400 amplitude and Rolandic rhythms predicted pleasantness ratings in different ways. The sN400 association showed irrespective of whether participants preferred fast or slow touch. However, the Rolandic rhythm association revealed individual differences. In those preferring fast touch, Rolandic rhythms differentiated between fast velocities, whereas in those preferring slow touch, these rhythms differentiated between slow velocities. Based on these results, we speculate that sN400 and Rolandic rhythms are differently shaped by CT and Aβ input. Moreover, although both afferents contribute to tactile affect their contributions may be biased towards implicit and explicit processes, respectively.<br>
&nbsp;<br>
Title: <strong>Vitamin T</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Francis McGlone</strong><br>
Abstract: Chronic stress is the cause of many adverse changes in the brain and has also been found to be an antecedent of mood changes associated with cognitive impairment. Affiliative tactile interactions are known to buffer social mammals against neurobiological and behavioural effects of stress, and within human populations the recent COVID pandemic, where for the first time in human evolution affective touch interactions were significantly restricted, we saw the adverse consequences on people’s stress levels and subsequent emotional state. But what’s the mechanism? Here a case will be made for the role of a population of cutaneous low threshold thermo- mechanosensitive c-fibres called c-low threshold mechanoreceptors (CLTM) as a neurobiological substrate responsible for regulating resilience to stress. Due to the delayed nature of their input, they cannot serve any useful discriminative role and are implicated in underpinning the affective and emotional aspects of touch. CLTMs are velocity tuned, preferentially encoding gentle, dynamic touch and project centrally to emotion processing brain areas. The CLTM is now being understood to provide a singular vital protective function, from the nurturing touch of the mother to its absence in loneliness. And now we have evidence from animal studies of their putative role in reducing plaque formation. A case will be made for what we are describing, by analogy with the vital role vitamins play in our physical health, for affective touch and their neuronal substrate the CLTM as ‘Vitamin-T’ for our emotional health.<br>
&nbsp;<br>
Title: <strong>The Effects of Psilocybin (‘magic Mushrooms’) on Social Touch Perception in Individuals with Resistant Major Depressive Disorder</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Leehe Peled-Avron</strong><br>
Abstract: Individuals with depression often experience difficulties in social interactions. Social interactions consist of both verbal and non-verbal means of communication, among which is social touch which is used to convey several types of emotions. Depression is associated with negative attitudes towards social touch and these negative attitudes mediate interpersonal difficulties. Psilocybin, the active compound in several types of fungi (‘magic mushrooms’) has been shown to alleviate symptoms of depression. Yet its effects on social interaction and specifically on social touch have yet to be explored. In this study, we examined the effect of psilocybin administration on perception of social touch in individuals with resistant major depressive disorder. Participants watch photos of either humans or inanimate objects touching or not. Participants are then asked to rate their emotions towards the objects in the photos. The responses are recorded a week before and a week after administration of 25mg of synthetic psilocybin during psychedelic assisted psychotherapy. Results demonstrate a significant increase in emotionality ratings in the human touch condition after psilocybin administration, no such difference was found for the ratings of the control conditions or following placebo administration. These results point to a potential improvement of the attitudes towards social touch following a psychedelic intervention in depression and may suggest a possible mechanism through which psilocybin alleviates depressive symptoms.<br>
&nbsp;<br>
Title: <strong>The Neuroscience of Human Social Touch</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>India Morisson</strong><br>
Abstract: Our knowledge of the neural underpinnings of affective touch has burgeoned over the past two decades, on levels from the receptor to larger-scale functional neuroanatomy of the brain. Yet we still understand very little about how these mechanisms might contribute to the role of touch in human social interaction. This talk describes ways in which specific properties of touch can be organized by the human nervous system during affiliative social interactions. In particular, our recent investigations of co-modulation between the brain and the neuropeptide oxytocin have suggested that oxytocin neuromodulation during touch-mediated social interactions is flexible and context-dependent. In humans, parietotemporal brain pathways may play a selective role in these context-sensitive processes, potentially allowing “tuning” of brain and body responses during social interactions. Such brain-hormone co-modulation during touch-mediated human social interactions allows for dynamic changes in interactants’ behavior and physiological states. These emerging lines of evidence hint that the role of social touch unfurls over time, not just during a single social interaction but over the course of whole relationships.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t3" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t3">Parallel Session 3 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49566552{}.cl-4953d7ce{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4954df7a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4954e6fa{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4954e6fb{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4954e704{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4954e70e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4954e70f{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4954e710{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49566552"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4954e6fa"><p class="cl-4954df7a"><span class="cl-4953d7ce">Track</span></p></td><td class="cl-4954e6fb"><p class="cl-4954df7a"><span class="cl-4953d7ce">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4954e704"><p class="cl-4954df7a"><span class="cl-4953d7ce">Type</span></p></td><td class="cl-4954e70e"><p class="cl-4954df7a"><span class="cl-4953d7ce">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4954e704"><p class="cl-4954df7a"><span class="cl-4953d7ce">Title</span></p></td><td class="cl-4954e70e"><p class="cl-4954df7a"><span class="cl-4953d7ce">The Emerging Science of Awe and its Cognitive and Social Outcomes</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4954e704"><p class="cl-4954df7a"><span class="cl-4953d7ce">Discussant</span></p></td><td class="cl-4954e70e"><p class="cl-4954df7a"><span class="cl-4953d7ce">Dacher Keltner</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4954e704"><p class="cl-4954df7a"><span class="cl-4953d7ce">Time</span></p></td><td class="cl-4954e70e"><p class="cl-4954df7a"><span class="cl-4953d7ce">15:15 - 16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4954e704"><p class="cl-4954df7a"><span class="cl-4953d7ce">Room</span></p></td><td class="cl-4954e70e"><p class="cl-4954df7a"><span class="cl-4953d7ce">Foyle: PFC/0G/007</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4954e70f"><p class="cl-4954df7a"><span class="cl-4953d7ce">Abstract</span></p></td><td class="cl-4954e710"><p class="cl-4954df7a"><span class="cl-4953d7ce">Awe is an emotion that is experienced in the presence of something vast that is difficult to understand and requires that existing knowledge structures be accommodated to make sense of what is being perceived (Keltner &amp; Haidt, 2003). Awe is often experienced through encounters with other people‚Äôs courage and kindness, nature, collective gatherings (dance, rituals, and ceremonies), music, visual art, religious and spiritual practice, epiphanies, and birth and death (Bai et al., 2017; Keltner, 2023). Within this broad landscape of awe, theoretical and empirical evidence suggest potential intra and interpersonal benefits (e.g., Monroy &amp; Keltner, 2022). This symposium builds on the emergent science of awe and highlights recent research examining the relation between awe and cognitive and social outcomes: including (1) expanding the scope of attention toward the environment; (2) envisioning diverse perspectives and possibilities (e.g., temporal distancing); (3) fostering forgiveness of past transgressions; and (4) promoting integration into communities and/or social groups. This symposium offers diverse insights from a selection of nine studies, conducted in two countries, with diverse methodologies such as field studies, daily diary techniques, and in lab studies.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The Effect of Positive-Awe and Threatening-Awe on Attentional Scope</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Chenxiao Zhao</strong><br>
Abstract: Awe is an emotional response to perceptually vast stimuli that transcend one’s current frames of reference. Previous research found that awe could facilitate global and holistic processing and thus broadens our attentional scope. However, recent studies suggest that awe can be differentiated in terms of positive-awe and threatening-awe, each associated with distinct neural mechanisms. Also, considering that previous research has shown that positive vs.&nbsp;negative emotions affect the attentional scope differently, in the current study, we aim to clarify whether positive-awe and threatening-awe exert different effects on the attentional scope. In Experiment 1, we independently evoked positive-awe and threatening-awe using videos and subsequently measured their effects on attentional scope with Navon task. Our results suggested positive-awe and threatening-awe affect attentional scope similarly. Experiment 2 replicated these effects after controlling for stimulus size. In Experiment 3 we aim to measure attentional scope in a more immersive way (during awe experiences instead of after the awe-induction), and eye movements are tracked to reveal the potential differences on attention-grabbing effect between different types of awe. Insights and recommendations to study how awe affects low-level attentional mechanisms will be discussed.<br>
&nbsp;<br>
Title: <strong>Many Paths to Presence: Mechanisms of the Relation Between Awe and Animism</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Ostafin, Brian</strong><br>
Abstract: Spiritual experiences involving awe are often accompanied by a feeling of presence, as illustrated in the experience of animism. The current research examined the influence of awe on animism and whether this main effect can be explained in part by each of three potential mechanisms of uncertainty, trust in intuition, and ego dissolution. The study used a community sample (N=344) and assigned participants into one of three mood-induction conditions consisting of videos to elicit awe, humor, or relaxation. The results indicated that compared to humor and relaxation, the awe participants reported greater experience of animism and life meaning. The awe-meaning relation was mediated by animism. The awe-animism relation was mediated by uncertainty, trust in intuition, and ego dissolution when examined in separate regression analyses and by trust in intuition and ego dissolution when examined simultaneously in a multiple mediator analysis. The results suggest that awe may elicit the experience of a world that is meaningful because it is a world that is alive, and that the aliveness of the world during awe may be especially due to the loss of ego and greater weight given to intuitive experience.<br>
&nbsp;<br>
Title: <strong>Awe and Temporal Distancing</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Özge Ugurlu</strong><br>
Abstract: Experiencing awe increases well-being and has been associated with improved stress-related symptoms, yielding resilience against stress. However, our understanding of the mechanism by which awe leads to adaptive well-being outcomes is still limited. Considering that awe might change one‚Äôs time perception, we further explored whether one pathway to wellbeing might be through temporal distancing, defined as viewing a negative experience as being in the future. To investigate this, we conducted a daily diary study during a global stressor, the COVID-19 pandemic. Similar to previous research, our results indicate that daily experiences of awe predict greater resilience against the stressor, COVID-19 in this context. Moreover, our mediation analysis revealed that daily experiences of awe also predicts higher levels of temporal distancing which mediates the link between awe and resilience. In sum, in the event of a global pandemic, if people remind themselves that their feelings are temporary, they are more likely to cope with their stressors.<br>
&nbsp;<br>
Title: <strong>The Influence of Awe on Social Integration</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>Maria Monroy</strong><br>
Abstract: Theoretical and empirical evidence in the science of awe suggest that awe promotes social integration. In a series of methodologically diverse studies (N = 1,143), we tested this claim and found evidence that awe is associated with greater social integration—in terms of openness to others, collective orientation, connectedness to others, and perceptions and behavioral intentions of inclusion. We first tested this claim in trait-like tendencies and found that awe prone people tend to be more open-minded, more collective oriented, feel more connectedness to others, and are more inclusive of others (Studies 1 &amp; 4). Second, in in-vivo studies in nature, self-reports of awe were related to greater connectedness to others (Studies 2a &amp; 2b). Third, in day-to-day life, on days when people experienced more awe than typical, they also experienced greater connectedness and openness to different cultures (Study 3). Fourth and last, in an experimental study, people induced to experience awe were more inclusive of People of Color (Study 4). Across these studies, the effects of awe were unique and beyond the effects of other positive emotions. This work provides evidence suggesting that experiences of awe are associated with different aspects of social integration and provides promise for future interventions.<br>
&nbsp;<br>
Title: <strong>Discussion</strong><br>
Time: 16:15-16:30<br>
Authors: <strong>Keltner, Dacher</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t4" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t4">Parallel Session 3 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-496082e4{}.cl-495dfc68{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-495f00c2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-495f082e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-495f082f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-495f0838{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-495f0839{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-495f083a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-495f0842{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-496082e4"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-495f082e"><p class="cl-495f00c2"><span class="cl-495dfc68">Track</span></p></td><td class="cl-495f082f"><p class="cl-495f00c2"><span class="cl-495dfc68">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-495f0838"><p class="cl-495f00c2"><span class="cl-495dfc68">Type</span></p></td><td class="cl-495f0839"><p class="cl-495f00c2"><span class="cl-495dfc68">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-495f0838"><p class="cl-495f00c2"><span class="cl-495dfc68">Title</span></p></td><td class="cl-495f0839"><p class="cl-495f00c2"><span class="cl-495dfc68">Virtual Reality and Games</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-495f0838"><p class="cl-495f00c2"><span class="cl-495dfc68">Time</span></p></td><td class="cl-495f0839"><p class="cl-495f00c2"><span class="cl-495dfc68">15:15 - 16:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-495f083a"><p class="cl-495f00c2"><span class="cl-495dfc68">Room</span></p></td><td class="cl-495f0842"><p class="cl-495f00c2"><span class="cl-495dfc68">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Fostering Positive Emotions in VR Interactions Between Rival Groups: Prosociality over Common Ingroup Identity</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Alvidrez, Salvador</strong><br>
Abstract: Inferring emotions in virtual reality (VR) interactions is challenging due to technical constraints. Identifying emotions arising in VR intergroup interactions between historically rival groups is relevant for favouring positive interactions. This study analysed the emergence of emotions in a VR intergroup verbal exchange. Catholic and Protestant participants (N = 60) in Northern Ireland worked jointly in a VR activity under 3 group salience conditions (Common Ingroup Identity, Intergroup Identity, Control). One participant in each dyad was, in fact, a pre-trained confederate. Avatars wore Union Jack (Protestant) or Irish flag (Catholic) t-shirts denoting group membership. The Common Ingroup condition used “Team Member” nameplates (i.e., team prime), whereas the Intergroup condition did not include this prime (e.g., “Player”); the Control used neutral outfits. In addition, confederates either helped participants with a difficult virtual task or not, testing the impact of prosocial behaviour. Results showed no effect of group identity salience on positive, negative, anxious or angry emotion word use. However, the confederate’s prosocial behaviour significantly predicted participant positive emotion word use (e.g.&nbsp;good, love, happy) and verbal mimicry. Enacting solidarity through prosocial acts, not belonging to common ingroups, drove positive emotions in VR verbal interactions.<br>
&nbsp;<br>
Title: <strong>Avatar Emotions: Evaluation of Dynamic Facial Expressions Transferred from Human Actors to Embodied Agents</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Tornberg, Christina; Laukka, Petri</strong><br>
Abstract: In the rapidly evolving field of social robotics, understanding the role of emotional expressions in embodied agents is pivotal. Emotional exchanges shape the tone of social interactions and play a crucial role in robot acceptance. Despite this significance, the lack of a methodologically robust pool of emotional stimuli for modeling expressions in embodied agents remains a challenge. In the current study, stimuli were selected from a newly developed database wherein actors conveyed a large number of emotions (N = 44) through facial, vocal and bodily expressions. In addition to video, the stimuli were also recorded using a custom iPhone app specifically designed to capture the facial motion of the actor and transfer that onto an embodied agent. In this evaluation study, we focus on facial expressions of boredom, concentration, confusion, determination, disappointment, doubt, gratitude, and interest – which are all emotions relevant to social interactions. Participants were instructed to rate stimuli portraying the above emotions in a forced-choice experiment. In this experiment, the facial expressions were presented in three conditions: (1) the original actor portrayals, (2) MetaHuman avatars, and (3) the Furhat robot (all presented on a computer screen). Data collection is ongoing, but we will present recognition rates for all emotions across all presentation conditions together with confusion matrices that show which emotions were confused with each other. The comparison of recognition rates across presentation conditions will offer novel insights into the efficient transfer of emotional signals from humans to embodied agents.<br>
&nbsp;<br>
Title: <strong>Social Acceptability of Being Touched by a Virtual Agent</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Boucaud, Fabien; Pelachaud, Catherine; Richard, Grégoire; Thouvenin, Indira</strong><br>
Abstract: Social touch, instances of interpersonal touch considered for their social meanings, has been shown by previous studies to facilitate emotional communication and regulation, provide physical well-being, and be heavily involved in relational bonding. In the field of affective computing, socially interactive agents (SIA, embodied artificial characters designed for social interactions with humans) are being endowed with more and more social abilities (understanding of natural language, emotion recognition, use of non-verbal behaviour) that allow them to communicate emotions, elicit feelings of empathy or to bond with human users. Endowing SIAs with the ability to touch could help them to better communicate emotions and empathy and to improve their relationship-building abilities towards human users, especially for those in situations of isolation. Touch is a very sensitive modality, however, and loses all its positive effects when used invasively. We present a study aimed at determining when touch from an agent encountered in virtual reality (VR) is both socially meaningful (conveys a clear emotion or social intention) and acceptable (not invasive nor unexpected). Users were embodied through a virtual avatar and played a game in VR while being encouraged by our agent, either only verbally or with an accompanying touch. Our results highlight that at the social interaction level, feelings of interactivity and familiarity are important for an acceptable and meaningful touch, while at the physical level, the level of embodiment felt by the users and how much they appreciate the touch sensation modulates how well they accept it.<br>
&nbsp;<br>
Title: <strong>From Virtual to Reality: Mapping Dynamic Emotions and Physiology in VR Environments</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>D’Amelio, Tomás Ariel; Tagliazucchi, Enzo</strong><br>
Abstract: This study ventures into the emerging intersection of affective neuroscience and affective computing by creating the first public database documenting real-time self-reports of emotional experiences in immersive virtual reality (VR) environments, in conjunction with a range of physiological measures. In this way, we aim to deepen our understanding of the temporal dynamics of emotions by using VR to create highly immersive experiences that closely resemble real-world situations. By incorporating both central and peripheral measures, the study aims to capture the complex interplay between subjective emotional experiences and their physiological correlates. The focus is on the fluid nature of emotions, with an emphasis on continuous self-reporting to better understand their evolving nature. VR provides a unique and controlled environment for eliciting and studying emotional responses, thereby enhancing the reliability of the data. Key goals include characterizing the neural and physiological correlates of affective experiences in VR, analyzing their temporal dynamics, and investigating the relationship between subjective reports and physiological data. This comprehensive approach promises not only to enrich the scientific understanding of emotions, but also to improve the predictive capabilities of affective computational models. It represents a significant step forward in accurately capturing and interpreting the full range of human emotional experiences in dynamic, naturalistic settings.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t5" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t5">Parallel Session 3 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-496a8d02{}.cl-496807bc{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49690acc{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49691256{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49691260{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49691261{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49691262{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4969126a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49691274{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-496a8d02"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49691256"><p class="cl-49690acc"><span class="cl-496807bc">Track</span></p></td><td class="cl-49691260"><p class="cl-49690acc"><span class="cl-496807bc">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49691261"><p class="cl-49690acc"><span class="cl-496807bc">Type</span></p></td><td class="cl-49691262"><p class="cl-49690acc"><span class="cl-496807bc">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49691261"><p class="cl-49690acc"><span class="cl-496807bc">Title</span></p></td><td class="cl-49691262"><p class="cl-49690acc"><span class="cl-496807bc">Social Context</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49691261"><p class="cl-49690acc"><span class="cl-496807bc">Time</span></p></td><td class="cl-49691262"><p class="cl-49690acc"><span class="cl-496807bc">15:15 - 16:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4969126a"><p class="cl-49690acc"><span class="cl-496807bc">Room</span></p></td><td class="cl-49691274"><p class="cl-49690acc"><span class="cl-496807bc">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>“I Can Do It(?)”: Examining How Self-Efficacy Shapes Reactions to Envy</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Cohen-Charash, Yochi; Gonzalez, Manuel F; Lee, Soohyun (Ashley); Fleyshmakher, Dina</strong><br>
Abstract: Although painful to experience, envy can motivate people to reduce the envy-provoking gap between themselves and envied others. For example, people can reduce this gap by elevating themselves to the envied’s superior level. We propose that the envious person’s self-efficacy can determine their reaction to envy. Specifically, envious individuals who believe in their ability to achieve goals (high self-efficacy) will strive to elevate themselves to the envied’s superior level. However, envious people experiencing low self-efficacy, will deal with envy differently (e.g., harming the envied, cognitive reappraisal). In two experiments, we found that boosting self-efficacy improved the envious person’s performance when the boost was in a different domain from envy, but not when the boost was in the same domain as envy. We suggest two possible explanations for the impact of domain (dis)similarity on self-efficacy effectiveness. First, affirming one’s value in a domain different from the envy domain can compensate for threats to self-worth in the envy domain (self-affirmation). Since envy is a reaction to a self-threat, self-affirming in a different domain might focus people on their abilities (vs.&nbsp;their inferiorities), thus improving performance. Second, being inferior to another in the envy domain and then, through self-efficacy boosting, learning that one is highly qualified in the same domain may create cognitive dissonance. This cognitive dissonance can undermine the self-efficacy boost, hence inhibiting changes in performance. We will present the two studies and potentially a third study examining these two explanations.<br>
&nbsp;<br>
Title: <strong>Differences Between Happy-for and Schadenfreude: Insights from Structural Topic Modeling.</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Feng, Roujia; Qin, Kaiyang; Cao, Wenrui</strong><br>
Abstract: This study investigated the nuanced positive emotions of happy-for-ness and schadenfreude. Analyzing 774 recall documents of 399 participants via structural topic modeling, we identified a total of 8 topics and observed significant differences in the topics related to the emotions of happy-for-ness and schadenfreude. The findings reveal that, compared to happy-for-ness, the experience of schadenfreude exhibits greater complexity in terms of topics. Firstly, schadenfreude covers a broader spectrum of content whereas happy-for-ness topics tend to be more focused. Specifically, there are 5 topics associated more with schadenfreude compared to 2 topics associated more with happy-for-ness. Besides, topics more prevalent in happy-for-ness experiences exhibit clear and positive connections with both relationship closeness and magnitude. Conversely, for topics more prevalent in schadenfreude documents, the relationships are more complex, with each topic displaying unique connections with relationship closeness and magnitude. The research offers valuable insights into the complexity of these emotions.<br>
&nbsp;<br>
Title: <strong>The Impact of Social Identity Threat on Loneliness among Unemployed People in Germany</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Loreth, Lukas; Simon, Bernd</strong><br>
Abstract: Unemployed people experience stigmatization in daily life which can lead them to worry about not fitting in, of not belonging and to being excluded due to being a member of a stigmatized group – dubbed social identity threat. Thus, experiences of social identity threat can frustrate one’s need for belonging. As prior research indicates, unmet belongingness needs can lead to loneliness. However, the impact of social identity threat on loneliness remains unclear. Thus, this research aimes to answer two questions: How does social identity threat frustrate one’s need for belonging, and does it induce feelings of loneliness? A possible mechanism is that social identity threat triggers negative emotions such as fear, shame, and anger that can proactively undermine one’s sense of social belonging and elicit loneliness. To answer these questions two studies were conducted with unemployed people living in Germany. In Study 1 (N = 445), a panel survey was employed and found that social identity threat positively predicted loneliness at a later point in time. Results also supported the robustness of relationship after controlling for sociodemographic and competing predictor variables. Study 2 (N = 329) provided experimental evidence of this link by manipulating exposure to social identity threat cues through mental imagery. Mediation analysis indicated that this is due to amplified emotions of anger and shame as well as a reduced sense of social belonging. However, fear did not mediate the link between social identity threat and loneliness. Both studies indicate that social identity threat is an antecedent of loneliness.<br>
&nbsp;<br>
Title: <strong>Socio-Communicative Interpretation of Facial Expressions Requires Social Context</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>Allison, Bronagh M; McKeown, Gary</strong><br>
Abstract: The debate over the function of facial expressions continues with the Behavioural Ecology View of facial displays (BECV), which argues for a more socio-communicative function for facial expression, compared with the Basic Emotions Theory (BET), which gives felt emotion as the prime causal basis for facial expressions. Gossip is a common form of human socio-communicative behaviour. Observations of gossip can be an opportunity to examine the social context-driven display of facial expressions. We predicted that facial expressions associated with the emotion term surprise—in the BET tradition—occurring in response to social information will be interpreted differently when presented in the context of the social interaction in which it occurs. Moments of gossip from the dyadic conversational social interactions in the Belfast Storytelling Database were coded. Participants (N=273) were presented with video clips containing gossip or a control group with non-gossip (backchanneling). They were presented in two contexts: minimal and full. Minimal-context clips showed only the receiver’s facial expression and no audio, while full-context clips presented interlocutors and audio. We fitted linear mixed-effect models in a 2 (social signal: gossip or non-gossip) x 2 (context: full or minimal) factorial design to examine their relationship with perceived levels of gossip and surprise. Absolute levels of perception of gossip and surprise were similar. We found participants perceived significantly more gossip in the full context, while there were no significant differences in perception of surprise dependent on context. The facial expression of surprise may have a default interpretation of surprise but requires socio-communicative context to be perceived as gossip-related.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t6" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t6">Parallel Session 3 : T6</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4974b958{}.cl-497235a2{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4973381c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49733fba{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49733fc4{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49733fc5{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49733fce{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49733fcf{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49733fd0{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4974b958"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49733fba"><p class="cl-4973381c"><span class="cl-497235a2">Track</span></p></td><td class="cl-49733fc4"><p class="cl-4973381c"><span class="cl-497235a2">T6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49733fc5"><p class="cl-4973381c"><span class="cl-497235a2">Type</span></p></td><td class="cl-49733fce"><p class="cl-4973381c"><span class="cl-497235a2">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49733fc5"><p class="cl-4973381c"><span class="cl-497235a2">Title</span></p></td><td class="cl-49733fce"><p class="cl-4973381c"><span class="cl-497235a2">Language</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49733fc5"><p class="cl-4973381c"><span class="cl-497235a2">Time</span></p></td><td class="cl-49733fce"><p class="cl-4973381c"><span class="cl-497235a2">15:15 - 16:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49733fcf"><p class="cl-4973381c"><span class="cl-497235a2">Room</span></p></td><td class="cl-49733fd0"><p class="cl-4973381c"><span class="cl-497235a2">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Interplay Between Emotion and Language: Evidence from Children with and without Developmental Language Disorder</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Aguilera, Mari ; Ahufinger, Nadia; Guerra, Ernesto; Verdaguer-Ribas, Oriol; Mayo, Coral; Andreu, Llorenç; Sanz-Torrent, Mònica</strong><br>
Abstract: Recent empirical evidence suggests a strong interconnection between emotion and language during development. This study has two objectives: i) to analyze the impact of language on emotional regulation in children with and without developmental language disorder (DLD); ii) to evaluate the impact of emotional prosody on emotional identification in children with and without DLD. For the first objective, vocabulary was assessed in time 1 and emotional regulation in time 2 (four years later) in a sample of 43 school-age children with and without DLD. For the second, two experiments were run in 60 school-age children with and without DLD through the eye-tracking technique. Four emotional faces were presented at the same time as a sentence, explicit in Exp1 (e.g., “Laura is happy”) and implicit in Exp2 (e.g., “Cristina escapes from the dog”), was heard. The results of the first objective showed that expressive language significantly predicted the emotional regulation assessed four years later in all children. On the other hand, the results of the eye-tracking showed in both experiments that typically developing (TD) children discarded prosodic cues to identify emotions and they preferred the face that is congruent with the semantic content of the phrase. In children with DLD, instead, prosodic cues interfere more with emotion identification. In conclusion, vocabulary richness significantly impacts emotional regulation, moreover, emotional prosody is a key dimension for emotional understanding, especially in population with DLD.<br>
&nbsp;<br>
Title: <strong>Putting Feelings into Words: Do Moroccan Learners of English Describe Others’ Emotions as Native Speakers?</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>El asri, Khalid</strong><br>
Abstract: Emotions are expressed and conceptualized differently across cultures (Pavlenko, 2005). Considering the languages investigated in this study, differences in the conceptualization of emotions between English and Moroccan Arabic would likely be greater since both varieties belong to distinct cultural dimensions (individualism and collectivism). Differences in the way emotions are conceptualized in these varieties, therefore, would pose problems for Moroccan learners of English, because they are required to make finer-grained distinction in using L2 emotion terms that may not exist in their L1. Nevertheless, it is predicted that emotion description would not be as difficult for advanced learners as intermediate learners. Rather, advanced learners would approximate native speakers in describing emotions of others since the range of situations and contexts in which English emotions are used require a higher proficiency level of English. To verify this hypothesis, 60 native speakers of English, 60 advanced learners, and 60 intermediate learners were asked to watch a short film and describe how actors felt at some suggested scenes by using one emotion word. The results revealed that advanced learners of English had rich emotion vocabularies and many of their lexical choices approximated those of native speakers. They, however, did not manage to provide the same emotion terms for some scenes as native speakers. On the other hand, intermediate learners quite managed to provide emotion terms as native speakers, but they differed from native speakers in many of their lexical choices. Based on these findings, some pedagogical implications are suggested.<br>
&nbsp;<br>
Title: <strong>Detecting Emotions in the Speech of Patients with Acquired Brain Injury: a Feasibility Study</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Klein, Salomé; Krasny-Pacini, Agata; Todirascu, Amalia; Vassiliadou, Hélène</strong><br>
Abstract: Patients with an Acquired Brain Injury (ABI) suffer from emotional dysregulation for which treatments lack evidence. Patient’s lack of insight and alexithymia biases usual patient-reported outcome measures. The aim of the study is to explore a novel objective measure of emotional regulation through linguistic markers, that could serve to test the effectiveness of Dialectical Behavior Therapy (DBT), in ABI. Methods: Along with other usual outcome measures, 45 patients with chronic ABI were voice-recorded on 40-90 minutes semi-directive interview and picture description, in which they narrated emotionally-charged memories and explained their perception of free will according to their emotional dysregulation at the time points 5-month apart: 5 months baseline, and immediately before therapy (to explore retest effects and stability of response) and immediately after therapy (to explore for gains due to a 5-month intensive DBT). Outcome measures consisted of the typology of explicit/implicit emotional expressions, the annotation and the automatic detection of emotional scripts in patients’ speech. Our protocol considers that emotional narration does not only involve prototypical expressions (e.g.&nbsp;‘I am angry’), but a multitude of emotional means (designated, suggested and/or displayed emotions), allowing thus to measure differently the evolution of patients regarding naming and recognizing emotions. We present preliminary results about the feasibility of this measure and the performance of the annotation guide by comparing it to other projects (Emotex, Emolex). This exploratory measure considers both neuropsychological and linguistic literature and conceptualize ABI disorders as the result of emotions that are too strong and/or poorly managed by the patient.<br>
&nbsp;<br>
Title: <strong>Shared Narratives: A Corpus-Based Study of Gendered Language in Depression Podcasts</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>Tomas, Frédéric; Braun, Nadine; Goudbeek, Martijn</strong><br>
Abstract: Women are generally believed to be more emotionally expressive and perceptive than men, an idea which is at least partially supported by scientific studies. However, results are inconsistent. This can be potentially problematic since such believes nurture existing gender stereotypes. Specifically in clinical settings, this may lead to a myriad of issues. This study therefore tested the hypothesis that men and women exhibit distinct linguistic patterns in oral conversations about their own depression in a podcast setting as a part of our Affective Language in Social mediA (ALISA) corpus. We compiled 13 transcripts (Nwords = 21,423) from a public depression podcast. In each episode, the host posed an open-ended question to prompt guests to share their depression experiences. Uninterrupted responses were transcribed and cleaned for analysis. The Linguistic Inquiry and Word Count (LIWC) was used to extract common gender-specific language. Based on inferential and Bayesian approaches and considering the number of words in each transcript, ANCOVAs were run to test the hypothesis. Results reveal a consistent absence of significant gender-based differences in linguistic behavior. Bayesian Factor values consistently favored null models, contradicting the prediction that men and women speak differently when discussing depression. Discussion points include challenging traditional assumptions and stereotypes about gender-specific communication in mental health contexts, emphasizing the apparent universality of verbal expression surrounding depression, and considering implications for mental-health support strategies that transcend traditional gender norms. Our future research will focus on expanding the ALISA corpus to better understand individuals’ naturalistic linguistic behavior in mental-health contexts.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-3-t7" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-3-t7">Parallel Session 3 : T7</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-497ed3ac{}.cl-497c5140{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-497d53d8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-497d5b4e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-497d5b4f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-497d5b58{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-497d5b59{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-497d5b62{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-497d5b63{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-497ed3ac"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-497d5b4e"><p class="cl-497d53d8"><span class="cl-497c5140">Track</span></p></td><td class="cl-497d5b4f"><p class="cl-497d53d8"><span class="cl-497c5140">T7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-497d5b58"><p class="cl-497d53d8"><span class="cl-497c5140">Type</span></p></td><td class="cl-497d5b59"><p class="cl-497d53d8"><span class="cl-497c5140">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-497d5b58"><p class="cl-497d53d8"><span class="cl-497c5140">Title</span></p></td><td class="cl-497d5b59"><p class="cl-497d53d8"><span class="cl-497c5140">Theory and Function</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-497d5b58"><p class="cl-497d53d8"><span class="cl-497c5140">Time</span></p></td><td class="cl-497d5b59"><p class="cl-497d53d8"><span class="cl-497c5140">15:15 - 16:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-497d5b62"><p class="cl-497d53d8"><span class="cl-497c5140">Room</span></p></td><td class="cl-497d5b63"><p class="cl-497d53d8"><span class="cl-497c5140">Moyola: PFC/02/017</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Being Facially Expressive is Socially Advantageous</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Kavanagh, Eithne; Whitehouse, Jamie; Waller, Bridget M</strong><br>
Abstract: Individuals vary in how they move their faces in everyday social interactions. In a first large-scale study, we measured variation in dynamic facial behaviour during social interaction and examined dyadic outcomes and impression formation. In Study 1, we recorded semi-structured video calls with 52 participants interacting with a confederate across various everyday contexts. Video clips were rated by 176 independent participants. In Study 2, we examined video calls of 1315 participants engaging in unstructured video-call interactions. Facial expressivity indices were extracted using automated Facial Action Coding System analysis and measures of personality and partner impressions were obtained by self-report. Facial expressivity varied considerably across participants, but little across contexts, social partners or time. Prototypical expressions of emotion also did not vary according to behavioural context as might be expected. In Study 1, more facially expressive participants were more well-liked, agreeable, and successful at negotiating (if also more agreeable). Participants who were more facially competent, readable, and perceived as readable were also more well-liked. In Study 2, we replicated the findings that facial expressivity was associated with agreeableness and liking by their social partner, and additionally found it to be associated with extraversion and neuroticism. Across both studies, prototypical expressions of emotion were produced at a low rate. Findings suggest that facial behaviour is a stable individual difference that proffers social advantages, pointing towards an affiliative, adaptive function.<br>
&nbsp;<br>
Title: <strong>A Systematic Examination of the Causal Determinants of Affect</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Szűcs, Tamás; Wu, Yufei; Tuerlinckx, Francis; Moors, Agnes</strong><br>
Abstract: A large amount of research effort goes into studying affect, its constituent elements, its dynamics, and its role in mental disorders, mental health, resilience, and decision making. However, surprisingly little is known about the causal determinants of affect. Although several determinants have been proposed by different theories, systematic research comparing the impact of the various determinants is scarce. Previous research from disparate areas, such as consumer research, experimental aesthetics, and affective science, often only incidentally reported on the effects and interactions of affect determinants using various operationalizations, making the scarce findings difficult to compare and synthesize. Here, we examine the effects of goal congruence, goal relevance, unexpectedness, and reward prediction errors on self-reported affect in a simple probabilistic choice task. Participants are presented with a number of doors, each hiding a monetary reward or loss. They are informed about the probabilities of the possible outcomes (e.g., 3 doors hide +2€, 2 doors hide -1€). After a participant has chosen a door, and the outcome is revealed, they are asked to report on their subjective affect using a single-item measure. We report the effects and interactions of the selected causal determinants of affect, and compare the different operationalizations of these determinants found in the literature. We hope that this systematic study can help map out the complexity involved in the antecedents of affect and contribute to providing a stable foundation for affective science.<br>
&nbsp;<br>
Title: <strong>Affective and Computational Mechanisms Underlying Pavlovian Learning Biases</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Stussi, Yoann; Sander, David</strong><br>
Abstract: Pavlovian threat conditioning is a fundamental process by which individuals learn to anticipate threats in the environment. While research has shown that humans learn more rapidly and more persistently to associate negative and positive emotional stimuli with aversive events beyond their inherent threat value, the computations underlying these Pavlovian learning biases remain unclear. Building on work testing the predictions of different emotion theories, we here examine the computational underpinnings of Pavlovian learning biases for negative and positive emotional stimuli. We applied computational-modeling techniques to data from four experiments (N = 247) using a differential Pavlovian threat conditioning paradigm. Threat-relevant (angry faces or snakes), positive-relevant (baby faces, happy faces, or erotic stimuli), and neutral (neutral faces or colored squares) stimuli were used as conditioned stimuli, with skin conductance response serving as an index of learning. Results indicate that a reinforcement-learning model distinguishing between excitatory (e.g., learning from reinforcement during acquisition) and inhibitory (e.g., learning from the absence of reinforcement during extinction) learning best explained the observed data. Whereas no evidence for faster Pavlovian conditioning was found at the computational level, both threat- and positive-relevant stimuli were associated with a lower inhibitory learning rate compared to neutral stimuli, contributing to weakening extinction learning to affectively relevant stimuli. These findings offer new insights into the affective and computational mechanisms underlying Pavlovian learning biases and advance our understanding of how humans learn to attribute and update affective value to their environment.<br>
&nbsp;<br>
Title: <strong>A Heuristic Approach to Categorize Emotion Theories in Psychology</strong><br>
Time: 16:00-16:15<br>
Authors: <strong>Muto, Sera</strong><br>
Abstract: This theoretical study presents a heuristic approach to categorize emotion theories in psychology. There are numerous emotion theories that researchers, especially early career researchers, including graduate and undergraduate students, may consider to believe and adapt for their research. It is important to categorize emotion theories appropriately and know their similarities and differences to study emotions. Thus, this study examines a heuristic approach to determine critical similarities and differences in categorizing emotion theories and creates a simplified chart to select an appropriate theory based on the researcher’s belief about emotions. Based on Moors’ (2022) typology of emotion theories in psychology, this study focuses on six emotion theories: (a) evolutionary theories or basic emotion theories, (b) network theories, (c) appraisal theories, (d) Moors’ goal-directed theory, (e) Barrett’s psychological constructionist theory, and (g) Russell’s psychological constructionist theory. A theoretical review found that there are five fundamental questions to differentiate these emotion theories: (1) scientific status (whether the folk set of emotion can be a scientific set), (2) componential causal mechanism (whether there are causal relationships in components of emotion), (3) emotion-specific mechanism (whether special-purpose mechanism is involved in the emotion process), (4) innate or learning (whether emotion process is innate rather than learned), and (5) categorization (whether categorization is necessary to experience emotions). This argument leads to the fundamental question of what emotions are; however, the results suggest that these five questions may be enough to categorize influential emotion theories in psychology, and will help to decide which theory to believe.<br>
&nbsp;<br>
Title: <strong>No Laughing Matter: Creating and Interpreting Emotions Through Interaction</strong><br>
Time: 16:15-16:30<br>
Authors: <strong>Howes, Christine; Maraev, Vladislav; Breitholtz, Ellen</strong><br>
Abstract: The theory of constructed emotion (Barrett, 2017) posits that emotions are not present in the brain a priori, but rely on our interpretation of affective states. This interpretation is driven by shared cultural emotion concepts which we use to categorise our feelings. However, this view places too much emphasis on internal cognition. In our view, the driving force for creating and interpreting emotion is interaction, and ‘emotions’ are constructed through discourse. One advantage of this approach is that emotions are not taken to be different in this regard from other types of concepts. Underpinning this is an action-based account of meaning (Eshghi et al., 2022). Any given action (including linguistic actions) provides constraints on potential follow-up actions, but does not determine them. Agents opportunistically pursue affordances relevant to their current goals by engaging directly with the environment, including their interlocutors. This serves to confirm or disconfirm their expectations rather than enriching intermediate brain-internal representations. Following Breitholtz (2020), we model affordances in the form of topoi – non-monotonic and defeasible principles of reasoning recognised within a socio-cultural community. For example, in the case of emotion the associated topoi for some collection of actions may suggest an interpretation of one’s own or another’s behaviours as due to nervousness or, conversely, excitement, depending on the interactional context (see also Frijda et al., 2014). We provide examples of laughter in dialogue, where, for example, laughter may be interpreted as signalling nervousness in a job interview, or mis-interpreted as displaying a non-serious stance towards the situation. Barrett, L. F. (2017). The theory of constructed emotion: An active inference account of interoception and categorization. Social Cognitive and Affective Neuroscience 12 (1): 1-23. Breitholtz, E. (2020). Enthymemes and Topoi in Dialogue: The Use of Common Sense Reasoning in Conversation. Leiden, The Netherlands : Brill. Eshghi, A., Howes, C. &amp; Gregoromichelaki, E (2022). Action coordination and learning in dialogue. In Bernardy, J-P, Blanck, R, Chatzikyriakidis, S et al (editors), Probabilistic Approaches to Linguistic Theory. CSLI Publications Frijda, N. H., Ridderinkhof, K. R., &amp; Rietveld, E. (2014). Impulsive action: emotional impulses and their control. Frontiers in Psychology, 5, 518.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-4-t1" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-4-t1">Parallel Session 4 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4988f7e2{}.cl-49866ec8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49877390{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49877b24{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49877b2e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49877b2f{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49877b30{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49877b38{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49877b39{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4988f7e2"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49877b24"><p class="cl-49877390"><span class="cl-49866ec8">Track</span></p></td><td class="cl-49877b2e"><p class="cl-49877390"><span class="cl-49866ec8">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49877b2f"><p class="cl-49877390"><span class="cl-49866ec8">Type</span></p></td><td class="cl-49877b30"><p class="cl-49877390"><span class="cl-49866ec8">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49877b2f"><p class="cl-49877390"><span class="cl-49866ec8">Title</span></p></td><td class="cl-49877b30"><p class="cl-49877390"><span class="cl-49866ec8">The Interplay of Intra- and Interpersonal Processes in Social Emotions</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49877b2f"><p class="cl-49877390"><span class="cl-49866ec8">Time</span></p></td><td class="cl-49877b30"><p class="cl-49877390"><span class="cl-49866ec8">09:15 - 10:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49877b2f"><p class="cl-49877390"><span class="cl-49866ec8">Room</span></p></td><td class="cl-49877b30"><p class="cl-49877390"><span class="cl-49866ec8">Whitla Hall</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49877b38"><p class="cl-49877390"><span class="cl-49866ec8">Abstract</span></p></td><td class="cl-49877b39"><p class="cl-49877390"><span class="cl-49866ec8">Emotions shaped in interaction with the social context, such as others' emotional expressions, norms and values, or perceivers‚Äô interaction goals. Although the importance of interpersonal processes is widely acknowledged, much research treats social emotions as intrapsychic phenomena, overlooking the interplay between intra- and interpersonal aspects. Across disciplines and methodological approaches, this symposium unites research providing new insights into how intra- and interpersonal processes interact in shaping emotional outcomes. Talk 1 highlights this interplay showing that the effectiveness of music teachers' evaluative emotional expressions in influencing students' performance varies depending on personality. Talk 2 dissociates internal and external self-relevance in envy, showing that being outperformed in internally self-relevant domains fosters benign envy, while being outperformed in domains valued by others fosters malicious envy. Talk 3 elucidates the emergence of embarrassment in infants and young children, exploring the influence of contextual factors that question traditional perspectives on embarrassment's onset and prerequisites. Talk 4 examines economic behavior during negotiations, revealing that individuals strategically exaggerate expressions of supplication emotions like sadness, but not appeasement emotions like shame. Talk 5 demonstrates that shame and pride and their action tendencies of concealment and exposure are elicited even by events occurring in private and that their intensity hinges also on the relevance of observers to individuals' status showing that intrapersonal and interpersonal theories of pride and shame need to be integrated. Taken together, these studies provide new insights into intra- and inter-personal processes of emotions and highlight why it is important to take their interactions into account.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>How Music Teachers’ Emotional Expressions Shape Students’ Performance: “c’est Le Ton Qui Fait La Musique”</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Gerben van Kleef, Eftychia Stamkou</strong><br>
Abstract: Teachers, parents, and other feedback providers commonly express positive emotions to stimulate learning. When students’ performance is below expectations, however, feedback providers may be inclined to express negative emotions. How these different emotional styles shape students’ development remains poorly understood. Here we investigate the effects of music teachers’ positive versus negative emotional expressions on their students’ musical performance. We draw on Emotions as Social Information (EASI) theory, which postulates that the effects of emotional expressions depend on targets’ dispositional information-processing motivation (which determines whether feedback is extracted from emotional expressions) and agreeableness (which determines the perceived appropriateness of positive vs.&nbsp;negative expressions). We followed music teachers and students during regular learning sessions. One week before the sessions, we assessed students’ information-processing motivation and agreeableness. Immediately after the sessions, students reported on their teachers’ emotional expressions during the session, and teachers rated the performance of students on two musical tasks. An outside expert evaluated recordings of a subset of these performances. Consistent with the EASI framework, students who were confronted with stronger positive emotional expressions of their teachers performed better to the extent that they were lower on information-processing motivation and higher on agreeableness. Conversely, students who were confronted with stronger negative emotional expressions performed better to the degree that they were higher on information- processing motivation and lower on agreeableness. These findings indicate that both positive and negative emotional expressions of teachers can benefit students’ performance, depending on the student’s personality. We discuss implications for feedback, emotions, and education.<br>
&nbsp;<br>
Title: <strong>Chasing Dreams or Social Standards? How Internal and External Self-Relevance Shape Envy.</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Jan Crusius</strong><br>
Abstract: What do people envy? People envy others for subjectively important characteristics, achievements, and possessions—self-relevance is a necessary precondition for envy. However, self- relevance can have different sources. It can be defined by what people truly value themselves, i.e., what is internally self-relevant. It can also be defined by what is valued by their social context, i.e., what is externally self-relevant. This distinction could matter for how envy evolves. Based on their appraisal patterns, we predicted that internal and external self-relevance differentially shape the distinct forms of envy: Internal self-relevance should promote benign envy (entailing upward motivation) and decrease malicious envy (entailing hostility). External self-relevance should decrease benign envy and increase malicious envy. We conducted 7 preregistered studies (total N = 2.050). In the first set, we measured internal and external self-relevance of certain values within subjects. In the second set, we manipulated internal and external self-relevance between subjects. We measured participants’ envious reactions towards an ideal person embodying these values. Meta-analyses support that high internal self-relevance predicted and lead to more benign envy and to less malicious envy. External self-relevance was associated with less benign and more malicious envy, although this effect was less consistent. Thus, being outperformed in a domain that people value for its own sake fosters benign envy. In contrast, chasing success in a domain that is prescribed by their social group may set people up to experience malicious envy.<br>
&nbsp;<br>
Title: <strong>Self-Conscious Emotional Arousal in Infancy and Early Childhood</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Milica Nikolic, Cristina Colonnesi, Disa Sauter</strong><br>
Abstract: The study of self-conscious emotional arousal in young children has been limited, possibly due to the assumption that complex socio-cognitive skills, such as self- awareness and mentalizing, are prerequisites for the emergence of self-conscious emotions. However, recent theoretical and empirical developments in developmental and cognitive sciences suggest that children may, in fact, experience and express self-conscious emotional arousal during social interactions from an early age. Here, we present findings from a proof-of-concept study where we induced and measured self-conscious emotional arousal, observed through facial expressions and physiological blushing, in children aged 3-5 years. During a photoshoot, children received compliments from the experimenter, and in the control condition, another person underwent the same procedure. Results indicated that children exhibited significantly more self-conscious emotional arousal, as indicated by more coy-smiles, when receiving compliments compared to when another person receives compliments. Building on this, we are currently setting up a study involving infants aged 6-36 months to investigate whether they, like older children, might experience and express self-conscious emotional arousal during social interactions. In this study, we also measure infants’ self-awareness using the mirror self-recognition task, aiming to determine whether self-conscious emotional arousal depends on the ability to recognize oneself. Preliminary results from this study, along with those from the proof-of-concept study, will be presented at the conference. These findings will answer whether and when infants demonstrate self-conscious emotional arousal in social interactions, thereby shedding light on the prerequisites of self-conscious emotional arousal.<br>
&nbsp;<br>
Title: <strong>The Strategic Display of Supplication Versus Appeasement Emotions in Negotiations</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Zi Ye, Eric van Dijk, Gert-Jan Lelieveld</strong><br>
Abstract: The current research focuses on the strategic use of supplication emotion (i.e., emotions like disappointment and sadness, which serve as a call for help) and appeasement emotions (i.e., emotions like guilt and shame, which communicate that one has done something wrong). Given that negotiators realize that their emotions can influence their opponents’ behaviors, negotiators may strategically communicate their emotions to obtain higher outcomes by adjusting the intensity of their emotions. The current research aims to investigate whether negotiators choose to exaggerate or downplay their disappointment or guilt (Study 1) and their sadness or shame (Study 2). To study this, we designed a two-person Ultimatum Bargaining setting in which participants indicated their truly experienced emotions (how much disappointment/sadness and guilt/shame they experienced) and what they wanted to communicate to their opponent (how much disappointment/sadness and guilt/shame they wanted to communicate) on a scale from 1-100. Participants indicated their experienced and communicated emotions either before or after opponents made their offer. Results showed that participants exaggerated the intensity of their disappointment (Study 1) and sadness (Study 2) before, but not after, opponents made their offer. Participants neither downplayed nor exaggerated their guilt (Study 1) and their shame (Study 2) both before and after opponents made their offer. Moreover, exaggerating disappointment was positively related to the motivation to earn as much as possible and negatively related to prosocial motivations. The current findings add to the literature on emotion deception and on the interpersonal effects of emotion in general.<br>
&nbsp;<br>
Title: <strong>A Systematic Examination of Shame and Pride’s Functions and Mechanisms Through Concealment and Exposure Behaviors</strong><br>
Time: 10:15-10:30<br>
Authors: <strong>Yiftach Argaman</strong><br>
Abstract: Shame and pride are traditionally explained through two models. The Information Threat Model (Sznycer, 2010) focuses on interpersonal processes, positing that shame and pride arise when an event potentially impacts one’s social status. Conversely, the Process Model of Self-Conscious Emotions (Tracy &amp; Robins, 2004) focuses on intrapersonal processes, positing that individuals feel shame or pride when events are incongruent or congruent with their identity goals. While both models assume link between shame-concealment and pride-exposure behaviors (the S/P-C/E association), they have different predictions regarding the conditions that elicit shame and pride and the content of concealment/exposure behaviors. In four experimental studies (Total N=1,000), we systematically examined the S/P-C/E association while juxtaposing the models’ predictions. Experiment 1 developed an experimental procedure aimed at assessing the S/P-C/E relationship. Shame and pride were evoked by randomly assigning participants to either low or high fictitious IQ score conditions. Concealment/exposure behaviors were then assessed. Results provide strong evidence for the S/P-C/E association. Supporting the effect of interpersonal processes, Experiment 2 found that the S/P-C/E association is proportional to the potential impact of exposure on individuals’ status. Supporting the effect of intrapersonal processes, we found that shame and pride drive individuals to conceal and expose themselves rather than only information about the event that triggered the emotion (Experiments 3-4), and that the S/P-C/E association occurs even when shame/pride is elicited in private events that remain undisclosed to others (Experiment 4). The (in)congruency of the results with existing models and the need for an integrative model are discussed.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-4-t2" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-4-t2">Parallel Session 4 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4993b772{}.cl-4990af14{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4991b382{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4991bb02{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4991bb0c{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4991bb0d{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4991bb16{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4991bb17{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4991bb18{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4993b772"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4991bb02"><p class="cl-4991b382"><span class="cl-4990af14">Track</span></p></td><td class="cl-4991bb0c"><p class="cl-4991b382"><span class="cl-4990af14">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4991bb0d"><p class="cl-4991b382"><span class="cl-4990af14">Type</span></p></td><td class="cl-4991bb16"><p class="cl-4991b382"><span class="cl-4990af14">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4991bb0d"><p class="cl-4991b382"><span class="cl-4990af14">Title</span></p></td><td class="cl-4991bb16"><p class="cl-4991b382"><span class="cl-4990af14">Affective Experiences Across the Adult Lifespan: Age-Related Differences, Mechanisms, and Implications</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4991bb0d"><p class="cl-4991b382"><span class="cl-4990af14">Time</span></p></td><td class="cl-4991bb16"><p class="cl-4991b382"><span class="cl-4990af14">09:15 - 10:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4991bb0d"><p class="cl-4991b382"><span class="cl-4990af14">Room</span></p></td><td class="cl-4991bb16"><p class="cl-4991b382"><span class="cl-4990af14">Bann: PFC/0G/024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4991bb17"><p class="cl-4991b382"><span class="cl-4990af14">Abstract</span></p></td><td class="cl-4991bb18"><p class="cl-4991b382"><span class="cl-4990af14">Individuals from different age groups differ in their affective experiences. In this symposium, we leverage theory-based approaches and cutting-edge statistical tools to describe the patterns of these age-related differences, to advance understanding of their underlying mechanisms, and to trace implications for well-being and health across the adult lifespan. The first presentation investigates age differences in emotional responding to controlled emotional film clips in a lifespan sample. Cross-random-effects models showed more intense and more complex responses in older than younger participants, with pronounced differences across emotions. The second presentation introduces a formalized theoretical approach to affect dynamics and employs this to everyday affective experience in an age-diverse sample. Results indicate complex, multi-directional age differences in affective processes. The third presentation investigates how people‚Äôs perception of time left to live is linked to age differences in everyday affective experience. Multilevel models showed that feeling closer to death was related to more negative affect, with strongest associations in middle-aged adults. Using data from longitudinal experience-sampling and dynamical structural equation modeling, the fourth presentation demonstrates age-related increases in prospective affect-health links throughout adulthood. These results suggest that health affects emotional experiences, and that emotional experiences affect health more strongly as people age. The fifth presentation uses parallel growth mixture modeling to investigate links between affective wellbeing and survival. This approach demonstrates the value of modeling multidimensional trajectories of affective well-being and their heterogeneous links to survival. Together, the symposium will showcase recent important advances in research on emotional aging.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotional Reactivity to 66 Film Clips from Adolescence to Old Age</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Antje Rauers, Lukas Aaron Knitter, Markus Studtmann, Michaela Riediger</strong><br>
Abstract: Film clips are frequently used to induce emotions in people from different age groups, often proceeding from the implicit assumption that such stimuli have comparable effects across age groups. However, conceptual reasons and empirical findings warrant doubts in this regard. Past evidence on age differences in subjective reactivity to emotional films is inconclusive, which may be due to the limited – and heterogeneous – age range, number of target emotions, and number of individual film stimuli included in past studies. The present study seeks to bridge these inconclusive results. We obtained N = 5843 individual ratings from N=99 persons (adolescents, younger adults, middle-aged adults, and older adults) who rated their subjective experience to N=66 film clips. These were selected based on appraisal theory to induce happiness, fear, anger, sadness, disgust, or no emotion (neutral stimuli). We used crossed- random effects models to test for age differences in target-emotion intensity and emotion specificity (the tendency to primarily respond with the target emotion over other emotions). Age effects varied across target emotions and film clips. For most emotions, older adults and adolescents responded more strongly than younger and middle-aged adults, while no age differences were found for disgusting and neutral films. Emotional specificity was comparatively lower in older adults versus younger age groups for disgusting and neutral films, but higher, for happy films. Together, these results suggest that in studies using film clips as emotion-induction stimuli, age-fairness should not be taken for granted: It may be rather the exception than the rule.<br>
&nbsp;<br>
Title: <strong>Age Differences in Affect Dynamics: Testing Predictions of Socioemotional Selectivity Theory with the MIVA Model</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Maria Wirth, Andreas Voss, Klaus Rothermund</strong><br>
Abstract: Emotional aging research is dominated by the idea of age-related improvements that result from shifts in motivation. Socioemotional selectivity theory (SST) proposes that as individuals age, they increasingly favor emotion-related goals and savor positive but avoid negative emotions. Previous age-comparative studies on everyday emotional experience typically were descriptive or studied the processes underlying emotional experience in isolation. We aimed at a more holistic approach to test hypotheses derived from SST regarding age-related differences in general emotional dispositions (i.e., anchoring), emotional reactivity, and emotion regulation by using a comprehensive computational approach. We applied our Model of Intraindividual Variability in Affect (MIVA) to data on everyday emotional experiences in an age-diverse sample (N = 378, age range 14 – 86 years). Parameter estimations were carried out within a Bayesian framework. Our results provide partial support for predictions derived from SST. Consistent with SST, affect elicited by pleasant events was down-regulated less by older adults and affect elicited by unpleasant events was down-regulated more by older compared to younger adults. Inconsistent with SST, anchoring showed a negative age-related trend, indicating a more positive general affect disposition in younger, not older adults. Reactions to pleasant events showed no age-related differences. Reactivity to unpleasant events was highest in midlife and lower for younger and older adults. We discuss the broader implications of our approach for understanding emotional development across the lifespan.<br>
&nbsp;<br>
Title: <strong>Daily Subjective Aging and Affective Dynamics</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Shevaun D. Neupert, Lyndsey N. Graham</strong><br>
Abstract: A core tenet of Socioemotional Selectivity Theory is that perception of time remaining in life plays a key role in the selection and pursuit of emotion regulation goals. The current study examined this idea within a daily diary framework, where subjective aging was captured by perceptions of nearness to death and perceptions of accelerated aging on consecutive days. Age differences in the within-person coupling between daily subjective aging reports and daily affective dynamics were tested. A 14-day daily diary study of 440 adults (M age = 65, range 50- 85) in the U.S. was conducted where participants reported on their subjective nearness to death, accelerated aging, physical health, positive affect, and negative affect each day. Multilevel models were conducted separately for positive and negative affect, adjusting for daily physical health. Individual differences in feeling farther away from death and a slower rate of aging were each associated with higher levels of positive affect. Daily negative affect was predicted by both within-person and between-person constructs. People who reported feeling subjective closer to death reported higher levels of negative affect. At the within-person level, on days when people reported feeling subjectively closer to death than their own average, they experienced an increase in negative affect. A significant interaction revealed that this effect was particularly strong among adults in midlife. These results suggest that daily manifestations of perceptions of limited time remaining in life are salient for daily affective dynamics, and that this salience is particularly pronounced among middle-aged adults relative to older adults.<br>
&nbsp;<br>
Title: <strong>Affect-Health Coupling from Adolescence to Old Age: Evidence from a Longitudinal Experience- Sampling Study</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Michaela Riediger, Fabian Münch, Jennifer Bellingtier, Elisabeth S. Blanke, Cornelia Wrzus, Gloria Luong</strong><br>
Abstract: While there is consensus that physical and emotional well-being are related, divergent claims have been made about possible age-related differences. This study aimed to investigate potential age-related differences in concurrent and prospective associations between everyday affective experiences and individuals’ health and physical well-being. We used two waves of measurement burst data (wave 1: N = 398, 12 – 90 years; wave 2: N = 365, 14 – 88 years; inter- wave interval: M = 2.53 years). Per wave, participants provided 54 experience samples of their momentary affective and physical well-being. In addition, several person-level health indicators were assessed, including subjective health as well as number and severity of health conditions and complaints. Overall, results point to an age-related increase in affect-health coupling: The older participants were, the more strongly were health problems associated with lower concurrent affective well-being. Age moderations also emerged for prospective affect-health links, both across shorter (hours) and longer time intervals (years). Dynamical structural equation modeling showed an age-related increase in cross-lagged associations between individuals’ time series of momentary emotional and physical well-being, assessed while participants pursued their normal daily routines. Similarly, moderated cross-lagged panel models yielded age-related increases in cross-lagged associations between everyday emotional well-being and indicators of physical health, assessed 2.5 years apart. Such age moderations emerged in both directions of cross-lagged associations (i.e., affect predicting later health, and health predicting later affect). This suggests that both the affective relevance of health impairments and the health-protective role of daily affective experiences may become more pronounced with advancing age.<br>
&nbsp;<br>
Title: <strong>Trajectories of Affective Well-Being and Survival in Middle-Aged and Older Adults</strong><br>
Time: 10:15-10:30<br>
Authors: <strong>Anthony D. Ong, Dakota W. Cintron</strong><br>
Abstract: Affective experiences are key components of subjective well-being with important implications for health. However, little is known about heterogeneous longitudinal affect trajectories and their links to survival. This study identified joint trajectory subgroups based on 18-year changes in positive and negative affect and examined their differential associations with mortality risk. Participants were 3,250 adults (aged 39-93 years) from the Midlife in the U.S. study assessed over three waves (1995-2013). Parallel growth mixture modeling revealed three subgroups: (1) improving (increasing positive affect, decreasing negative affect), (2) deteriorating (decreasing positive affect, increasing negative affect), and (3) flourishing (high, stable positive affect, low, stable negative affect). Adjusting for baseline demographic and health covariates, Cox proportional-hazard results showed the improving group had the lowest mortality risk (HR 0.82, 95% CI 0.35,1.32) and the deteriorating group had the highest mortality risk (HR 1.86, 95% CI 1.34,3.55), relative to flourishing. These findings highlight the importance of modeling multidimensional trajectories of affective well-being and their heterogeneous links to survival.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-4-t3" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-4-t3">Parallel Session 4 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-499e1bb8{}.cl-499aea06{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-499bec94{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-499bf450{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-499bf451{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-499bf45a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-499bf45b{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-499bf45c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-499bf464{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-499e1bb8"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-499bf450"><p class="cl-499bec94"><span class="cl-499aea06">Track</span></p></td><td class="cl-499bf451"><p class="cl-499bec94"><span class="cl-499aea06">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-499bf45a"><p class="cl-499bec94"><span class="cl-499aea06">Type</span></p></td><td class="cl-499bf45b"><p class="cl-499bec94"><span class="cl-499aea06">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-499bf45a"><p class="cl-499bec94"><span class="cl-499aea06">Title</span></p></td><td class="cl-499bf45b"><p class="cl-499bec94"><span class="cl-499aea06">Conflict and Politics</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-499bf45a"><p class="cl-499bec94"><span class="cl-499aea06">Time</span></p></td><td class="cl-499bf45b"><p class="cl-499bec94"><span class="cl-499aea06">09:15 - 10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-499bf45c"><p class="cl-499bec94"><span class="cl-499aea06">Room</span></p></td><td class="cl-499bf464"><p class="cl-499bec94"><span class="cl-499aea06">Foyle: PFC/0G/007</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Contempt and Other Specific Emotions as Predictors of Support for Anti-Democratic Political Behavior</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Rudolph, Ben; Roseman`, Ira J</strong><br>
Abstract: Western democracies have seen a rise in extreme and anti-democratic political behavior in recent years. Political psychologists have pointed to a role for emotions in explaining such behaviors. We examined the extent to which particular emotions predicted support for anti-democratic actions in the U.S. We conducted two survey studies measuring support for extreme behaviors, along with emotions and other predictors: one in the weeks before the 2020 election; the other starting on the evening of the January 6th attack on the U.S. Capitol. We asked respondents to rate how often they felt various emotions toward Republican President Donald Trump and his Democratic Party opponent, Joe Biden, and the extent to which respondents would support Trump refusing to leave office if he lost the election. Study 1, fielded in a nationally representative sample of U.S. voters (n=1200) found that pride and enthusiasm toward Trump and contempt toward Biden emerged as the positive and negative emotions that most strongly predicted support for Trump refusing to leave office. Study 2 closely replicated these results in another sample of registered voters (n=287) immediately after Trump supporters attempted to stop Congress from certifying Biden’s election. Again, enthusiasm and pride toward Trump and contempt toward Biden were the most powerful predictors of support for Trump refusing to leave. These patterns of emotions align with findings from Tausch et al.&nbsp;(2011) about contempt, as well as theories of intergroup conflict (e.g., Tajfel &amp; Turner, 1979), and highlight specific emotions that may be involved in anti-democratic behavior.<br>
&nbsp;<br>
Title: <strong>Of Looming Threats: Affective and Behavioural Responses to Making Crises’ Consequences Salient</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Ditrich, Lara; Febriana, S. Gina</strong><br>
Abstract: Dire predictions about our planet’s future fill the news almost every day. These include reports on the effects of climate change and geopolitical crises alike. Viewing such reports can profoundly impact recipients’ emotions and behaviour, even driving some to engage in collective action. Current models of collective action assign a central role to emotions when explaining individuals’ engagement. In doing so, they primarily focus on anger about present injustices. We propose that a second emotional pathway plays an equally important role: fear of things taking a turn for the worse in the future. We shed light on this pathway in seven studies (total N=2149). Two studies in the context of climate change and the war in Ukraine suggest that making a crisis’s consequences salient indeed fosters fear – if the consequences are described in a concrete fashion. The remaining studies focused on the climate crisis. They revealed larger increases in fear when consequences (vs.&nbsp;causes) were highlighted, even controlling for anger. Fear, in turn, consistently correlated with higher collective action intentions. A final study showed that highlighting consequences also affected behaviour: Participants for whom consequences (vs.&nbsp;causes) of climate change had been made salient invested more effort into collecting donations for a pro-environmental organization. In sum, our work implies that fear of a crisis’s consequences might be an important yet understudied emotional pathway shaping individuals’ collective responses to contemporary crises. We will discuss the implications of our findings for the nature of the “emotional pathway” in current models of collective action.<br>
&nbsp;<br>
Title: <strong>Emotions at War: What can Emotion Science Offer?</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Fischer, Agneta; Noor, Masi; Cheshin, Arik</strong><br>
Abstract: The period leading up to World War II and the war itself has profoundly influenced the questions that were posed in (social) psychological research. How was it possible that the masses in Germany, but also in other parts of Europe were brainwashed with antisemitism; what does it tell us about mass behavior, about stereotypes; under which circumstances does prejudice develop, and so on. In the meantime, we have gained insight into group identities, group behavior, and group polarization, such that we can unmistakably observe the laws of group emotions in the current wars in Ukraine or Israel and Gaza. However, the political international world-wide crises require us to rethink the questions that we should pose for the answers that we seek. What can emotion science offer? We have knowledge about how negative emotions are strengthened, especially between groups, but we have much less systematic knowledge about the emotions and emotion strategies that are needed among such extreme circumstances: what emotions can help make life bearable, how can we support a road to peace, how can hate and revenge be replaced by understanding, trust, empathy and forgiveness? What drives these emotions, and under what circumstances can they blossom? In this talk, we will give some answers to these questions on the basis of previous research, but we will also ask new questions, and plea for new research lines to gain more insight into emotions during extreme conflicts.<br>
&nbsp;<br>
Title: <strong>Emotions in Political Rituals and in Inner Asian Tributary Relations</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Schwarz, Michal</strong><br>
Abstract: Enthronization or political recognition in tributary relations was always extraordinary event in traditional international or interethnic relations in Inner Asia. These political rituals were usually celebrated on the occasion of creating a new alliance, in connection of establishing new dynasty or with succession of new hereditary or selected ruler. Because of interconnected religious and political institutions, the event had always many symbolic features connected to religious justification of power. These features were connected to A) understanding of sacred statecraft, B) ritual communication with spiritual world and C) emotions of ritual participants. After the comments to the spirits and sacred state, this paper will mainly focus on participant emotions. The analyzed data are based on 1) classical books with citations about the power of rituals, 2) cases of religious justification of power in royal edicts and on stele inscriptions, 3) historical events, 4) emotional value ascribed to particular symbols, 5) emotional expressions in ritual manuscripts. All mentioned sources provide comprehensive picture about involvement of emotions including established believes about ontological status of emotions like various states of happiness, eternal bliss etc. Note: As an important part of political and public life, the use of symbols and changing political rituals continue even during the colonial period and by contemporary Inner Asian neighbors including Vietnam and Korea.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-4-t4" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-4-t4">Parallel Session 4 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49a86aaa{}.cl-49a511b6{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49a61854{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49a6201a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49a62024{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49a62025{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49a62026{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49a6202e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49a6202f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49a86aaa"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49a6201a"><p class="cl-49a61854"><span class="cl-49a511b6">Track</span></p></td><td class="cl-49a62024"><p class="cl-49a61854"><span class="cl-49a511b6">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49a62025"><p class="cl-49a61854"><span class="cl-49a511b6">Type</span></p></td><td class="cl-49a62026"><p class="cl-49a61854"><span class="cl-49a511b6">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49a62025"><p class="cl-49a61854"><span class="cl-49a511b6">Title</span></p></td><td class="cl-49a62026"><p class="cl-49a61854"><span class="cl-49a511b6">Text and AI</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49a62025"><p class="cl-49a61854"><span class="cl-49a511b6">Time</span></p></td><td class="cl-49a62026"><p class="cl-49a61854"><span class="cl-49a511b6">09:15 - 10:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49a6202e"><p class="cl-49a61854"><span class="cl-49a511b6">Room</span></p></td><td class="cl-49a6202f"><p class="cl-49a61854"><span class="cl-49a511b6">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Decrypting Auditory Hate Speech: The Development of the Warsaw Multimodal Hate Speech Data Base (WMHS)</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Puchała, Dominik Jakub; Rammohan, Rathi Adarshi; Świderska, Aleksandra; Schultz, Tanja; Küster, Dennis</strong><br>
Abstract: Hate speech, a phenomenon and manifestation of prejudice, is attracting increasing interest from emotion researchers. However, reminiscent of past debates on emotions, many diverse and sometimes conflicting definitions of hate speech persist. Most notably, few studies have investigated hate speech as a multimodal phenomenon that is capable of eliciting complex subjective, physiological, and behavioural responses. We argue that this may be partially due to a predominant focus on ‘hate text’ in existing research. The current work capitalizes on recent advancements in automatic transcription and large language models (LLMs) to annotate a large new multimodal hate speech database, the WMHS. Based on a review of hate speech definitions, we provide a preview of the features of the WMHS, which currently consists of more than 8 hours of manually annotated multimodal hate speech episodes in Polish. By providing an open access mechanism to other researchers, we aim to facilitate new interdisciplinary approaches leveraging psychological research as well as machine- and deep-learning approaches to classify textual, auditory, and multimodal hate speech. Towards this aim, the final database will include comprehensive descriptive statistics, Polish transcriptions, translations, and expert-annotated ground truth data distinguishing between target groups, categories, and protected characteristics of auditory hate speech. We will discuss potential use cases, e.g., improved content moderation, as well as new perspectives for basic research into the socio-emotional underpinnings of hate speech and the differences between merely reading (about) hate speech and having to confront this phenomenon in the real world.<br>
&nbsp;<br>
Title: <strong>Using Artificial Intelligence to Understand People’s Interpersonal Emotion Regulation Strategies</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Li, Xiuhui; Chen, Yuhui; Lopez-Perez, Belen</strong><br>
Abstract: Interpersonal emotion regulation, as defined by Niven et al.&nbsp;(2009), employs various strategies like affective and cognitive engagement, attention, and humour to influence others’ emotions. Traditional research in this area (Little et al.&nbsp;2012; Lopez-Perez et al.&nbsp;2017), often relies on questionnaires, which may not be effective for those with limited literacy or introspection skills. To address this, recent studies (Kwon &amp; Lopez-Perez, 2021; Lopez-Perez et al., 2016) have adopted narrative-based methods, particularly for children, although these require time-intensive and potentially subjective qualitative analysis. Our research aimed to evaluate the effectiveness of open AI, specifically text-based models like ChatGPT and CLAUDE, in categorizing emotional content in narratives. We conducted two studies to compare AI performance against human coding in identifying regulation strategies from qualitative data. In Study 1, with 2824 responses, ChatGPT initially achieved Kappa values over .61. Refinements in coding instructions led to improved reliability (Ks &gt; .80) between ChatGPT and human coders. Study 2, with 2304 responses, demonstrated comparable accuracy using these refined instructions, achieving Ks &gt; .81. Additionally, testing CLAUDE with 1,152 narratives showed similar reliability (Ks &gt; .74). These results indicate that AI can effectively understand and categorize regulation strategies, although significant training is needed.<br>
&nbsp;<br>
Title: <strong>Textual Emotion and the Veracity of News Headlines: The Roles of Valence, Arousal, and Words Position</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Zhou, Xiaoyu</strong><br>
Abstract: Research Background and Aim: Fake news tends to have different language patterns from real news. Language patterns have become a popular focus in deception research, whereas the role of emotional patterns is relatively overlooked.To offer a nuanced understanding of emotional cues in distinguishing fake news from real news, this study investigates how the interplay between textual emotion and words position relates to the veracity of health and gossip news headlines. Method: Drawing on datasets comprising 6,644 headlines with confirmed veracity, this research employs a lexicon of emotion norms and machine learning techniques to quantify emotional valence and arousal scores at the word level. To have a uniform understanding of the position, we normalize each headline’s length to the average length in their datasets. This algorithm adjusts a sentence’s raw emotion scores to fit this grid, maintaining a proportional representation of each word’s score. The algorithm operates in two ways, depending on the sentence length. For sentences shorter than or equal to the grid size, it directly maps each word’s score to the grid, using a rounding method based on the word’s position. For longer sentences, it first averages adjacent word scores, compressing the sentence to the grid size less or equal than the average size. Then these averaged scores are mapped to the grid following the first way. Results: Logistic regression was conducted to assess emotional patterns in normalized-length fake and real headlines. Findings reveal that heightened arousal at the beginning and end of headlines correlates with lower credibility in health news, while a positive valence at the start of gossip news headlines suggests greater rates of being real news. Implications: Highlighting the role of arousal in news veracity. Arousal and valence are distinct dimensions of emotion. Previous research mainly focused on the contribution of valence to veracity and rarely investigated the relationship between arousal and information veracity. This research provided arousal and valence profiles for each headline and examined their associations with news veracity. Addressing the location of emotion in headlines. The placement of lies within a disclosure can sometimes reflect a liar’s thinking process. Previous research mainly focused on the overall emotion reflected in information. The current research took a relative micro-level lens to see the location or distribution of emotion in one piece of information. We innovatively normalized each headline’s length to the same length to have a uniform understanding of the location of emotion. Proving the importance of emotional language patterns in information veracity. Language patterns have become a popular focus in deception research, whereas the role of emotional patterns is relatively overlooked. The current research addressed this gap by offering a detailed emotional profile within fake and real news headlines.<br>
&nbsp;<br>
Title: <strong>Appraisal Shifts in Reappraisal: Observations using Large Language Models</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Uusberg, Andero; Ruder, Deniss; Sirts, Kairit</strong><br>
Abstract: Reappraisal is a helpful way to regulate emotions that is difficult to describe and model on a mechanistic level. One solution is to characterize reappraisal as a set of shifts along how a situation is appraised along dimensions such as motive relevance, motive congruence, coping potential and the like. We implemented this approach with the help of natural language processing to detect appraisals and their shifts from text. We first established that general purpose large language models such as GPT 4 can recover appraisals from text with accuracies that are similar to purpose-built models and human annotators. Specifically, we asked GPT4 to re-produce appraisal ratings of 1200 texts collected by Troiano, Oberländer, &amp; Klinger (2022). We found that the accuracy of GPT ratings (root mean squared error (RMSE) of 1.45 on a 5-point scale relative to human self-ratings) were similar to a transformer-based purpose-built model (RMSE = 1.4, Troiano et al., 2022) as well as to human annotators (RMSE = 1.46). The relative accuracy of models and humans varied between appraisal dimensions and emotions. We then used GPT to detect appraisal shifts in two datasets containing texts written about an emotional event before and after engaging in reappraisal. We found that appraisal shifts detected from text were related to reappraisal success. I will discuss the conceptual implications and potential practical applications of these findings.<br>
&nbsp;<br>
Title: <strong>Defining Emotions for Technology: Lessons Learned from Writing a Global Standard for Ethics in Empathic AI</strong><br>
Time: 10:15-10:30<br>
Authors: <strong>Bland, Ben; McStay, Andrew</strong><br>
Abstract: IEEE 7014 is an ethical standard for empathic AI in the late stages of development; it considers ethical issues in relation to technologies that measure, simulate and interact with emotions. The Institute of Electrical and Electronics Engineers (IEEE), one of the primary global standards development organisations, initiated the world’s first series of standards for the ethics of AI, including IEEE 7014 Standard for Ethical considerations in Emulated Empathy in Autonomous and Intelligent Systems. This new standard attempts to establish normative ethical practices for affective computing, “emotion AI”, and other emotion-related technologies. This presentation will address IEEE 7014’s structure and content, highlighting the challenges faced in its consensus-driven creation by an international expert group. These challenges include: defining scope, and enumerating ethical issues unique to empathic AI; selecting normative references and ethical frameworks, with resultant requirements for “ethical explainability”; and aligning with regional cultural values and emerging regulations. Designing the standard involved addressing limitations, risks, responsibilities, and technical requirements, stemming from the subjective nature of emotional models used in empathic systems. Developing IEEE 7014 followed the typical process of major standards organisations, requiring consensus-based drafting with input from a diverse group of international volunteers from academia, industry, and regulatory bodies. This process entails limitations, such as development timelines that are typically too long to keep pace with emerging technologies, and inadequate stakeholder input due to private and proprietary content licensing. Potential improvements for future standards development, as suggested by the standards community, will also be discussed.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-4-t5" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-4-t5">Parallel Session 4 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49b318ba{}.cl-49afabda{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49b16092{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49b16cae{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16caf{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cb0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cb8{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cb9{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cba{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cc2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cc3{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49b16cc4{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49b318ba"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49b16cae"><p class="cl-49b16092"><span class="cl-49afabda">Track</span></p></td><td class="cl-49b16caf"><p class="cl-49b16092"><span class="cl-49afabda">T5</span></p></td><td class="cl-49b16cb0"><p class="cl-49b16092"><span class="cl-49afabda">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49b16cb8"><p class="cl-49b16092"><span class="cl-49afabda">Type</span></p></td><td class="cl-49b16cb9"><p class="cl-49b16092"><span class="cl-49afabda">Individual Talks</span></p></td><td class="cl-49b16cba"><p class="cl-49b16092"><span class="cl-49afabda">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49b16cb8"><p class="cl-49b16092"><span class="cl-49afabda">Title</span></p></td><td class="cl-49b16cb9"><p class="cl-49b16092"><span class="cl-49afabda">Dynamic perspectives</span></p></td><td class="cl-49b16cba"><p class="cl-49b16092"><span class="cl-49afabda">Dynamic perspectives</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49b16cb8"><p class="cl-49b16092"><span class="cl-49afabda">Time</span></p></td><td class="cl-49b16cb9"><p class="cl-49b16092"><span class="cl-49afabda">09:15 - 10:15</span></p></td><td class="cl-49b16cba"><p class="cl-49b16092"><span class="cl-49afabda">09:15 - 10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49b16cc2"><p class="cl-49b16092"><span class="cl-49afabda">Room</span></p></td><td class="cl-49b16cc3"><p class="cl-49b16092"><span class="cl-49afabda">Roe: PFC/02/018</span></p></td><td class="cl-49b16cc4"><p class="cl-49b16092"><span class="cl-49afabda">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>It Takes Two: Exploring the Temporal Interpersonal Emotion System of Parents and Adolescents During Conflict Discussions</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Workman, Katey; Main, Alexandra</strong><br>
Abstract: Adolescence is a developmental period historically categorized as turbulent due to biological, cognitive, and social changes that necessitate a realignment of the parent-child relationship (Collins &amp; Laursen, 2004). The way parents respond to their children’s emotions is a crucial component of socialization (e.g., Eisenberg et la., 1998). Temporal Interpersonal Systems (TIES; Butler, 2011) models highlight the importance of moment-to-moment emotion dynamics for interpersonal relationships, and these models have been applied more recently to parent-adolescent relationships (see Lougheed, 2020). However, few studies have examined how adolescent perceptions of parental responses to their emotions influence their psychological adjustment. In the present study we strive to answer the following research questions: (1) Do parental responses to adolescent emotions predict internalizing/externalizing problems and prosocial behavior?, and (2) Does adolescent perspective taking moderate these associations at dispositional and moment-to-moment timescales? We hypothesize that positive responses (e.g.&nbsp;validation and interest) will contribute to positive outcomes, greater perspective taking will strengthen these associations, and that moment-to-moment timescales will be more revealing than dispositional measures. Specific emotions during mother-adolescent conflict discussions (N = 120 dyads) were coded using the Specific Affect Coding System (SPAFF; Coan &amp; Gottman, 2007), mothers and adolescents reported on adolescents’ internalizing/externalizing problems, prosocial tendencies, and perspective taking concurrently and six months after the conflict discussion. Mothers and adolescents also participated in a video recall task in which adolescents rated how much their mother was unfair/manipulative, hostile/critical, and warm/supportive every 30 seconds across the 8-minute interaction. We will use grid-sequence analysis (Brinberg et al., 2017) to identify patterns of emotion dynamics between mothers and adolescents and path analyses to test hypotheses about longitudinal associations between these emotion dynamics and adolescent adjustment. Implications for applying dynamic methodologies to research on parent-adolescent emotions and how these emotions are perceived by social partners will be discussed.<br>
&nbsp;<br>
Title: <strong>Recalcitrant Emotions are Arational at the Moment and Prospectively Rational</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Xiang, Youce</strong><br>
Abstract: Contra Brady 2009 who argued that recalcitrant emotions are epistemically irrational for a number of counts including incurring unnecessary cognitive, behavioral costs, and priming subjects to self-defeatingly assent to already-rejected belief as well as to invent non-genuine reasons to vindicate their persistence, I argue that recalcitrant emotions are rational for numerous reasons. Inspired by Fodor, Ledoux and Griffiths, I contend that they are first of all of modular nature that possess dissociable neural substrates from higher cognition, so recalcitrant emotions such as fear and anger comprise automatic, independent generation resistant to rational appraisal. It is therefore inappropriate to charge them as irrational; they are at most arational at the moment. Furthermore, following the new pro-emotion consensus, I maintain that the persistence of recalcitrant emotions constructively contributes to the development of human practical rationality that is ecologically situated and constrained, drawing salience and attention to the underlying focus and care of the experiencers. It allows the potential of self-revelation, reinterpretation and belief-revision; such instrumental and prospective value of recalcitrant emotions justify their relentless duration and adds another level of rationality to them.<br>
&nbsp;<br>
Title: <strong>Investigating Resilient Emotion Regulation – the Role of Emotion Regulation Variability and Emotion Regulation Flexibility</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Zerban, Matthias; Puhlmann, Lara; Yuen, Kenneth; Koval, Peter; Kobylinska, Dorota; Walter, Henrik; Tüscher, Oliver; Kalisch, Raffael</strong><br>
Abstract: Recent developments in the field of emotion regulation (ER) suggest no clear distinction of functional and dysfunctional ER strategies. Rather, dynamic deployment of ER strategies has been proposed as a cornerstone of healthy emotion regulation. Recent technological advances allow investigation of such dynamic processes by ecological momentary assessments (EMA) carried out via mobile devices. ER dynamics are commonly separated into ER variability, i.e., variation in use of different ER strategies over time, and ER flexibility, meaning ER variability that is synchronized with situational changes. First evidence from EMA studies confirms the beneficial influence of ER variability. However, the overall field remains understudied. Further, these studies solely focus on momentary negative affect as outcome. Investigating how ER dynamics relate to longer-term outcomes, like resilience, will provide further insight into relevance and scope of these concepts. Here, we investigate the relationships between different ER dynamic measures and psychological resilience in an international multicentre study (N=240), using EMA and questionnaire data, collected over a period of six months. We investigate both within- and between-subject effects of ER dynamics on resilience as outcome, using linear, as well as linear mixed models. We find no link between ER dynamic measures and resilience on between- or within-person level. Negative associations between ER variability measures and negative affect are in line with previous results. Contradictory to theory, flexibility measures show positive associations with negative affect. Our work suggests that ER variability, while being beneficial in the short run, does not seem to have a similar effect on resilience. Further, instead of flexibly applying different strategies across contexts, choosing from rather few strategies might be better-suited to regulate momentary negative affect.<br>
&nbsp;<br>
Title: <strong>Associations Between Attentional Disengagement from Distressed Infant Faces and Cortisol Reactivity are Moderated by Depressive Symptoms in Pregnant Women: An Eye-Tracking Study</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Dworschak, Christine</strong><br>
Abstract: Antenatal depression is one of the most common psychiatric disorders and has been linked tolower maternal sensitivity, which in turn has been found to be associated with negative mentalhealth outcomes in children. However, to date the mechanism behind the association betweenantenatal depression and maternal sensitivity is unclear. One potential mechanistic pathway isthe link between maternal sensitivity and stress reactivity. The aim of this study was to closethese gaps in the literature and investigate associations between attentional disengagement fromdistressed infant stimuli and cortisol reactivity in response to a stress test in a sample of pregnantand nulliparous women. N=79 women (n=36 pregnant) completed two eye-tracking tasksexamining disengagement from adult and infant stimuli distress, a stress manipulation task, andfilled out the BDI-II to assess depressive symptoms. Pregnant vs.&nbsp;nulliparous women showed astronger cortisol reactivity in response to the stress test. While no associations were foundbetween attentional disengagement from adult stimuli and cortisol reactivity, we foundsignificant associations among disengagement from infant (vs.&nbsp;adult) stimuli and cortisolreactivity for pregnant (but not nulliparous) participants which was moderated by depressivesymptoms. For pregnant participants with higher (vs.&nbsp;lower) depressive symptoms, slowerdisengagement from distressed infant stimuli predicted stronger cortisol reactivity in responseto acute stress, while the opposite pattern was observed for nulliparous participants. Findingsof this study provide a more fine-grained understanding of the mechanistic pathway betweenantenatal depression and maternal sensitivity and provides important implications forinterventions.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-5-t1" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-5-t1">Parallel Session 5 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49bd488a{}.cl-49ba56e8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49bbb060{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49bbb83a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49bbb83b{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49bbb844{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49bbb845{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49bbb846{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49bbb84e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49bd488a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49bbb83a"><p class="cl-49bbb060"><span class="cl-49ba56e8">Track</span></p></td><td class="cl-49bbb83b"><p class="cl-49bbb060"><span class="cl-49ba56e8">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49bbb844"><p class="cl-49bbb060"><span class="cl-49ba56e8">Type</span></p></td><td class="cl-49bbb845"><p class="cl-49bbb060"><span class="cl-49ba56e8">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49bbb844"><p class="cl-49bbb060"><span class="cl-49ba56e8">Title</span></p></td><td class="cl-49bbb845"><p class="cl-49bbb060"><span class="cl-49ba56e8">The Positive and Dark Side of Interpersonal Emotion Regulation</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49bbb844"><p class="cl-49bbb060"><span class="cl-49ba56e8">Time</span></p></td><td class="cl-49bbb845"><p class="cl-49bbb060"><span class="cl-49ba56e8">14:45 - 15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49bbb844"><p class="cl-49bbb060"><span class="cl-49ba56e8">Room</span></p></td><td class="cl-49bbb845"><p class="cl-49bbb060"><span class="cl-49ba56e8">Whitla Hall</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49bbb846"><p class="cl-49bbb060"><span class="cl-49ba56e8">Abstract</span></p></td><td class="cl-49bbb84e"><p class="cl-49bbb060"><span class="cl-49ba56e8">Previous research has demonstrated that people are motivated to change others‚Äô emotions. When it comes to affect improvement (i.e., making others feel good) most research has been conducted from either the agent or the target perspective, overlooking the interactive nature of the process. For affect worsening (i.e., deteriorating others‚Äô feelings) the research is even scarcer with many questions remaining as to what strategies and motives drive people‚Äôs efforts when engaging in this process. To address the gaps for affect improvement, the first talk will look at romantic couple‚Äôs use of co- regulation strategies and their links with attachment, demonstrating that both anxiety and avoidance attachment are linked to lower use of supportive regulation strategies. The second talk will discuss romantic couples‚Äô co-regulation considering whether the target‚Äôs perception of regulation strategy moderates the relationship between their situation appraisal and the perceived effectiveness of the regulation attempt. To address the gaps for affect worsening, the third talk will present a new scale to measure the strategies of engagement and rejection and the findings considering cross-cultural and developmental differences. The fourth talk will address the links between affect worsening motives and strategies relying on intensive longitudinal data, with preliminary findings suggesting that while altruistic motives are associated with engagement strategies, counter-hedonic motives are linked to both engagement and rejection strategies. Finally, the fifth presentation will discuss the link between the dark triad and the motives and strategies in interpersonal emotion regulation.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Avoidant Attachment Predicts Lower Use of High-Engagement Strategies to Regulate a Partner’s Emotions.</strong><br>
Time: 14:45-15:00<br>
Authors: <strong>Carolyn MacCann, Kit S. Double, &amp; Rebecca T. Pinkus</strong><br>
Abstract: Prior research has shown that both attachment anxiety and attachment avoidance relate to the strategies people use to regulate their own emotions. Despite the obvious interpersonal relevance, no research has yet examined the association of adult attachment dimensions with the strategies people use to regulate their partner’s emotions. Using longitudinal actor-partner independence models, the current study examines whether attachment anxiety and attachment avoidance (and their interaction) predict the use of eight emotion regulation strategies over a two-year period (7 measurement points at T0, 1.5, 3, 6, 12, 18, and 24 months). Participants were 534 heterosexual couples recruited from Prolific (of which 178 dyads were available at 24 months). Both actor effects and partner effects were stronger for attachment anxiety than attachment avoidance. For actor effects: a) avoidance significantly predicted lower use of receptive listening and valuing to regulate a partner for both men and women, and also predicted lower direction action, reappraisal and humor for women only, and b) anxiety had no significant effects for men but predicted lower listening, reappraisal, and direct action for women. For partner effects: a) avoidance significantly predicted lower receptive listening, valuing and humor for men, and lower expressive suppression and humor for women, and b) anxiety significantly predicted lower valuing for women, but greater listening but lower humor for men. This research clearly shows that attachment relates not just to how you regulate your own emotions, but also how you regulate your partner (actor effects) and how your partner regulates you (partner effects).<br>
&nbsp;<br>
Title: <strong>Situational Influences on Emotion Regulation Strategies Among Romantic Partners</strong><br>
Time: 15:00-15:15<br>
Authors: <strong>Sarah A. Walker, Rebecca, T. Pinkus, Carolyn MacCann</strong><br>
Abstract: People in romantic relationships frequently make attempts to regulate each other’s emotions (known as extrinsic emotion regulation). The current study examines: a) how situation appraisals influence which regulation strategies people use to regulate their partner’s (target’s) emotions, b) how the target’s situation appraisals influence their perceived effectiveness of the regulation attempt and c) whether the target’s perception of regulation strategy moderates the relationship between their situation appraisal and the perceived effectiveness of the regulation attempt. In this study, 150 couples (300 individuals) were recruited from Prolific and reported on a recent emotional situation from the perspective of either: a) the target (whose partner tried to regulate their emotions) or b) the regulator (who tried to regulate their partner’s emotions). The target’s text description of a recent emotional situation was sent to the regulator to ensure that both members of the dyad were responding to the same situation. Both target and regulator rated: a) 4 situation appraisals (challenge, control-self, control-others, and uncontrollability), b) how much the regulator used 8 strategies (expressive suppression, downward comparison, distraction, direct action, humor, positive reappraisal, receptive listening, and valuing), and c) the perceived effectiveness of the regulation attempt. By examining both partners’ perspectives and controlling for relationship length, this study aims to advance the understanding of dyadic emotion co-regulation. Expected results and potential implications for dyadic emotion regulation within romantic relationships will be explored.<br>
&nbsp;<br>
Title: <strong>Interpersonal Affect Worsening Scale (IAWS): Development and Validation of a New Questionnaire to Assess Regulation Strategies.</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Shayne Polias, Belén López-Pérez, Antonio Zuffianò, Yuhui Chen, Melissa Lopez Reyes, &amp; Madelene Sta. Maria</strong><br>
Abstract: Interpersonal emotion regulation, or managing others’ emotions, does not always entail directing others’ feelings to positive states, but also inflicting or upregulating negative emotions. The process of causing others to experience unpleasant emotions is called interpersonal affect worsening. The relative lack of research on interpersonal affect worsening can partly be due to the limited assessment tool that can delineate between the regulation strategies to achieve it. Therefore, this research focused on the development of the interpersonal affect worsening scale (IAWS), a tool that aimed to measure strategies for interpersonal affect worsening. Drawing upon the Interpersonal Affect Classification (Niven et al., 2009), the items and scenarios were generated based on the examples of real-life experiences. Three studies were conducted to establish the factor structure, reliability, construct, and criterion validity. In addition, a measurement invariance tests were done where responses from four different groups (United Kingdom and Philippines; younger adult and older adult) to evaluate the applicability of IAWS in different groups. Findings suggested two regulation strategies, engagement, and rejection, that demonstrated unique associations with different constructs. The findings contribute to the limited empirical evidence on the process of affect worsening suggesting important cultural and age differences in the use of strategies. Therefore, this opens the door to further studies to better understand what social contexts may make certain regulation strategies more prevalent and what variables in the lifespan may account for changes in strategy use.<br>
&nbsp;<br>
Title: <strong>Exploring the Temporal Dynamics of Motives and Strategies in Daily Interpersonal Affect Worsening</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Yuhui Chen, Belén López-Pérez</strong><br>
Abstract: Prior studies (e.g., López-Pérez et al., 2017; Netzer et al., 2015) have identified individuals’ tendencies to upregulate others’ negative emotions, labelled as Interpersonal Affect Worsening (IAW). These investigations, however, are limited to experimental environments and have not explored the temporal relationship between motives and strategies in daily life. This research investigates the association between the motives of IAW (altruistic versus counter-hedonic) and the strategies (engagement versus rejection). Additionally, we will examine the role of sympathy. Our current sample consists of 91 participants (mean age = 19.37; 79% female). They were involved in a week-long ecological momentary assessment, in which they reported 3 times a day whether they engaged in IAW, their relationship with the target, their motives, and strategies. Analysis revealed a significant within-person spillover between engagement and altruistic motive (β = .16; 95% CI: .009, .296). At the between level, we found a significant correlation between the intercepts (r =.97; 95% CI: [.759, .990]). Intriguingly, altruistic motive did not predict rejection (β = .317; 95% CI: -.133, 1.454) or vice versa (β = .37; 95% CI: -.262, 3.195). Counter-hedonic motive demonstrated significant spillover with both engagement (β = .29; 95% CI: .003, .51) and rejection (β = .263; 95% CI: .056, .486), and predicted higher use of rejection (β = .105; 95% CI: .013, .206). Our study illuminates the temporal dynamics between motives and regulation strategies in IAW. While altruistic motive predominantly correlates with engagement, counter-hedonic AW shows a broader association with both engagement and rejection.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-5-t2" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-5-t2">Parallel Session 5 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49c7870a{}.cl-49c4d406{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49c5f048{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49c5f872{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49c5f873{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49c5f87c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49c5f87d{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49c5f87e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49c5f87f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49c7870a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49c5f872"><p class="cl-49c5f048"><span class="cl-49c4d406">Track</span></p></td><td class="cl-49c5f873"><p class="cl-49c5f048"><span class="cl-49c4d406">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49c5f87c"><p class="cl-49c5f048"><span class="cl-49c4d406">Type</span></p></td><td class="cl-49c5f87d"><p class="cl-49c5f048"><span class="cl-49c4d406">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49c5f87c"><p class="cl-49c5f048"><span class="cl-49c4d406">Title</span></p></td><td class="cl-49c5f87d"><p class="cl-49c5f048"><span class="cl-49c4d406">Regulatory Mechanisms of Positive Emotions from Experimental Research to Real-World Dynamics</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49c5f87c"><p class="cl-49c5f048"><span class="cl-49c4d406">Discussant</span></p></td><td class="cl-49c5f87d"><p class="cl-49c5f048"><span class="cl-49c4d406">Annika Ziereis</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49c5f87c"><p class="cl-49c5f048"><span class="cl-49c4d406">Time</span></p></td><td class="cl-49c5f87d"><p class="cl-49c5f048"><span class="cl-49c4d406">14:45 - 16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49c5f87c"><p class="cl-49c5f048"><span class="cl-49c4d406">Room</span></p></td><td class="cl-49c5f87d"><p class="cl-49c5f048"><span class="cl-49c4d406">Bann: PFC/0G/024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49c5f87e"><p class="cl-49c5f048"><span class="cl-49c4d406">Abstract</span></p></td><td class="cl-49c5f87f"><p class="cl-49c5f048"><span class="cl-49c4d406">Within this symposium, our objective is a comprehensive exploration of the foundational aspects of positive emotion regulation. Departing from the predominant emphasis on strategies dedicated to mitigating negative emotions within existing research and theories on emotion regulation, our intention is to spotlight innovative research that challenges established assumptions. The presentations will cover a broad method spectrum, spanning from physiological measures of controlled inhibition of laughter and their associated neural underpinnings, to the choice of strategies employed in the everyday regulation of positive emotions and its relationship with well-being. In addition, we demonstrate that personality plays a role in the search for positive experiences even from negative sources and explore how self- regulatory processes may moderate engagement in tasks of various difficulty. Furthermore, we will cover influences of external positive and negative feedback on conflict monitoring processes and how emotion regulation and cognitive control interact. By creating connections between different research areas of positive emotion regulation and applying a multimethodological approach, this symposium aims to pave the way for a more unified and holistic understanding of emotion regulation.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Between Laughter and Restraint: Inhibition and Contagious Laughter During Humoristic Experiences</strong><br>
Time: 14:45-15:00<br>
Authors: <strong>Vanessa Mitschke, Annika Ziereis, Anne Schacht</strong><br>
Abstract: Laughter has a crucial function in fostering social connections and alleviating adverse emotions but can take an intriguing shift when a person tries to suppress it. To examine the outcomes and mechanisms of laughter suppression, we performed three experiments. In Experiment 1, participants listened to stimuli containing humorous material (jokes) and were instructed to control their laughter using two emotional regulation techniques: expressive suppression (ES) and cognitive reappraisal (CR). Experiment 1’s results indicated a significant decrease in facial expressions and amusement when employing CR compared to unrestricted listening. In contrast, ES wholly suppressed smiling, especially for slightly to moderately amusing jokes. It should be noted that very funny jokes were difficult to suppress in all conditions. Experiment 2 investigated the effects of laughter mimicry and social appraisal on humor suppression by complementing the jokes with pre-recorded laughter videos. Suppressing laughter mimicry was extremely difficult, particularly after being exposed to humorous material. Additionally, the presence of laughter from others simultaneously increased the perceived amusement of the material. It is worth noting that although ES did not decrease enjoyment (Exp. 1), attempting to suppress laughter while others were laughing resulted in a significant decrease in amusement (Exp. 2). To further explore the neural correlates of suppressing a smile, Experiment 3 tested inhibition-related ERPs in a go/no-go paradigm. We analyzed the no-go N2 and P3 under two conditions: with and without jokes and further contrasted the independent sources of withholding a smiling and a keypress response.<br>
&nbsp;<br>
Title: <strong>Feeling Pleasure after Experiencing Pain: Self-Regulation in Benign Masochism</strong><br>
Time: 15:00-15:15<br>
Authors: <strong>Karolina Dyduch-Hazar, Vanessa Mitschke,</strong><br>
Abstract: Some people, more than others, seek enjoyment from imposing venial harm on themselves such as eating horrendously spicy foods, getting painful tissue massages, or even visiting interactive haunted houses. But do such aversive experiences factually make masochistic individuals feel good? In two studies we sought to answer this question. In a series of trials, participants were given an option to choose the desired stimuli from four different video clip categories corresponding to adequate levels of valence (positive vs.&nbsp;negative) and arousal (high vs.&nbsp;low). After watching each video clip, participants reported how they currently felt. In Study 1, benign masochism was associated with greater preference for stimuli characterized by high arousal and negative valence. High benign masochists reported greater positive affect after exposure to such repulsive stimuli than low benign masochists. Study 2 replicated these findings while controlling for sensation seeking. Our findings demonstrate that some individuals self-regulate through exposure to everyday repellent experiences. They also highlight the utility of the benign masochism in examining contrahedonic motives in self-regulation.<br>
&nbsp;<br>
Title: <strong>Self-Regulation Strategies in Young Adults: Challenges and Benefits of Affective Feedback and Task Difficulty</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Guillermo Recio, Àngel Blanco, Sebastian Korb, Rafael Valenzuela, José V. Pestana, Nuria Codina</strong><br>
Abstract: We investigated challenges and benefits of affective feedback and task difficulty on performance, emotional state, motivation, and cognitive control and feedback processing in the brain, measured by means of event-related potentials. Seventy participants completed two different tasks. First, a Flanker task with three types of affective feedback to performance showing either: 1) only positive facial expressions (happy supervisors); 2) positive (happy supervisors to hits) and negative expressions (angry supervisors to errors); or 3) only negative expressions (angry supervisors). We predicted a trade- off between cognitive control and emotion regulation, namely, negative feedback would have a negative impact overall by inducing negative emotion and weakening task engagement. Positive feedback should have a positive impact on mood and motivation but may lead to loosening cognitive control. We hence expected a smaller Flanker effect, enhanced conflict monitoring (N2/P3), and feedback processing (FRN) when receiving both positive and negative feedback from the supervisors (2), compared with always receiving a positive (1) or negative feedback (3). Preliminary results confirmed a clear benefit on mood and motivation associated with positive feedback. The second task was a random motion task with three levels of difficulty (easy, moderate, hard), and tested the hypothesis that moderate difficulty would have positive effects in mood state and task engagement, as it would be challenging but achievable. Preliminary results revealed a benefit for the easy condition instead. Finally, we investigated whether positive emotion reverted benefits in performance in both tasks, taking individual differences in self-regulation (i.e., learning from errors, perseverance) as a covariate.<br>
&nbsp;<br>
Title: <strong>Emotion Regulation Choices in Positive and Negative Situations: An Ecologically Valid Approach using Experience Sampling.</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Anna Fischer, Anne Schacht</strong><br>
Abstract: How we regulate our emotions is essential for our well-being and social relationships. Emotion regulation (ER) is a highly complex, adaptive, and dynamic process and can occur in any type of situation. While research traditionally focused on ER strategies in negative situations, the regulation of emotions in positively perceived situations has often been overlooked. This study addresses this gap by examining ER choices in both positive and negative situations, recognizing the importance of a comprehensive understanding of ER across various contexts. Hereby, the complexity and spontaneity of real-life situations provide a more accurate representation of encountered situations and the corresponding ER strategies employed. Therefore, we implemented an experience sampling study using a smartphone application. 100 participants were asked randomly five times per day for two to four weeks if an emotional situation occurred. For each reported situation, participants provided insights into its context, motivation for regulation, the employed ER strategy, and perceived success in regulating their emotions. Self-reports on well-being and mental health were collected separately. Preliminary analyses suggest that refraining from regulation or extending the duration of emotions in positive situations may play a beneficial role in well-being. The findings from this research contribute to a more comprehensive understanding of emotion regulation across diverse positive and negative situations, shedding light on the potential impact of ER choices in positively perceived contexts on mental health and well-being.<br>
&nbsp;<br>
Title: <strong>Discussion</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Ziereis, Annika</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-5-t3" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-5-t3">Parallel Session 5 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49d1ba2c{}.cl-49cf19ca{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49d02bf8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49d033f0{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49d033fa{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49d033fb{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49d03404{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49d03405{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49d03406{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49d1ba2c"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49d033f0"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Track</span></p></td><td class="cl-49d033fa"><p class="cl-49d02bf8"><span class="cl-49cf19ca">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49d033fb"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Type</span></p></td><td class="cl-49d03404"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49d033fb"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Title</span></p></td><td class="cl-49d03404"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Emotional Experiences and Skills in the Context of Social Exchange Processes and Interpersonal Relationships</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49d033fb"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Time</span></p></td><td class="cl-49d03404"><p class="cl-49d02bf8"><span class="cl-49cf19ca">14:45 - 16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49d033fb"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Room</span></p></td><td class="cl-49d03404"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Foyle: PFC/0G/007</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49d03405"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Abstract</span></p></td><td class="cl-49d03406"><p class="cl-49d02bf8"><span class="cl-49cf19ca">Emotion expression and understanding depend on the social context. Emotions can also influence characteristics of interpersonal processes and relationships, and support relationship building. Using dyadic paradigms and experience sampling designs, the research presented in this symposium aims to improve the understanding of how emotions and emotional competencies shape, and are shaped by, interpersonal coordination and social exchange processes. The first presentation addresses adult-age and valence differences in interpersonal motor following (i.e., aligning one‚Äôs own body movements with those of another person) in emotionally meaningful conversations at zero acquaintance. The second talk focuses on how one person‚Äôs motor following affects the interaction partner‚Äôs transparent self-disclosure during conversations about positive and negative personal experiences. The third speaker investigates interdependencies between romantic partners‚Äô emotion recognition skills in old age, examining the role of both individual and dyadic variables in this regard. The fourth talk presents research from a 21-day experience sampling study examining orgasm communication and orgasm pursuit goals as predictors of self-reported sexual satisfaction and orgasm occurrence in heterosexual adults. The fifth presentation examines adult-age differences in the functionality of negative emotionality during sad or conflictual couple conversations. Together, these talks illustrate the interpersonal nature of emotional experiences and competencies and highlight their relevance for social relationships.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Examining Adult-Age Differences in Interpersonal Motor Coordination Between Strangers</strong><br>
Time: 14:45-15:00<br>
Authors: <strong>Jenny Jaquet, Alissa von Großmann, Antje Rauers, Elisabeth S. Blanke, Uwe Altmann, &amp; Michaela Riediger</strong><br>
Abstract: Interpersonal motor following (IMF; i.e., aligning one’s own body movements with those of another person) has been found to be more pronounced when people interact with persons whom they like or with whom they wish to build a relationship. Consequently, it is considered a behavioral expression of social motivation. Developmental theories maintain that this social motivation changes across the lifespan. With increasing adult age, people may increasingly prioritize close relationships over peripheral contacts and new relationships. Therefore, we hypothesized IMF to be less frequent and of shorter duration in older, compared to younger adults, when interacting with a stranger. We analyzed videos of N = 104 dyadic conversations about emotionally meaningful events among unacquainted younger (20-31 years) and older women (69-80 years). IMF indices were quantified using computer- based algorithms (Altmann, 2013). We found that older adults, on average, followed their partner’s movements for a shorter amount of time than younger adults. The frequency of IMF intervals was higher among age-homogenous than age-heterogenous dyads. Both IMF indices were more pronounced during positively (vs.&nbsp;negatively) valanced conversations. Our findings contribute to understanding how age and valence shape interpersonal coordination in emotionally meaningful conversations at zero acquaintance.<br>
&nbsp;<br>
Title: <strong>Follow Me and I Will Tell You More: Associations Between Interpersonal Motor Following and Self-Disclosure</strong><br>
Time: 15:00-15:15<br>
Authors: <strong>Alissa von Großmann, Jenny Jaquet, Antje Rauers, Andrea Schlesier-Michel, Elisabeth S. Blanke, Uwe Altmann, &amp; Michaela Riediger</strong><br>
Abstract: When telling another person about an emotional experience, the other person may behave in ways that encourages further self-disclosure (Reis &amp; Shaver, 1988). This may extend to nonverbal behavior. For example, research suggests that responsive behavior can be expressed in interpersonal motor following (i.e., the alignment of the responder’s body movements with the speaker’s movements). Past research has studied these aspects – self-disclosure and motor following –separately. However, both behaviors reflect mutual interest in the other person and may thus facilitate each other. This assumption has not been studied before. Thus, in our study, we hypothesized that the responder’s motor following is associated with the speaker’s self-disclosure, with mutually reinforcing effects. To test this, we analyzed videos (N = 104) of dyadic conversations about emotional positive and negative events among younger (20–31 years) and older (69–80 years) previously unacquainted women. To compute indices for the responder’s amount of interpersonal motor following, we performed motion energy and time series analyses (Altmann, 2013). Four independent raters evaluated the speaker’s self- disclosure (taking into account the inner states as reported by the speaker; ICC = .67 – .97). Actor- partner interdependence models show that the responder’s motor following was not associated with the other person’s self-disclosure. However, one’s own motor following was associated with one’s own self-disclosure. This suggests that motor following and self-disclosure are common reflections of one’s engagement with the conversation. We discuss the role of objective indices versus subjective perceptions of motor following for interpersonal outcomes.<br>
&nbsp;<br>
Title: <strong>Individual and Dyadic Correlates of Emotion Recognition Performance in Older Couples</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Beyza Sönmez, Elisa Weber, &amp; Gizem Hülür</strong><br>
Abstract: Research has widely documented that the ability to recognise facial emotion expressions from pictures declines in old age. In the current study, we examine how emotion recognition performance is related to different cognitive abilities and self-report measures, such as empathy and relationship satisfaction, in older individuals and couples. In the current study, we use data from 151 older couples (average age = 72.6 years) who took part in assessments of the cognitive abilities of fluid and crystallized intelligence, processing speed, memory, and completed tests of emotion recognition from pictures and short videos. Self-report measures analysed in this study included measures of empathy and relationship satisfaction. Associations between tests of cognitive abilities and emotion recognition were addressed in a confirmatory factor analysis. A model including separate latent factors for fluid intelligence, crystallized intelligence, processing speed, memory functioning and emotion recognition showed a good model fit. Older participants scored lower on all cognitive functioning tasks, except on tasks for crystallized intelligence. Covariances revealed that emotion recognition performance is significantly related to all cognitive abilities within individuals, but not between partners. Emotion recognition performance was correlated across partners. There were no sex differences in emotion recognition. Emotion recognition was unrelated to self-reported empathy and relationship satisfaction. Taken together, our findings suggest that cognitive ability is the closest correlate of emotion recognition performance from images of facial expression in older adults.<br>
&nbsp;<br>
Title: <strong>Love to Love You: Orgasm Communication and Sexual Pleasure Equity Through an Interdependence Lens</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Cheryl L. Carmichael, &amp; Carly Wolfer</strong><br>
Abstract: In heterosexual partnered sex men are significantly more likely to experience orgasm than women. Explanations for the “orgasm gap” have traditionally centered women’s psychological and biological deficits and fail to consider the inherently interpersonal nature of partnered sex. We apply interdependence theory to examine how both partners’ orgasm pursuit goals contribute to orgasm occurrence and sexual pleasure. Heterosexual partnered adults (N=128 individuals; 50% men; 18 to 40 years old; relationship length = 3 months to 5 years) completed our mixed-methods 21-day experience sampling study of their sexual encounters. Multilevel models revealed that men reported higher levels personal orgasm pursuit (pursuing my own orgasm) and perceived partner orgasm pursuit (perceptions that my partner is pursing my orgasm) than women. When entered simultaneously, perceived partner orgasm pursuit uniquely predicted orgasm occurrence and sexual satisfaction over and above personal orgasm pursuit. Moreover, perceived partner pursuit amplified the effect of personal orgasm pursuit on sexual satisfaction. Participants also rated the extent to which they and their partner communicated their desire to orgasm, and we coded their open-ended descriptions of how they, and their partner, communicated about their orgasm desires for cue type (verbal/nonverbal). Only the degree to which participants communicated their orgasm desire predicted perceived partner orgasm pursuit, orgasm occurrence, and sexual satisfaction; the use of verbal and nonverbal cues did not. This work reveals how orgasm communication may be able to prompt interpersonal orgasm pursuit and emphasizes the importance of adopting a dyadic perspective for understanding and addressing sexual pleasure inequity.<br>
&nbsp;<br>
Title: <strong>Let’s Talk, Honey! Age Differences in Emotional Experiences During Sad and Conflictual Couples’ Conversations</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Margund K. Rohr, Nicola Ngombe, Philipp Kanske, &amp; Ute Kunzmann</strong><br>
Abstract: Theories of emotional aging paint a rosy picture by pointing to age-related gains in emotional experience and emotion regulation, especially in close relationships such as couples. A common paradigm here is conflict discussion, in which older couples show less negative affect, report more affection, and display greater cohesion than younger couples. Accordingly, age-related gains are often understood prohedonically, neglecting that the functionality of negative emotions depends on the context. Specifically, while expressing negative emotions during conflict may threaten the relationship, it signals feelings of understanding and togetherness during comforting conversations. In addition, there is evidence for greater context-dependency in old age, which needs to be further explored. In an ongoing study, we ask younger (currently n = 60 dyads, 18 - 35 years old) and older couples (currently n = 20 couples, 55 years and older) to talk about a sad and a conflictual topic in their relationship. Preliminary results show similarities and differences in the emotional experiences of younger and older couples in both contexts. Specifically, while younger couples experience more negative affect during conflict than their older counterparts, we find no age differences in negative emotional experience during comforting situations. Results are discussed in light of prominent theories and implications for future research are drawn.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-5-t4" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-5-t4">Parallel Session 5 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49dc01da{}.cl-49d96e02{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49da7c5c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49da83d2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49da83d3{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49da83dc{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49da83e6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49da83e7{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49da83e8{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49dc01da"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49da83d2"><p class="cl-49da7c5c"><span class="cl-49d96e02">Track</span></p></td><td class="cl-49da83d3"><p class="cl-49da7c5c"><span class="cl-49d96e02">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49da83dc"><p class="cl-49da7c5c"><span class="cl-49d96e02">Type</span></p></td><td class="cl-49da83e6"><p class="cl-49da7c5c"><span class="cl-49d96e02">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49da83dc"><p class="cl-49da7c5c"><span class="cl-49d96e02">Title</span></p></td><td class="cl-49da83e6"><p class="cl-49da7c5c"><span class="cl-49d96e02">Crises and Media</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49da83dc"><p class="cl-49da7c5c"><span class="cl-49d96e02">Time</span></p></td><td class="cl-49da83e6"><p class="cl-49da7c5c"><span class="cl-49d96e02">14:45 - 15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49da83e7"><p class="cl-49da7c5c"><span class="cl-49d96e02">Room</span></p></td><td class="cl-49da83e8"><p class="cl-49da7c5c"><span class="cl-49d96e02">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>to Read or not to Read? Motives for Reading Negative COVID-19 News</strong><br>
Time: 14:45-15:00<br>
Authors: <strong>Niehoff, Esther; Mittenbühler, Maximilian; Oosterwijk, Suzanne</strong><br>
Abstract: The COVID-19 pandemic confronted individuals with a slew of negative news. But what drives people to either engage or not engage with news that can be distressing or frightening? The presented research examined how predicted psychological consequences of reading COVID-19 news explained people’s decisions to read or not read. To that end, we asked participants to choose whether they wished to read COVID-19 news articles based on headlines. The headlines indicated that the articles either contained fact-based information about the pandemic or stories about personal experiences with COVID-19. The headlines were subsequently rated on a set of motivational dimensions, such as “reading this article is my moral duty”. To ensure robustness of findings, we implemented a cross-validation approach. This gave support for four preregistered hypotheses: Choosing to read negative COVID-19 news was positively predicted by (a) the expected acquisition of knowledge; (b) the perceived relevance to one’s own personal situation; (c) one’s sense of moral obligation, and (d) the extent to which the story in question focused on personal as opposed to fact-based information. Based on exploratory analyses, we also found suggestive support that anticipated compassion positively predicted choice to read negative COVID-19 news, and that a sense of inappropriateness, and the anticipated gratitude for one’s own situation, negatively predicted choice. Furthermore, we found a quadratic relationship between feelings and choice, where both the anticipation of weak or no feelings, and the anticipation of strong feelings, negatively predicted choice to read negative news. Taken together, these findings reinforce the idea that engaging with negative content provides informational and social value to the individual.<br>
&nbsp;<br>
Title: <strong>The Impact of Emotions and Media Coverage on Behavior Change in the Climate Crisis</strong><br>
Time: 15:00-15:15<br>
Authors: <strong>Stoll-Kleemann, Susanne</strong><br>
Abstract: Emotions are found among the strongest predictors of climate change mitigation and adaptation behaviour. Therefore, to understand the many causes of persistent and undesirable climate-altering behaviours, it is necessary to focus on emotions and emotion-regulation strategies. Complementary to previous studies investigating the isolated influence of media or emotions, we focus on the influence of generalised emotions established via frequent media coverage. We discuss the relevant emotions and the role of the media underlying the motivations of individuals to behave in a less carbon-emitting manner. In a German quota sample (n=979), we investigate whether commonly used principles of COVID-19 pandemic reporting (regular coverage, focus on victims causing other-suffering and self-condemning emotions) can be strategically applied to climate crisis reporting. We show that the confrontation with information about victims of climate change (e.g., the number of heat-related deaths) resulted in emotional reactions of our participants such as other-suffering (pain, sympathy, worry) and few self-condemning (guilt) emotions. The motivation to reassess one’s own behaviour and shift the focus to protecting the vulnerable from avoidable plights was triggered. Participants indicated that they would change their behaviour if they were confronted with such information if it is regularly and reliably reported. To elicit emotional responses via experience-based mechanisms, personal stories about how climate change is harming individuals have been identified as a promising way to increase emotional engagement with climate change. By reducing psychological distance to climate change and promoting experiential processing and associative appraisal, narrative-based communication strategies may provide an effective tool to promote low carbon behavior.<br>
&nbsp;<br>
Title: <strong>Emotions in Collective Climate Action: A Systematic Literature Review</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Sach, Anna A; Castiglione, Anna; Sisay, Benjamin; Bizzego, Andrea; Esposito, Gianluca; Sauter, Disa; Brick, Cameron</strong><br>
Abstract: Emotions influence and are influenced by collective climate action. They bring people to protest or organise, and shape the mood of rallies and assemblies. Feelings of empowerment, feeling moved and enthusiasm motivate people to continue, while resignation and burnout can help predict activists leaving the movement. Some climate movements explicitly organise the sharing or expressing of emotions. Understanding the role of these affective processes is relevant for mobilisation and continued engagement. Many studies have analysed emotions and other factors motivating collective climate activism, while less research has focused on sustained climate activism. Systematically reviewing this body of literature, we aim to synthesize the empirical knowledge and identify gaps and biases which can guide future research. Previous reviews of environmental and social psychological papers indicated that psychological scholarship often neglected marginalised communities who are disproportionately affected, which is reflected in a dominance of WEIRD samples and authors. In methodological terms, studies usually relied on cross-sectional quantitative panel samples, whereas causal and qualitative methods are rare. We report an ongoing systematic literature review about the underlying psychological dynamics of collective climate action. We are assessing which psychological factors have emerged as correlates and triggers of collective climate action, and which constructs, methods, samples, socio-cultural contexts and phases of activism have been studied and the relationships found. We expect that this review will shed light, among other psychological aspects, on the affective dynamics involved in collective climate action, to get a more complete understanding of the affective dynamics in place.<br>
&nbsp;<br>
Title: <strong>Using Hope-Evoking Media to Increase Emotional Bandwidth and Decrease Stress: A Media Prescription Perspective</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Nabi, Robin; Walter, Nathan; Myrick, Jessica; Dobmeier, Christopher M; Wang, Minghui</strong><br>
Abstract: Rooted in the broaden-and-build theory (Fredrickson, 1998, 2001), recent research on “media prescriptions” has demonstrated that exposure to brief, 3-5 minute video content that evokes hope or amusement over the course of a week can have indirect, salubrious effects on stress in the days that follow (Prestin &amp; Nabi, 2020; Nabi et al., 2022). Although there is some indication that coping efficacy may help to explain this finding, the psychological mechanism(s) through which these lingering effects emerge is not fully specified. This research explores the concept of “emotional bandwidth” as a potential critical mediator. Specifically, we predict that those exposed to inspiring or humorous content will (a) experience the emotions of hope or amusement (respectively). The elevations in these positive emotions will be associated with an increase in perceived emotional bandwidth to cope with stressors, which in turn, will relate to subsequent decreased perceived stress and increased empathy. Data collection is currently underway with a representative sample of 500 US adults. A pretest in Week 1 assesses typical media consumption, personality traits including empathy, stress levels, and emotional bandwidth. During Week 2, each weekday participants will watch a 3-5 minute video that is either inspiring or humorous, listen to a meditation, scroll on their phones, or experience no media content (control group) and report on their felt emotions, stress, and emotional bandwidth in the moment. The following 2 weeks, participants will again report on their stress, emotional bandwidth, empathy as well as any changes in their media habits.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-5-t5" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-5-t5">Parallel Session 5 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49e637ea{}.cl-49e3aa5c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49e4af06{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49e4b686{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49e4b687{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49e4b690{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49e4b691{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49e4b692{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49e4b69a{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49e637ea"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49e4b686"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Track</span></p></td><td class="cl-49e4b687"><p class="cl-49e4af06"><span class="cl-49e3aa5c">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49e4b690"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Type</span></p></td><td class="cl-49e4b691"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49e4b690"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Title</span></p></td><td class="cl-49e4b691"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Knowledge and Regulation</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49e4b690"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Time</span></p></td><td class="cl-49e4b691"><p class="cl-49e4af06"><span class="cl-49e3aa5c">14:45 - 16:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49e4b692"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Room</span></p></td><td class="cl-49e4b69a"><p class="cl-49e4af06"><span class="cl-49e3aa5c">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotion Recognition Accuracy and Appraisal Dimension Ratings of 44 Emotions from Dynamic Multimodal Expressions</strong><br>
Time: 14:45-15:00<br>
Authors: <strong>Laukka, Petri; Israelsson , Alexandra Ai; Tornberg, Christina; Lachmann, Tim; Boman, Magnus; Fischer, Håkan</strong><br>
Abstract: Studies on nonverbal expression of emotions are currently moving away from a focus on a limited number of unimodal expressions toward a wide variety of emotions expressed dynamically through several channels. We present results from the validation of a newly developed database of dynamic multimodal expressions, wherein actors convey a large number of emotions through facial, vocal and bodily expressions. A subset of 5,000 recordings was evaluated using both a forced-choice emotion recognition task and an appraisal dimension rating task (e.g., novelty, pleasantness, goal conduciveness, urgency, power). The subset contained recordings from 28 actors (14 F, 14 M) who expressed 44 emotions, each with two levels of emotion intensity (medium, high). In addition, we performed machine learning classification (support vector machines) based on facial action units, head movements and vocal features. Results from human judgments and machine classification showed similar patterns of accuracy for the different emotions, and together suggest that almost all of the 44 emotions could be recognized with better-than-chance-accuracy. The best recognized emotions included determination, concentration, expectation, positive surprise, relief, and amusement for positive emotions; and anger, disgust, boredom, schadenfreude, fear, sarcasm, confusion, and sadness for negative emotions. Results further provide novel information on the perceived appraisal patterns for a wide variety of emotions. Taken together, the findings suggest that nonverbal emotional communication may be more nuanced and flexible than previously thought.<br>
&nbsp;<br>
Title: <strong>Does Acceptance Lead to Change? Training in Radical Acceptance Improves Implementation of Cognitive Reappraisal</strong><br>
Time: 15:00-15:15<br>
Authors: <strong>Segal, Or; Weinbach, Noam; Aderka, Idan M; Sher, Helene</strong><br>
Abstract: Third-wave cognitive behavioral treatments such as dialectical behavioral therapy (DBT) theorize that practicing emotional acceptance can facilitate cognitive change. The goal of the current study was to provide an empirical evidence for this notion by assessing if a two-week online training to cultivate acceptance of negative personal events can subsequently improve the ability to implement cognitive reappraisal while being exposed to aversive stimuli. During six training sessions, 120 healthy individuals recorded personal events from their lives that evoke negative emotions in them. Participants were randomly allocated into three groups: In a Radical Acceptance group, participants implemented a DBT skill aimed to promote acceptance of the negative events they described. In a Check the Facts group, participants reappraised their automatic interpretations of the described events. A Control group described the events, but did not use any DBT skill to cope with them. A picture-based emotion regulation task was used before and after the training to assess implementation of emotional acceptance and cognitive reappraisal. The results showed that following the training, participants who practiced radical acceptance of reality improved in their ability to implement both emotional acceptance and cognitive reappraisal. In contrast, Check the Facts group improved only in the implementation of cognitive reappraisal, but not emotional acceptance. The control group did not improve in either strategy. The findings provide empirical evidence to support the notion that cultivating acceptance can subsequently improve the ability to reinterpret reality for coping adaptively with negative events.<br>
&nbsp;<br>
Title: <strong>Can Humans Perceive Emotions Just by Seeing Touching Hand?</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Oya, Rika; Tanaka, Akihiro</strong><br>
Abstract: We communicate emotions through various nonverbal cues, such as face, voice, and touch. Touch is one of important channels in emotional communication which works differently from the face and voice. Previous studies have investigated the perception of 12 discrete emotions from touch. Results showed that six emotions (anger, fear, disgust, love, gratitude, and sympathy) were communicated in the United States (Hertenstein et al., 2006, Study 1), and three of the six were communicated in Japan (Oya &amp; Tanaka, 2023). Interestingly, Hertenstein et al.&nbsp;(2006) also revealed that five emotions except for gratitude were decoded accurately without the experience of being touched, just by seeing the tactile behavior of the encoder (Study 3). Here, we conduct almost the same experiment as the Study 3 in Hertenstein et al.&nbsp;and examine whether we can perceive emotions just by seeing without feeling touch for Japanese participants. In the experiment, participants were presented with video clips of tactile behavior recorded in Oya and Tanaka (2023). In each video clip, one member of a dyad was assigned the role of encoder, whereas the other member was assigned the role of being decoder. The encoder freely touched the decoder’s arm with the hand to express each of the 12 emotions. Participants watched these video clips and judged the expressed emotion by the encoder. Results will be discussed in terms of the role of visual and tactile information in emotional communication through touch.<br>
&nbsp;<br>
Title: <strong>Emotion Understanding, Emotion Regulation, and Mental Well-Being: Evidence from New Emotion Ability Tests</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Floman, James; Brackett, Marc ; LaPalme, Matthew; Ponnock, Annette; Doyle, Aidan B</strong><br>
Abstract: Emotion granularity theory (Kashdan et al., 2015) holds that emotion understanding (EU) abilities facilitate targeted emotion regulation (ER) and thereby support mental well-being (MWB). However, existing EU tests tap only a few components of the theorized construct space. To address this gap, we developed three new tests. The Emotion Language Test (ELT) assesses the breath and precision of emotion language across 10 primary emotions employing expert consensus and machine learning-derived scoring from a corpus of 20,000 emotion terms. The Conceptual Emotion Granularity Test (CEGT) measures the specificity of people’s emotion concept maps (how they organize emotions into sets of mental categories, from a broad view of just positive and negative emotions to a more emotion-specific view). The Core Relational Themes of Emotion (CORE) test gauges knowledge of the central meanings or themes underlying 19 positive and negative emotions (e.g., achievement for pride, loss for sadness). In five validity studies, with demographically diverse working U.S. adults (Ntotal = 2028), we found evidence supporting the structural, convergent, discriminant, and predictive validity of the new EU assessments. The EU tests predicted higher ER ability on a performance test (STEM), and healthier MWB, including greater purpose in life and post-traumatic growth, lower compassion fatigue, and a mindset that emotions are malleable versus fixed (absolute rs ranged from .11 to .45, ps&lt;.05). The new tests also showed evidence of incremental validity beyond widely-used EU tools (i.e., the MSCEIT and STEU). Theoretical and methodological contributions will be considered, along with study implications and future research directions.<br>
&nbsp;<br>
Title: <strong>Predicting Emotion Regulation Strategies from Aspects of the Social Context in Everyday Life</strong><br>
Time: 15:45-16:00<br>
Authors: <strong>Main, Alexandra; Yung, Shun Ting; Chen, Yaoyu; Zawadzki, Matthew</strong><br>
Abstract: Emotion regulation has traditionally been conceptualized as an intrapersonal phenomenon with a focus on individuals’ subjective experiences. However, emotions occur predominantly in the context of social interactions (Campos et al., 2011), particularly during emerging adulthood when individuals spend more time outside the family home. However, few studies have examined predictors of the use of different emotion regulation strategies in everyday life. Using Ecological Momentary Assessment (4 daily assessments across 14 days), we first examined concurrent associations between social contexts (closeness to interaction partner and pleasantness of interaction) and use of emotion regulation strategies (cognitive reappraisal and expressive suppression) among college students. Second, we used lagged models to investigate potential carryover effects of aspects of the social context on emotion regulation strategy use. Better quality of social interactions was associated with both less suppression and less reappraisal at the same moment (β = -.23, p &lt;.001 and β = -.20, p &lt;.001 for reappraisal and suppression, respectively), but not at subsequent moments (β = .02, p &gt; .05 and β = .04, p &gt; .05 for reappraisal and suppression, respectively). Interestingly, we found that reappraisal at one moment predicted more pleasant interactions and closeness at the next moment (β = .09, p = .004 and β = .09, p = .040 for pleasantness and closeness, respectively). Our findings underscore the importance of understanding both social contexts and emotion regulation on momentary levels. This study holds implications for understanding social context and emotion regulation in the everyday lives of emerging adults.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-5-t6" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-5-t6">Parallel Session 5 : T6</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49f061fc{}.cl-49edd806{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49eeda80{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49eee228{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49eee232{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49eee233{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49eee234{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49eee23c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49eee23d{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49f061fc"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49eee228"><p class="cl-49eeda80"><span class="cl-49edd806">Track</span></p></td><td class="cl-49eee232"><p class="cl-49eeda80"><span class="cl-49edd806">T6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49eee233"><p class="cl-49eeda80"><span class="cl-49edd806">Type</span></p></td><td class="cl-49eee234"><p class="cl-49eeda80"><span class="cl-49edd806">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49eee233"><p class="cl-49eeda80"><span class="cl-49edd806">Title</span></p></td><td class="cl-49eee234"><p class="cl-49eeda80"><span class="cl-49edd806">Mechanisms of Emotion</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49eee233"><p class="cl-49eeda80"><span class="cl-49edd806">Time</span></p></td><td class="cl-49eee234"><p class="cl-49eeda80"><span class="cl-49edd806">14:45 - 15:45</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49eee23c"><p class="cl-49eeda80"><span class="cl-49edd806">Room</span></p></td><td class="cl-49eee23d"><p class="cl-49eeda80"><span class="cl-49edd806">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Implicit Motivational Value of Experiences</strong><br>
Time: 14:45-15:00<br>
Authors: <strong>Waugh, Christian; Porth, Adam; Fang, Xuanyu; Sands, Paul; Kishida, Kenneth</strong><br>
Abstract: Theoretical and neuroscientific accounts of emotions acknowledge that many of their constituent processes exist outside of conscious reflection. Yet, assessing these implicit emotional processes has been elusive. We suggest that reinforcement learning (RL) paradigms and models can assess implicit emotional processes related to motivated behavior. In RL paradigms, people make choices between options that lead to pre-specified rewards and punishments, however, it is possible to also estimate the implicit motivational value of the rewards and punishments themselves instead of pre-specifying them. We implemented these new RL models in two tasks: one in which people made choices that predicted the likelihood of whether they would see either familiar or novel negative, neutral, or positive emotional images; and another in which they viewed faces varying in attractiveness. We estimated the implicit motivational value (iMV) of these stimuli and found that, as expected, participants exhibited greater iMV to positive than to negative images and greater iMV to attractive than to less attractive faces. Further, there were only mild correlations between iMV and explicit ratings of these stimuli. These findings demonstrate the extraordinary possibility for using RL models to estimate the iMV of a host of emotional or otherwise motivationally salient stimuli that is clearly separable from explicitly asking participants about their feelings.<br>
&nbsp;<br>
Title: <strong>Appraisal of Certainty’s Effect on Information Processing: Attempted Replications of Tiedens and Linton (2011) Findings.</strong><br>
Time: 15:00-15:15<br>
Authors: <strong>Mailliez, Mélody; Bresson, Thomas; Julia, Katia; Courchamp, Laurine</strong><br>
Abstract: An extensive body of research has examined the effects of unrelated emotions (incidental emotions) on judgments and decisions through their constituent appraisals. Tiedens and Linton (2001) pioneered research showing that incidental emotions associated with a high degree on the appraisal of certainty (e.g., joy, anger) trigger heuristic processing whereas those associated with a low degree on the appraisal of certainty (e.g., hope, fear) trigger a more deliberative processing. However, several researchers failed to show any mediation of the link between incidental emotions and decisions through the appraisal of certainty. It is then of particular relevance to deepen the role of the appraisal of certainty in such relation since there seems to be a working assumption in much of the field that the certainty appraisal modulates judgments and decisions according to the information processing that is supposed to trigger. In three preregistered studies (Nstudy 1 = 318; Nstudy 2 = 736, Nstudy 3 = 500), we attempted to replicate the seminal results of Tiedens and Linton (2001). We did not find an effect of the appraisal of certainty on judgements and decisions in any of these three studies. Further investigations are then needed to disentangle whether the repeated absence of effects is the consequence of methodological considerations or whether it is necessary to consider other appraisal dimensions as a determinant of information processing triggered by incidental emotions (e.g., appraisal of control or an interaction between certainty and control).<br>
&nbsp;<br>
Title: <strong>The Role of Contrast Emotions in Response Inhibition</strong><br>
Time: 15:15-15:30<br>
Authors: <strong>Gupta, Rashmi</strong><br>
Abstract: Previous studies examined the role of irrelevant emotional facial expressions in response inhibition. Irrelevant emotional faces would facilitate or inhibit response inhibition, depending on how these faces are paired with different emotional faces. In previous studies, angry faces were either paired with neutral, happy, or fearful faces in the response inhibition task, potentially leading to mixed results. This is the first study where all four irrelevant emotional faces (happy, angry, fearful, and neutral) were used simultaneously and presented in the same block as a stop signal in the stop signal paradigm. Participants were required to respond to the go signals (discriminate between X and O). Occasionally, a stop signal with irrelevant facial expressions (happy, angry, fearful, or neutral) was presented, where participants were required to withhold their motor response. All stop signals with irrelevant emotional facial expressions in comparison to neutral facial expressions interfered with the response inhibition process. Our results extend previous findings by suggesting that approach and avoidance reactions to facial expressions depend on the contrasting emotions presented in the task. The finding helps explain many inconsistent results with respect to the effect of emotions on response inhibition reported in the literature. It also suggests that the role of valence (emotional vs nonemotional)⁠ needs to be considered in determining inhibitory control. These results have theoretical implications for understanding the nature of emotions and their interaction with cognitive control functions.<br>
&nbsp;<br>
Title: <strong>Artificial Intelligence for Anxiety: Pathways for Transdisciplinary Research on Anxiety Sensitive Artificial Intelligence</strong><br>
Time: 15:30-15:45<br>
Authors: <strong>Vanhée, Loïs; Borit, Melania</strong><br>
Abstract: Anxiety is a psychological state raised by uncertainty leading to uncertainty-reducing behaviors (e.g.&nbsp;anticipation, vigilance). Although anxiety typically functions positively by facilitating management of potential threats, excessive or prolonged anxiety threatens human wellbeing and health (anxiety comorbids with severe ailments like depression or phobia), resulting in social costs scaled in trillion euros worldwide annually, from treatment to sick leave and productivity losses. Whereas factors inducing anxiety and resulting from it are often difficult to integrate and also overlooked besides therapeutic praxis, Artificial Intelligence-based technologies provide a critical leverage for enabling a scalable, pragmatic, and systematic accountability of these anxiety factors. We coin these technologies as Anxiety Sensitive Artificial Intelligence (AnxSAI). AnxSAI opens for a broad range of applications, from anticipating and preventing (e.g.&nbsp;in education, work, urban planning) to mitigating and treating anxiety disorders (e.g.&nbsp;individualized precision therapies). Whereas until now AnxSAI has been near-exclusively investigated from computer science perspectives, it is inherently an inter- and transdisciplinary domain of research. The present study develops a framing for the systematic transdisciplinary mapping of AnxSAI research along three interrelated layers. The first layer focuses on foundational concerns: crossing anxiety as a psychological construct within computational methods AI models (e.g.&nbsp;recognition from text, simulation models). The second layer focuses on the social ramifications of AnxSAI, crossing sociology, law, philosophy, ethics, organizational theory, and critical studies. The third layer covers the practical implementation of AnxSAI technologies with societal actors, identifying pathways to achieving positive impact (e.g.&nbsp;relevant stakeholders and their desires and concerns, costs).<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t1" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t1">Parallel Session 6 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-49fa7818{}.cl-49f7e526{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49f8ed54{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49f8f4e8{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49f8f4e9{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49f8f4f2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49f8f4f3{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49f8f4f4{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49f8f4fc{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-49fa7818"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4e8"><p class="cl-49f8ed54"><span class="cl-49f7e526">Track</span></p></td><td class="cl-49f8f4e9"><p class="cl-49f8ed54"><span class="cl-49f7e526">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4f2"><p class="cl-49f8ed54"><span class="cl-49f7e526">Type</span></p></td><td class="cl-49f8f4f3"><p class="cl-49f8ed54"><span class="cl-49f7e526">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4f2"><p class="cl-49f8ed54"><span class="cl-49f7e526">Title</span></p></td><td class="cl-49f8f4f3"><p class="cl-49f8ed54"><span class="cl-49f7e526">Rethinking theories of emotional processes: Goal-direction, relevance-detection and social orientation</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4f2"><p class="cl-49f8ed54"><span class="cl-49f7e526">Discussant</span></p></td><td class="cl-49f8f4f3"><p class="cl-49f8ed54"><span class="cl-49f7e526">Andrea Scarantino</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4f2"><p class="cl-49f8ed54"><span class="cl-49f7e526">Time</span></p></td><td class="cl-49f8f4f3"><p class="cl-49f8ed54"><span class="cl-49f7e526">09:15 - 10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4f2"><p class="cl-49f8ed54"><span class="cl-49f7e526">Room</span></p></td><td class="cl-49f8f4f3"><p class="cl-49f8ed54"><span class="cl-49f7e526">Whitla Hall</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-49f8f4f4"><p class="cl-49f8ed54"><span class="cl-49f7e526">Abstract</span></p></td><td class="cl-49f8f4fc"><p class="cl-49f8ed54"><span class="cl-49f7e526">The development of emotion theory benefits from cross-fertilisation between disciplines and subdisciplines.  This symposium gathers together scholars who are reconsidering psychological accounts by incorporating ideas from related domains of study to propose new angles on longstanding theoretical issues.  The first paper extends stimulus-driven and appraisal accounts of emotion causation by incorporating goal-directed concepts relating to decision theory and proposes that emotional outcomes depend on evaluation of forward-looking prospects of the utility of alternative action options.  The second paper reports on theoretical developments arising from a cross-disciplinary collaboration involving linguistics, psychology, philosophy, and neuroscience.  The authors argue that relevance theory can clarify how emotions are produced, perceived, and also communicated to other people.  The third paper, led by an anthropologist, extends this relevance-based account into the developmental domain of social learning and seeks to understand the consequences of observing caregiver emotions on children‚Äôs allocation of attention to different aspects of the social environment and their appraisals of social value.  The final paper explores the implications of moving beyond intrapsychic processes when seeking to understand and explain the emergence and communication of emotions.  The author argues that cognitive calculations of relevance or expected utility are not the only determinants or regulators of unfolding emotional episodes.  Instead, emotional meanings and actions may consolidate over time during social transactions between people engaged in joint or clashing activities.  The papers will be integrated and critiqued by a discussant who is a philosopher with substantial expertise in the various disciplines contributing to affective science.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotions as High-Impact Decisions</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Agnes Moors</strong><br>
Abstract: Emotions are typically characterized as intense and short-lived, as having a positive or negative valence, as urgent or control-precedent, as difficult to control, and as having an irrational flavor. To explain these features, traditional emotion theories have put forward a stimulus-driven process of emotion causation. This is a process in which the representation of a stimulus (e.g., snake) or stimulus features (e.g., danger) directly activates the representation of a response or action tendency (e.g., flight or defense). Traditional theories place this process in sharp contrast with a goal-directed process, which they hold responsible for instrumental actions and emotion regulation. In a goal-directed process, an action (or strategy) is selected based on a weighing of the expected utilities of the available action options (or strategies). I recently proposed a goal-directed theory, which proposes that most of our so-called emotional episodes rely on the same goal-directed process as that involved in instrumental action. The main difference is that the goals at stake in so-called “emotional” episodes have a higher value than those at stake in so-called “non-emotional, instrumental” episodes. I explain how this theory can account for the typical and apparent characteristics of emotions (i.e., intense, valenced, urgent, difficult to control, and irrational), and what the implications of this parsimonious view are for the scientific status of the set of emotions itself.<br>
&nbsp;<br>
Title: <strong>Emotions and Relevance</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Daniel Dukes, Constant Bonard, Steve Oswald, Tim Wharton, and David Sander</strong><br>
Abstract: Virtually all affective scientists place relevance (or a related concept) at the heart of their definition of emotion. And yet, a more comprehensive understanding of the notion of relevance within the affective sciences is still needed, particularly when compared to advances in pragmatic linguistics, where the concept of relevance (c.f. relevance theory) is one of the cornerstones. In this presentation, prepared by researchers in psychology, philosophy, neuroscience and linguistics, we will detail two examples concerning emotion recognition to demonstrate how beneficial a comparison of the two conceptions of relevance could be. The first is related to the contextual embeddedness of emotion recognition, while the second is related to the communicative status of emotions. Drawing on relevance theory’s cognitive model of communication, we point out how understanding whether an expression of emotion was made spontaneously or with a view to communicate something is crucial to a descriptively adequate account of emotion recognition – e.g.&nbsp;a parent squinting might be misunderstood as a signal of disapprobation because it is interpreted as intended for communication when it is only a nonintentional expression of puzzlement. We will also discuss relevance and emotion in terms of the ongoing debate between goal-directed vs stimulus-driven processes, suggesting that, during the emotion elicitation process, relevance may lie at the interface between our goals and (internal and external) stimuli. We will conclude that a comparison between the notion of relevance in emotion theory and the concept relevance in relevance theory is worthwhile for the affective sciences and beyond.<br>
&nbsp;<br>
Title: <strong>Emotions as Social Processes</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Brian Parkinson</strong><br>
Abstract: Most psychological theories see emotions as consequences of cognitive and perceptual processes involving appraisals, bodily feedback or some combination of the two and primarily located inside an individual person’s mental system. Social factors feature in these theories only as indirect influences on these intrapsychic processes. Correspondingly, research into emotion’s effects on other people often focuses on one-way information transmission that influences appraisals or automatically induced mimicry that triggers feedback processes. In this paper, I explore an alternative view of emotional action and reaction as serving the primary function of aligning people’s orientations to different aspects of meaningful social contexts. In this view, emotions either emerge from reciprocal adjustments of two or more people engaged in joint activity or from clashes and intersections between interactants’ lines of action. Individuals and groups are also able to modify their emotional course in a strategic or goal-directed manner but are likely to meet resistance and countermoves from the people they are trying to affect. Although individuals need to register each other’s changing relational positions at some level for these processes to operate, there is no need for them to arrive at any coherent emotional meaning before emotional engagement with the social world can happen. Similarly, both relevance detection and evaluation of intended outcomes can operate as socially distributed processes rather than happening squarely in the minds of each separate individual as preconditions for emotional onset.<br>
&nbsp;<br>
Title: <strong>Discussion</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Scarantino, Andrea</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t2" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t2">Parallel Session 6 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a049384{}.cl-4a0205ec{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a030cb2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a031432{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a031433{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03143c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03143d{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a031446{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a031447{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a049384"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a031432"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Track</span></p></td><td class="cl-4a031433"><p class="cl-4a030cb2"><span class="cl-4a0205ec">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a03143c"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Type</span></p></td><td class="cl-4a03143d"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a03143c"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Title</span></p></td><td class="cl-4a03143d"><p class="cl-4a030cb2"><span class="cl-4a0205ec">How does alexithymia moderate emotion processing? Evidence from cognitive and biological markers</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a03143c"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Time</span></p></td><td class="cl-4a03143d"><p class="cl-4a030cb2"><span class="cl-4a0205ec">09:15 - 10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a03143c"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Room</span></p></td><td class="cl-4a03143d"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Bann: PFC/0G/024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a031446"><p class="cl-4a030cb2"><span class="cl-4a0205ec">Abstract</span></p></td><td class="cl-4a031447"><p class="cl-4a030cb2"><span class="cl-4a0205ec"></span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The Effect of Alexithymia on Emotion Response Coherence During Positive and Negative Emotions</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Elena Constantinou, Georgia Panayiotou</strong><br>
Abstract: Alexithymia is a term used to describe a pattern of emotion processing deficits characterized by difficulties in identifying and describing feelings and an externally oriented, concrete thinking style. A hallmark characteristic of alexithymia is a decoupling between different emotional responses, particularly between subjective experience and physiological reactivity. The current study investigated this decoupling hypothesis, by assessing the coherence among subjective experience, physiological arousal and facial expressions during different types of emotional experiences. Eighty- four participants viewed neutral, pleasant and unpleasant film-clips rating continuously their subjective pleasantness using a dial, while skin conductance levels (SCL), heart rate (HR), zygomatic and corrugator activity were recorded. Lagged within person cross-correlations were calculated for each pair of emotion responses to assess coherence during film-viewing. Multi-level models examined the effects of film type and alexithymia levels on coherence. Results showed an effect of alexithymia only on the coherence between skin conductance and subjective experience, with lower coherence at higher alexithymia levels, but only for negative emotions. This effect was mainly driven by the externally-oriented component of alexithymia. Alexithymia had no effects on the coherence of other emotion response pairs. These findings provide further support for a decoupling between emotion responses in alexithymia, but also for the specificity of such deficits, which pertain only to negative emotions and only to the arousal aspect of emotional experiences.<br>
&nbsp;<br>
Title: <strong>The Relationship Between Alexithymia and Gut Microbiota in Patients with Inflammatory Bowel Disease</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Luigia Zito, Roberta Lanzara, Chiara Conti, Federico Anaclerio, Konstantinos Efthymakis, Liborio Stuppia, Piero Porcelli</strong><br>
Abstract: Background: Inflammatory bowel disease (IBD, mainly ulcerative colitis and Crohn’s disease) is a chronic intestinal disease of multifactorial etiology. The role of gut microbiota in IBD is increasingly recognized because of the bidirectional communication with the brain. To date, studies on the association between gut dysbiosis and psychological factors in IBD are few. In our ongoing longitudinal study, we aim to evaluate the relationship between intestinal microbiota and psychological factors, including alexithymia, in IBD patients. Methods: Data are related to a preliminary consecutive sample of 23 treatment-seeking IBD patients with quiescent disease activity. Patients were asked to collect a stool sample at home to evaluate microbiota composition and alteration. Alexithymia (TAS-20), gastrointestinal symptoms (GSRS), IBD health-related quality of life (IBDQ), somatic symptoms (PHQ-12), perceived stress (PSS), and depression and anxiety symptoms (HADS) were concurrently assessed. Results: Within this sample, all patients met criteria for intestinal dysbiosis. Specifically, actinobacteria were highly correlated with PHQ-12, GSRS abdominal pain and bloating, IBDQ gastrointestinal symptoms, systemic symptoms, emotional distress, and social functioning (r=.58-.76). Psychological symptoms, including alexithymia, were not correlated with bacterial strains while the DIF alexithymia component correlated significantly with GSRS abdominal pain, IBDQ systemic symptoms and emotional distress (r=. 47-.51). Conclusion: Preliminary, our results suggest that specific gut bacteria (actinobacteria) are associated with somatic symptoms rather than psychological factors, including alexithymia. The possible mediating role of alexithymia between gut microbiota and physical and mental health will be further evaluated by recruiting a larger sample size and using a longitudinal study design.<br>
&nbsp;<br>
Title: <strong>Out of Sync: Disrupted Prefrontal Brain Synchronization During Bluffing in Alexithymia</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Malina Misol, Giacomo Costa, Zhihao Wang, Branislava Ćurčić-Blake, Sander Martens, Andre Aleman, Katharina S. Goerlich</strong><br>
Abstract: Introduction: Alexithymia is associated with impairments in social cognition and interaction. One component of social interaction is strategic deception, e.g., bluffing in negotiations or poker games. Here, we hypothesized that prefrontal interpersonal brain synchronization (IBS) would be disrupted in pairs of alexithymic (TAS-20 score ≥ 61) and lexithymic individuals (AL pairs) compared to pairs of two lexithymic players (LL pairs). Methods: Functional near-infrared spectroscopy (fNIRS) hyperscanning was used to simultaneously measure medial prefrontal IBS in 30 LL and 30 AL pairs during rest, and during bluffing versus honest decisions in a poker game. Additionally, personality assessments were conducted between alexithymia facets, anxiety, depression, and ‘dark triad’ personality traits. Results: Initial results from 39 pairs (23 AL) revealed higher-resting state IBS in LL versus AL pairs. AL pairs exhibited significantly reduced task IBS during bluffing than LL pairs. Moreover, alexithymic individuals scored higher on psychopathy, Machiavellianism, depression, and anxiety than lexithymic individuals. Partial correlations controlling for depression and anxiety identified specific correlations between DDF and Machiavallianism, and DIF and psychopathy. Conclusions: Alexithymia is associated with disrupted prefrontal brain synchronization during strategic deception, providing new insights into the neural mechanisms underlying impairments in social cognition and interaction.<br>
&nbsp;<br>
Title: <strong>Alexithymia Moderates Salience Effects in Emotional Facial Expression Perception and Recognition</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Marine Mas, Olivier Luminet</strong><br>
Abstract: Introduction: Emotional salience affects cognition and contributes to adaptive emotion regulation. However, the moderating impact of alexithymia on emotional salience perception remains poorly understood. Following deficit models of alexithymia, salience perception might favor emotional processing by acting as a clue and helping individuals counter their emotional perception deficits. According to over-responding models, emotional salience might activate protective avoidance mechanisms and deteriorate performance in presence of emotional information. Methods: Emotional facial expression pictures were created from the DynaFACES Database (videos depicting actors’ faces morphing from neutral to emotional facial expressions). Ninety-four participants evaluated 160 pictures of happy, disgusted, fearful, angry and sad faces at various intensities (40%, 60%, 80%, 100%) and completed the Toronto Alexithymia Scale (TAS-20). Outcome variables were arousal ratings, valence ratings, and correct emotion recognition. Results: We found a morphing intensity by alexithymia interaction, which was explained by higher arousal ratings and better emotion recognition for emotional faces at 40% morphing intensity for people scoring higher on alexithymia. No interaction effects morphing intensity by alexithymia were observed for the higher morphing intensities. Conclusions: Higher TAS-20 total scores only predicted higher emotional responses at lower emotional salience intensity, which may then contribute to better recognition of emotional facial expressions. People with higher alexithymia can extract meaningful information to correctly recognize emotion when emotional information is the least available, supporting the over-responding model of alexithymia.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t3" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t3">Parallel Session 6 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a100d04{}.cl-4a0c9c8c{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a0da762{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a0daf46{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf47{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf50{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf51{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf52{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf53{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf5a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf64{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0daf65{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a100d04"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf46"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Track</span></p></td><td class="cl-4a0daf47"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">T3</span></p></td><td class="cl-4a0daf50"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf51"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Type</span></p></td><td class="cl-4a0daf52"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Symposium</span></p></td><td class="cl-4a0daf53"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Symposium</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf51"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Title</span></p></td><td class="cl-4a0daf52"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Emotions in Daily Life: A Closer Look at What Participants Have to Say</span></p></td><td class="cl-4a0daf53"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Emotions in Daily Life: A Closer Look at What Participants Have to Say</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf51"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Discussant</span></p></td><td class="cl-4a0daf52"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Yasemin Erbaş</span></p></td><td class="cl-4a0daf53"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Yasemin Erba≈ü</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf51"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Time</span></p></td><td class="cl-4a0daf52"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">09:15 - 10:30</span></p></td><td class="cl-4a0daf53"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">09:15 - 10:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf51"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Room</span></p></td><td class="cl-4a0daf52"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Foyle: PFC/0G/007</span></p></td><td class="cl-4a0daf53"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Foyle: PFC/0G/007</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a0daf5a"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Abstract</span></p></td><td class="cl-4a0daf64"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Emotion research has long recognized the complexity of emotional experiences, yet conventional approaches to measurement often ask participants to report their experiences along a limited set of predetermined emotion words and scales. Our symposium proposes an alternative approach, giving participants the freedom to express their experiences more elaborately. What emotion categories might emerge from their narratives, and how might these align or contrast with existing frameworks? Additionally, we aim to understand how these methods can illuminate participants‚Äô thought processes when they articulate their feelings. In the current symposium, we will seek to answer the above questions through four talks. Evgeniya Vedernikova will show emotion labels extracted from open-ended descriptions gathered via an experience sampling method (ESM) study and put those labels into context and in relation to well-being. Katie Hoemann will continue by discussing how diversity in emotion can be assessed by asking ESM participants to freely describe their everyday emotional experiences over time. Afterwards, Roza Kamiloƒülu will explore the clustering of a wide range of positive emotions in daily life, using bottom-up, computational approaches. Leonie Schorrlepp will give insights into how participants decide on their answers during ESM emotion assessments by combining cognitive interview techniques with standard rating scales. Finally, Yasemin Erba≈ü will summarize the above presentations and suggest future directions to fill current gaps. Together, these talks will give new insights into the richness of emotional experiences in daily life and how we can best capture these experiences.</span></p></td><td class="cl-4a0daf65"><p class="cl-4a0da762"><span class="cl-4a0c9c8c">Emotion research has long recognized the complexity of emotional experiences, yet conventional approaches to measurement often ask participants to report their experiences along a limited set of predetermined emotion words and scales. Our symposium proposes an alternative approach, giving participants the freedom to express their experiences more elaborately. What emotion categories might emerge from their narratives, and how might these align or contrast with existing frameworks? Additionally, we aim to understand how these methods can illuminate participants‚Äô thought processes when they articulate their feelings. In the current symposium, we will seek to answer the above questions through four talks. Evgeniya Vedernikova will show emotion labels extracted from open-ended descriptions gathered via an experience sampling method (ESM) study and put those labels into context and in relation to well-being. Katie Hoemann will continue by discussing how diversity in emotion can be assessed by asking ESM participants to freely describe their everyday emotional experiences over time. Afterwards, Roza Kamiloƒülu will explore the clustering of a wide range of positive emotions in daily life, using bottom-up, computational approaches. Leonie Schorrlepp will give insights into how participants decide on their answers during ESM emotion assessments by combining cognitive interview techniques with standard rating scales. Finally, Yasemin Erba≈ü will summarize the above presentations and suggest future directions to fill current gaps. Together, these talks will give new insights into the richness of emotional experiences in daily life and how we can best capture these experiences.</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotion Words: What’s Inside People’s Affective Reports</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Evgeniya Vedernikova</strong><br>
Abstract: In their lives, people face various events that might evoke a wide range of emotions. Studying these emotions and how they change when people adapt to those events lies at the heart of people’s well-being. Current emotion measures are not ideal for such studies. Most measures are based on retrospective questions of how frequently people experience certain emotions. The emergence of experience sampling methods (ESM) has greatly improved our possibilities for studying emotional development and change. However, these methods often still rely on a very limited, preselected set of default emotion terms that do not necessarily capture how people describe their own emotions and what they feel in daily life. We investigate emotional adaptation by asking people to describe in their own words, which emotions are experienced as well as how these emotions are related to well-being. In an ESM study participants report their emotional experiences in a free way with open-ended questions without being limited by multiple choice items. Also, we look into their well-being via short, close-ended items. We present and discuss the initial findings of this study. This study would help get a better understanding of people’s emotional adaptation: what emotions are experienced in everyday life, in which contexts, and at which well-being levels. Emotion labels received in this study will be a useful ground for future ESM studies.<br>
&nbsp;<br>
Title: <strong>Diversity in Everyday Experiences of Emotion: A Natural Language Approach</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Katie Hoemann</strong><br>
Abstract: Research on diversity in emotion examines the range and balance of emotions experienced in the moment and over time, to date linking these to positive real-world outcomes such as fewer mental and physical health symptoms, as well as greater social cognitive and wise reasoning abilities. To measure diversity, participants are commonly asked to rate sets of pre-specified emotions. This approach overlooks the richness and nuance of everyday experiences of emotion, potentially obscuring individual and situational differences therein. Bringing natural language to bear on diversity can clarify whether key findings extend to spontaneously-generated emotion words. We address this need through secondary analysis of studies that have asked participants to freely label or describe their emotional experiences over the course of several weeks. This innovative approach allows us to observe the emotion words used and how they may fluctuate in daily life contexts. Using these proof-of-concept data, we evaluate how lexical estimates of diversity in emotion are associated with relevant outcomes (e.g., momentary affect, self-reported depression and anxiety). We discuss these initial results in terms of their consistency with the existing literature and their implications for future research – including a larger ongoing study in which participants verbally describe their current experiences four times a day for 70 days. We conclude by considering how we sample and define language for emotion and how we understand the role of diversity in promoting health.<br>
&nbsp;<br>
Title: <strong>The Granularity of Good: Distinguishing Positive Emotional Experiences</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Roza Kamiloğlu</strong><br>
Abstract: What does it mean to feel good? This research investigates the distinct nature of positive emotions through a semantic space analysis of personal narratives. We questioned whether different types of positive experiences, such as the awe of natural beauty or the thrill of a sports victory, are fundamentally unique. To explore this, we collected and computationally analyzed 3,592 instances of 22 positive emotions from 165 individuals. Our method involved unsupervised clustering to identify distinct patterns within these narratives, with the goal of maximizing internal consistency and distinctiveness among emotional categories. This technique allowed us to establish clear inter-cluster differences and intra-cluster similarities, indicating that each cluster was both unique from the others and consistent within itself. The analysis yielded four emotions — amusement, interest, lust, and tenderness — that each formed their own cluster, suggesting they are uniquely experienced. By applying semantic space analysis to in-depth personal emotional narratives, this research enhances our understanding of positive emotions and contributes to the refinement of emotion taxonomies. The insights gained hold implications for advancing psychological research methodologies and enriching the practice of psychological assessment.<br>
&nbsp;<br>
Title: <strong>How Do People Decide How They Feel? Response Processes in Experience Sampling Method Studies</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Leonie Schorrlepp</strong><br>
Abstract: Emotions play a central role in our functioning. A prominent way for the assessment of emotions is the Experience Sampling Method (ESM). Due to technological advances of the past decades, ESM research is booming among researchers and clinicians and is now commonly used to study dynamics in emotions. To justify the use of ESM to study emotions in research and clinical practice, valid measurements are crucial. However, recently concerns have been voiced regarding the validity of emotion assessments using ESM. In particular, research suggests that participants apply different response processes to decide on their answers, making intra-individual and inter-individual comparison difficult. That is, for the question ‘how sad are you right now’ on a scale from 1 (not at all) to 7 (very much), a ‘4’ may often carry different meaning for different participants and even for the same one at different points in time. During the presentation, we will share initial results of a mixed-methods investigation into response processes during emotion assessment, combining ESM and qualitative interviewing techniques. During the study, participants rated their emotions five times per day across 28 days of ESM. We also asked participants to reflect on their rating choices in the moment using open-ended data. Additionally, we conducted several semi-structured and cognitive interviews during the 28-day period to get a more detailed insight into participants’ response processes. We will present answering profiles derived from our analysis of these interviews to illustrate that intra- and interindividually inconsistent response processes are indeed present, posing to the validity of ESM data.<br>
&nbsp;<br>
Title: <strong>Discussion</strong><br>
Time: 10:15-10:30<br>
Authors: <strong>Erba≈ü, Yasemin</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t4" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t4">Parallel Session 6 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a23ca42{}.cl-4a1719d2{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a224afa{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a225270{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a22527a{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a22527b{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a22527c{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a225284{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a225285{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a23ca42"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a225270"><p class="cl-4a224afa"><span class="cl-4a1719d2">Track</span></p></td><td class="cl-4a22527a"><p class="cl-4a224afa"><span class="cl-4a1719d2">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a22527b"><p class="cl-4a224afa"><span class="cl-4a1719d2">Type</span></p></td><td class="cl-4a22527c"><p class="cl-4a224afa"><span class="cl-4a1719d2">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a22527b"><p class="cl-4a224afa"><span class="cl-4a1719d2">Title</span></p></td><td class="cl-4a22527c"><p class="cl-4a224afa"><span class="cl-4a1719d2">Interpersonal Context</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a22527b"><p class="cl-4a224afa"><span class="cl-4a1719d2">Time</span></p></td><td class="cl-4a22527c"><p class="cl-4a224afa"><span class="cl-4a1719d2">09:15 - 10:15</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a225284"><p class="cl-4a224afa"><span class="cl-4a1719d2">Room</span></p></td><td class="cl-4a225285"><p class="cl-4a224afa"><span class="cl-4a1719d2">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Adolescents’ Regulation of Positive and Negative Emotions and Affect: Moderation of Peer Status and Affiliation</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Visscher, Anke; Sijtsema, Jelle; van Roekel, Eeske; Bogaerts, Stefan</strong><br>
Abstract: Adolescents’ emotion regulation shapes adolescents’ behavior and cognitive processes, impacting their overall development. (Experienced) social environments, particularly peer contexts, play a crucial role in shaping how adolescents regulate their emotions. Yet, a gap persists in understanding the dynamics of emotions within specific peer contexts. Peer affiliation and peer status are two important and distinct factors that might influence adolescents’ emotion regulation (ER). Therefore, this study examined to what extent peer status and peer affiliation affect the relationship between the use of (positive and negative) ER strategies, and positive (PA) and negative affect (NA) in adolescents’ daily life. Dutch adolescents attending pre-vocational education reported on their momentary positive and negative affect, and ER of both positive affect and negative emotions (i.e., rumination, expression, sharing) 3 times per day for a 14-day period. Results highlight the interplay between peer dynamics, ER strategies, and both PA and NA. This study provides valuable insights into the contextual factors influencing adolescent emotional experiences.<br>
&nbsp;<br>
Title: <strong>The Link Between Need Frustration and Empathic Accuracy in Romantic Relationships</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Scharmer, Aurelia Lilly; Stas, Lara; Ickes, William; Verhofstadt, Lesley</strong><br>
Abstract: The frustration of relational needs, encompassing relatedness, autonomy, and competence, is a major driver of conflicts in romantic relationships. Relational need frustration has been negatively associated to multiple key relationship processes, including conflict resolution. Despite abundant research suggesting that need frustration might also undermines empathic accuracy, the ability to infer another person’s thoughts and feelings accurately (i.e., to perceive another person’s thoughts and feelings in a manner consistent with the way they experience and report them), this association has never been tested empirically. In this study, we tested the hypothesis that during couples’ conflict interaction, need frustration and empathic accuracy are negatively associated within the same person. To this end, we analyzed data from a lab-based conflict interaction study, including a video-mediated recall task. Using an Actor-Partner Interdependence Model, we found that women’s need frustration, but not men’s, was negatively linked to their own empathic accuracy during couple conflict. An exploratory analysis of the partner effects revealed a positive association between men’s level of need frustration and women’s empathic accuracy during couple conflict. These findings highlight the importance of taking need frustration into account―by researchers and clinicians―when trying to understand and enhance relational well-being.<br>
&nbsp;<br>
Title: <strong>Failed Empathy Interventions</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Tagesson, Alexander; Pärnamets, Philip; Wallin, Annika</strong><br>
Abstract: We empathize when doing so aligns with our underlying motives and avoid empathy when it hinders fulfilment of these motives. Recently, leading empathy researchers have tried to get people to become more empathic, and more pro-social, by using motivated empathy interventions. In our study, we create an interventions competition, using previously published interventions, to test which interventions increase motivation to empathize and prosociality in both an in- and outgroup context. Using self-report- and behavioral measures, participants reported how much empathy they felt with someone suffering from poverty and was offered to make a real-life monetary donation to poverty prevention and help the suffering person. Our results suggest that interventions designed to increase motivation to empathize do not perform better than a control intervention. Interventions did not get participants to become more empathic or pro-social; importantly, some interventions made participants significantly less empathic than control. This negative effect might explain some of the previous results on motivated empathy interventions. It might also be an important experimental tool for future studies: even if we cannot make people more empathic, restricting their empathy still gives us an opportunity to study empathy’s impact in social situations. An additional finding suggests that different types of motivated empathy interventions, with different underlying mechanisms for motivating empathy, perform equally in different contexts. First-time being tested, this result is surprising, as it should allegedly be easier to motivate oneself to empathize with ingroup members as compared with outgroup members.<br>
&nbsp;<br>
Title: <strong>Do Emotions Matter in Business Relationships?</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Zlatanou, Filoumena; Dickert, Dr Stephan; Henneberg, Prof.&nbsp;Stephan C.</strong><br>
Abstract: Emotions comprise a complex network of interconnected subevents that focus on a target (e.g., person, event, or object), and involve appraisal, attributional, behavioral, and physiological processes (Russell &amp; Feldman Barrett, 1999). They exert a notable influence on many psychological procedures, including cognitive functions, social perceptions, motivations, judgement formation, decision-making and action tendencies (Han et al., 2007; Slovic et al., 2007). Next to their interpersonal influence, emotions may play a critical role in facilitating or hindering the development of business relationships, which are defined as long-term interorganizational collaborations and exchanges (Lambe et al., 2000; Palmatier, 2008) that hinge on social interactions between individuals acting as economic agents on behalf of their firms (Forkmann et al., 2022). This study investigates the role of emotions in business relationships, by specifically exploring their interplay with established attitudinal mechanisms such as trust and commitment, which characterize Business-to-Business (B2B) interactions (Harmeling et al., 2015). Fifteen senior managers from diverse B2B industries were subjected to in-depth interviews using the methodology established by Gioia et al.&nbsp;(2013). The analysis gives rise to an elaborate nomological model highlighting the subtle impact of expected and unexpected (counterintuitive) emotions in the context of business relationships both at an interpersonal and interorganizational level. A gamut of positive and negative emotions is triggered by adherence to or deviation from relational norms, contributing to the development of pivotal attitudinal constructs (Selnes &amp; Grønhaug, 2000). The present study links emotion and business literature to extend the present theoretical viewpoints on emotions as significant mechanisms underlying enduring business relationships.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t5" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t5">Parallel Session 6 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a2d954a{}.cl-4a2a8fa8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a2ba0f0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a2ba8fc{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a2ba8fd{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a2ba8fe{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a2ba8ff{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a2ba906{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a2ba907{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a2d954a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a2ba8fc"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Track</span></p></td><td class="cl-4a2ba8fd"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a2ba8fe"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Type</span></p></td><td class="cl-4a2ba8ff"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a2ba8fe"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Title</span></p></td><td class="cl-4a2ba8ff"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">History and Aesthetics</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a2ba8fe"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Time</span></p></td><td class="cl-4a2ba8ff"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">09:15 - 10:00</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a2ba906"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Room</span></p></td><td class="cl-4a2ba907"><p class="cl-4a2ba0f0"><span class="cl-4a2a8fa8">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotions and Values</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>de Sousa, Ronald B</strong><br>
Abstract: Two features are widely regarded as crucial components of emotions: formal objects, (Teroni 2007) which identify an emotion by specifying its correctness or ‘fittingness’ conditions, and motivating force or ‘action readiness’ (Frijda 2004). This paper argues that the objective reality of a value apprehended by an emotion relates to its ‘practical specificity’. An emotion is high in practical specificity when it gives rise to a relatively narrow range of motivating goals. So-called ‘basic emotions’ like fear or anger, particularly if interpreted as ‘affect programs’ shaped by natural selection or early conditioning, are high in practical specificity. They are plausibly viewed as related to needs. Needs, unlike mere wants. are specifiable de re, independently of the description under which they are presented.(Wiggins 1998). They are therefore likely to motivate relatively specific goals. Other emotions, by contrast, notably aesthetic emotions, have ostensible formal objects that provide little or no guidance. If an emotion’s formal object does not in itself rationalize any goals or action tendencies, then it is unlikely to have originated in specific organismic need. A low degree of practical specificity may partly explain why aesthetic disputes are notoriously difficult to resolve. While aesthetic values may reflect vestiges of traits conditioned by evolutionary pressures, our current interest in them, honed by idiosyncratic biographical experience as well as by social facts, may be all that is now left of their ‘reality’. That doesn’t mean such things don’t matter: just that their mattering is essentially subjective, and reflects no objective, stance-independent value.<br>
&nbsp;<br>
Title: <strong>Social Categories in the Dramatisation of Anger in Ancient Greek Comedy</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Irarrazabal, Manuela</strong><br>
Abstract: This paper discusses anger in Aristophanes ’comedies from the perspective of embodied cognitive theory. Following the “conceptual metaphors” model proposed by Lakoff and Johnson (1980; 1999), according to which abstract concepts, such as anger, relay upon metaphors that are grounded in bodily experience, I argue that the representation of anger in Greek comedy sheds light on social aspects of Athenian life such as gender and class divisions. Lakoff’s “opponent” metaphor (1987) designates a variety of symbolic representations used to conceptualise anger, such as it being an entity taking hold of us and imposing demands. This last idea can take the form of a transaction, which is in line with the view that emotions are strategic moves in an ongoing exchange between socially situated organisms (Griffiths and Scarantino, 2001). Conceptualisations of anger, and by this I mean presuppositions rather than explicitly articulated theories, are rich in ideologies as to when, where and towards whom emotions are justified. Members of a certain social group are portrayed as more prone to anger than others. Yet, the way these assumptions operate is not always that straightforward. While Aristotle’s claim that to be angry one needs to have a certain status in society (otherwise fear prevails), here I argue that by looking at comedy we can get a more nuanced understanding of the complexity of social categories in antiquity. As a corollary, this paper shows the value that literary representations of emotions can have for understanding both their history and their role in society.<br>
&nbsp;<br>
Title: <strong>Fluency, Prediction, and Motivation: Processing Ease, Expectations, and Goals Determine Emotional Reactions to Art</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Winkielman, Piotr; Jasko, Katarzyna; Yoo, Jenny</strong><br>
Abstract: This theoretical talk, illustrated with data, discusses psychological mechanisms underlie aesthetic emotions. We propose important extensions of Processing Fluency Theory of Aesthetic Pleasure. This theory posits that ease of processing elicits positive feelings and thus enhances stimulus evaluations. In recent years, however, the theory faced serious empirical and conceptual challenges. We propose to extend it by integrating insights from Predictive Processing Frameworks (PPF) and the Epistemic Motivation Model (EMM). We propose four extensions. First, fluency of a stimulus depends on perceivers’ expectations – their internal model of the world. Second, perceivers also form expectations about fluency itself and thus can experience surprising fluency. These expectations can come from the individual’s history, their current task, and their environment. Third, perceivers can value fluency but also disfluency, reflecting their non-directional epistemic goals (motivation to achieve or avoid certainty). Fourth, perceivers also have directional epistemic goals, preferring specific conclusions or belief content. Consequently, affective reactions depend on whether the stimulus satisfies those goals. These directional epistemic goals may override concerns about fluency or change the value of fluency associated with specific content. We review supporting evidence and introduce novel predictions. By integrating insights from PPF and EMM, our expanded framework can better capture established fluency effects and highlights their limitations and extensions. This talk is based on a theoretical paper that has been recently published in the special issue of Philosophical Transactions of the Royal Society. This special issue focused on integration of Predictive Coding Theories of Aesthetic Emotions with standard approaches to aesthetic judgments.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t6" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t6">Parallel Session 6 : T6</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a371066{}.cl-4a342522{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a352620{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a352dbe{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a352dbf{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a352dc0{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a352dc8{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a352dc9{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a352dca{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a371066"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a352dbe"><p class="cl-4a352620"><span class="cl-4a342522">Track</span></p></td><td class="cl-4a352dbf"><p class="cl-4a352620"><span class="cl-4a342522">T6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a352dc0"><p class="cl-4a352620"><span class="cl-4a342522">Type</span></p></td><td class="cl-4a352dc8"><p class="cl-4a352620"><span class="cl-4a342522">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a352dc0"><p class="cl-4a352620"><span class="cl-4a342522">Title</span></p></td><td class="cl-4a352dc8"><p class="cl-4a352620"><span class="cl-4a342522">Conflicts in Clinical Contexts</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a352dc0"><p class="cl-4a352620"><span class="cl-4a342522">Time</span></p></td><td class="cl-4a352dc8"><p class="cl-4a352620"><span class="cl-4a342522">09:15 - 10:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a352dc9"><p class="cl-4a352620"><span class="cl-4a342522">Room</span></p></td><td class="cl-4a352dca"><p class="cl-4a352620"><span class="cl-4a342522">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Interpersonal Capitalization and Unmet Interpersonal Needs Among Adolescents at Varying Risk for Suicidal Ideation</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Perezmontemayor Cruz, Ignacio; MacNeil, Sasha; Gouin, Jean-Philippe</strong><br>
Abstract: Introduction: Perceived burdensomeness and thwarted belongingness are appraisals of unmet interpersonal needs associated with higher risk of suicidal ideation. While prior studies have examined the influence of negative interpersonal experiences on unmet interpersonal needs, little is known about the role of positive interpersonal processes. Interpersonal capitalization, the action of sharing a positive personal event with close others, is an interpersonal process that increases positive affect and connectedness between the sharer and the responder. This study examined whether daily capitalization was associated with fluctuations in perceived burdensomeness, thwarted belongingness, and positive affect among adolescents at higher- and lower-risk of suicidal ideation. Methods: This study included adolescents (Mage=15.55; range=12-18; 74.55% female) with a major depressive disorder considered at higher-risk for suicidal ideation (Higher-Risk group; n=23), and adolescents without psychopathology considered at lower-risk for suicidal ideation (Lower-Risk group; n=32). Participants completed a ten-day daily-diary procedure with measures of daily interpersonal capitalization, positive affect, perceived burdensomeness, and loneliness as a proxy for thwarted belongingness. Within-person analyses examined the associations of daily capitalization with burdensomeness, loneliness, and positive affect across groups. Results: Only the higher-risk group reported lower perceived burdensomeness and loneliness on days where they engaged in more capitalization. While higher capitalization was associated with higher positive affect in both groups, the higher-risk group benefitted from larger increases in positive affect in response to capitalization. Conclusion: Engaging in daily interpersonal capitalization may be useful to reduce daily thwarted belongingness and perceived burdensomeness and increase positive affect among adolescents at higher risk for suicidal ideation.<br>
&nbsp;<br>
Title: <strong>The Effects of Emotion on Harmful Health Behaviors: Opposing Effects of Incidental Versus Integral Sadness</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Chen, Sarah (Shih-Hua); Wang, Ke; Rees, Vaughan ; Lee, Irene; Tan, Andy; Lerner, Jennifer</strong><br>
Abstract: Judgment and decision making research has long assumed that integral and incidental forms of an emotion exert similar influences on behavior. However, this assumption remains largely unexamined. To address this gap, the present research explored differences in the underlying mechanisms of integral versus incidental sadness on decisions regarding addictive substances. Previous studies have found that incidental sadness increases craving to smoke as well as the duration of nicotine inhalation (Dorison et al., 2020). However, whether these effects also occur under the influence of integral sadness remains unclear. Drawing on the Appraisal Tendency Framework (Lerner &amp; Keltner, 2000, 2001), we hypothesized that the effects of sadness on decisions about substance use would depend on the degree to which evoked sadness relates conceptually to the substance itself. The more closely linked sadness is to smoking, the lower craving for cigarettes should be. Across two experiments with smokers (N = 1,344), we hypothesized and found that, compared to neutral-mood, integral sadness decreased (d = –.47, p &lt; .001), whereas incidental sadness increased (d = .12, p = .01), craving. Additionally, integral sadness increased intentions to quit, compared to neutral conditions (d = –.45 ~ –.51, p &lt; .001); incidental sadness did not. Our findings thus challenge the long-held assumption that incidental and integral forms of a given emotion share similar influences on judgment and decision. The present work offers theoretical advances for research on emotion and provides a novel perspective for incorporating insights from emotion science to predict and influence health behaviors.<br>
&nbsp;<br>
Title: <strong>Show No Fear: An Analysis of Staff Communication During Conflict Management in Acute Adult Inpatient Mental Health Settings.</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>O’Neill, Ciara; Brew, Benjamin; Hoe, Juanita; Cibelli, Francesca; McCabe, Rose; Lavelle, Mary</strong><br>
Abstract: Inpatient mental health wards are under pressure due to high bed occupancy rates and staff shortages. Service users can be acutely unwell and often admitted involuntarily (40%). Behavioural displays of conflict such as aggression and violence can be features of this environment. Healthcare staff attempt to diffuse conflict behaviours, when they arise, through verbal and non-verbal communication, known as de-escalation. However, de-escalation training is not evidence based and practice varies greatly. Training programs advocate that de-escalating staff control their own emotional expression in such situations, particularly the expression of fear and anxiety. However, little is known about how this occurs in practice or how this relates to de-escalation success. The aim of this study is to explore the emotional expression of staff during de-escalation incidents in real world settings and examine the relationship with de-escalation success. De-escalation success has been operationalised as halting the sequence of conflict for that service user avoiding the need to use restrictive practices such as restraint (held to limit movement), seclusion (locked in isolation) and rapid tranquilisation (involuntarily injected with psychotropic medication). Method De-escalation incidents (n=46), involving a service user and one (or multiple) members of staff, on acute adult mental health wards are being recorded using body cameras worn by staff. Staff will also complete a questionnaire battery examining their experience and fear of violence at work. Analysis Staff verbal and nonverbal communication will be annotated in ELAN, providing a behavioural time series that can be exported for analysis. An adapted version of the Ethological Coding System for Interviews will guide hand annotation of behavioural markers associated with flight, displacement and social avoidance. The relationship between staff behaviours and (i) their fear of violence and (ii) de-escalation success will be examined. Results Analysis of this data is currently underway and the findings will be presented. The findings of this study will provide evidence to inform de-escalation training and clinical practice.<br>
&nbsp;<br>
Title: <strong>Coping with Emotional Distress via Self-Disclosure to Robots: Intervention with Caregivers</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Laban, Guy; Morrison, Val; Kappas, Arvid; Cross, Emily</strong><br>
Abstract: People engage in self-disclosure to others when trying to regulate the impact of emotional distress. Here we introduce a novel long-term intervention aimed at supporting informal caregivers to cope with emotional distress via self-disclosing to a social robot. Informal caregivers often struggle in managing the emotional and practical demands of the caregiving situation and experience a lack of social support and interaction. Accordingly, we were interested in the extent of informal caregivers’ self-disclosure towards a social robot over time, and how perceptions of the robot develop over time. Moreover, we wished to examine how this intervention made informal caregivers feel, and the extent to which interacting with the robot affected these individuals’ emotion regulation. In a mediated experiment 34 Informal caregivers conversed with a social robot 10 times across 5 weeks about general everyday topics. Our results show that informal caregivers self-disclosed increasingly more to the robot across time and perceived it as increasingly social and competent over time. Participants’ moods positively changed after interacting with the robot, which they perceived as more comforting over time. Participants also reported feeling increasingly less lonely and stressed. Finally, our results showed that after self-disclosing to the robot for 5 weeks, informal caregivers reported being more accepting of their caregiving situation, reappraising it more positively, and experiencing fewer feelings of blame towards others. These results set the stage for establishing relationships with robots, and highlight how communicating with social robots holds the potential for providing emotional support for people coping with emotional distress.<br>
&nbsp;<br>
Title: <strong>Parents’ Depressive Symptomatology and their Perception of their Autistic Children’s Emotion Regulation Difficulties</strong><br>
Time: 10:15-10:30<br>
Authors: <strong>Costa, Andreia P.</strong><br>
Abstract: Parents of autistic children have significantly more depressive symptomatology than parents of neurotypical children (Cohrs &amp; Leslie, 2017). To understand which factors might contribute to that, 108 parents (36 ASD, 72 TD) of children aged 4-12 years answered to three questionnaires: the Center for Epidemiologic Studies Depression Scale (CES-D; Radloff, 1977; parents’ depressive symptomatology), the Autism Spectrum Quotient Questionnaire for Children (AQ-Child; Auyeung et al.&nbsp;2008; children’s autistic traits), and the Emotion Regulation Checklist for children (ERC; Shields &amp; Cicchetti, 1997; children’s emotion regulation ability). The results revealed that autistic children were reported by their parents as having less emotion regulation ability than neurotypical children (t(106)=7.68, p&lt;.001, ES r=.60). The odds of presenting clinically significant depressive symptomatology (CES-d&gt;16) among parents of children with autism were 5 times higher than among parents of neurotypical children (χ2(1)=13.29, p&lt;.01, OR=5). Furthermore, parents with high depressive symptomatology (CES-d&gt;16) reported increased emotion regulation difficulties in their children (t(106)=3.18, p&lt;.01, ES r=.30). Regression analyses revealed that parents’ perceptions of their children’s emotion regulation difficulties were a better predictor of parents’ depressive symptomatology than children’s diagnostic status. These results suggest that how parents perceive their children’s difficulties with emotion regulation might be an important aspect in the understanding of depression in parents of autistic children. However, further research is needed to better understand that relation as a cyclical and perhaps bi-directional relationship: parents’ perception of their child’s emotional difficulties may be linked to their depressive symptomatology, which in turn may aggravate the children’s emotional difficulties.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="parallel-session-6-t7" class="level2">
<h2 class="anchored" data-anchor-id="parallel-session-6-t7">Parallel Session 6 : T7</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a4037e0{}.cl-4a3db862{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a3eb6b8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a3ebe24{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a3ebe25{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a3ebe2e{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a3ebe2f{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a3ebe38{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a3ebe39{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a4037e0"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a3ebe24"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Track</span></p></td><td class="cl-4a3ebe25"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">T7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a3ebe2e"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Type</span></p></td><td class="cl-4a3ebe2f"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Individual Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a3ebe2e"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Title</span></p></td><td class="cl-4a3ebe2f"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Recognition and Perception</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a3ebe2e"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Time</span></p></td><td class="cl-4a3ebe2f"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">09:15 - 10:30</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a3ebe38"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Room</span></p></td><td class="cl-4a3ebe39"><p class="cl-4a3eb6b8"><span class="cl-4a3db862">Moyola: PFC/02/017</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The Effects of Facial Feedback on the Automatic Discrimination of Facial Expressions</strong><br>
Time: 9:15-9:30<br>
Authors: <strong>Baker, Joshua; Van der Donck, Stephanie; Boets, Bart; Korb, Sebastian</strong><br>
Abstract: The role of facial muscle activations in how we perceive the emotional world has been debated. Some evidence suggests that feedback generated by facial muscles can guide our interpretation of facial expressions, and that accurate recognition of others’ emotional expressions is aided by a simulation mechanism involving our own motor system. I will present a preregistered study (N=30) that examines the effect of posing a smile on the automatic discrimination of facial expressions as indexed by steady-state visual evoked potentials (ssVEPs) during an oddball paradigm. By presenting images of different facial expressions at different frequencies, one can derive power from EEG spectra at the same frequencies, and deduce the extent to which different types of expressions are automatically discriminated. Such ‘frequency tagging’ techniques offer an excellent signal to noise ratio, and may reveal novel effects of facial feedback on the visual processing of facial expressions.<br>
&nbsp;<br>
Title: <strong>Judgments of Smile Genuineness in an Intergroup Context</strong><br>
Time: 9:30-9:45<br>
Authors: <strong>Milošič, Ana; Khan-Djuric, Anika; Kremer, Sophia; Rychlowska, Magdalena; Shore, Danielle M</strong><br>
Abstract: We investigate how group membership affects smile judgments. In three preregistered studies (N = 400), participants rated the genuineness of posed and spontaneous smiles (UvA Nemo Smile Database). Participants initially evaluated smiles without having any information about the expresser’s group membership. Later, in a minimal group paradigm, they were informed about expressers’ ingroup or outgroup status. We examine the influence of this information on participants’ judgments. In Study 1, smile discrimination accuracy (measured with the d’ statistic) was not affected by information about group membership. However, participants’ tendency to rate smiles as genuine (measured with the criterion C) increased when the expresser was an ingroup member. The opposite tendency to rate smiles as posed was observed when the expresser was an outgroup member. Participants were also more motivated to accurately judge the smiles of ingroup than outgroup members. This result suggests that the interpretation of positive expressions, which are critical for establishing harmonious intergroup exchanges, can be distorted even in a minimal group paradigm. Studies 2 and 3 aim to replicate these findings. Additionally, Study 3 measured participants’ looking behavior with an eye tracker. Ongoing analyses examine how group membership affects the d’ and C statistics as well as the time participants spent looking at the expressers’ eyes versus the mouth. We predict that this time will be longer for ingroup members compared to outgroup members. Together, the studies will provide insights into the role of attention to the eyes in judgments of facial expressions in intergroup contexts.<br>
&nbsp;<br>
Title: <strong>Personality Information Shapes Judgment of Emotional Expressions</strong><br>
Time: 9:45-10:00<br>
Authors: <strong>Sevi, Leora; Catmur, Caroline; Bird, Geoff</strong><br>
Abstract: We do not infer the emotions of others in a vacuum of information about their traits; we often possess pre-existing knowledge of, or rapidly infer, the personality traits of those we interact with. However, emotion recognition research has mostly used anonymous target stimuli and thus has not considered how this potentially important source of information might be integrated into emotion judgments. We theorised that presenting personality information about targets (arbitrarily attributed and counterbalanced across participants) would alter the judgment of emotions from their facial expressions compared to judgments made prior to any trait information. This hypothesis was consistently supported across four studies (total N = 345), using both artificially-generated and real expression stimuli, and employing two paradigms, one requiring explicit ratings of emotion and the other implicit matching of expression stimuli. Study 3 supported the hypothesis that this effect depends on participants’ idiosyncratic beliefs about the direction and magnitude of the relationships between traits and emotions. Study 4 replicated this result using naturalistic dynamic expression stimuli, and demonstrated that the effect of participants’ personal trait priors further depends on their beliefs about its precision and the precision of the expression stimuli and trait priors (i.e., how diagnostic the trait or expression is as to the emotion); participant’s personal trait priors had the greatest effect on their shift in emotion judgment when they were more precise and combined with expressions judged to be less diagnostic, aligning with Bayesian theories of cue integration. Our findings highlight an important role for trait information in shaping judgments of emotion, with broader implications regarding the relationship between the processes of impression formation and emotion inference.<br>
&nbsp;<br>
Title: <strong>Embodied Emotion: Implicit Facial Muscle Response Patterns to Emotion Words Align with Prototypical Facial Emotional Expressions</strong><br>
Time: 10:00-10:15<br>
Authors: <strong>Wingenbach, Tanja S H; Baker-Kukona, Anuenue; Rismawati , Rizky</strong><br>
Abstract: Embodiment grounds emotion in the body. Processing an emotion word is predicted to demonstrate itself in the body similarly to experiencing an emotion. Previous research showed facial muscle activity in line with an emotion word’s valence during processing. Much less is known about emotion-specificity in facial muscle activity while processing emotion words. The current study aimed to test for embodiment of emotion as represented in facial muscle activity across the face using emotion word stimuli. It was hypothesised that the implicit facial muscle activity aligns with the prototypical pattern for facial expressions of anger, disgust, fear, sadness, surprise, and happiness. Participants (N = 76, male = 16, female = 59, non-binary = 1, M(age) = 26.9, SD = 8.4) silently read emotion words associated with the six emotion categories while facial electromyography was measured from the facial muscle sites: depressor anguli oris, zygomaticus major, levator labii, corrugator supercilii, and frontalis. Repeated measures contrasts for pattern hypotheses were conducted on a subset of participants (n = 50), as the remaining data is currently still being pre-processed. Contrasts were a-priori defined per emotion category across facial muscle sites based on prototypical assumptions of facial emotional expressions. Results showed significant alignment between the expected and the observed facial muscle activity for all six emotion categories. Given that the measured facial muscle activity aligned with the prototypical facial expression for the tested emotion categories, the current study further supports embodiment and suggests that emotion words are represented in the face in an emotion-specific manner.<br>
&nbsp;<br>
Title: <strong>Modulating Facial Emotion Recognition with Electrical Muscle Stimulation</strong><br>
Time: 10:15-10:30<br>
Authors: <strong>Korb, Sebastian; Efthimiou, Themis; Baker, Joshua; Mehu, Marc; Elsenaar, Arthur; Clarke, Alasdair</strong><br>
Abstract: Facial neuromuscular electrical stimulation (fNMES) is a novel non-invasive method for precisely controlling activations of specific facial muscles for brief durations and at specific time points during a task. This provides a powerful means to better understand how facial expressions influence felt and perceived emotions. I will be presenting data from several experiments showing that 500 ms of fNMES to bilateral smiling muscles can bias responses in an emotion categorisation task, making participants more likely to perceive emotionally ambiguous facial expressions as happy.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="flash-talks-abstracts" class="level1">
<h1>Flash Talks Abstracts</h1>
<div style="page-break-after: always;"></div>
<section id="flash-talks-1-t1" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-1-t1">Flash Talks 1 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a521906{}.cl-4a4f7c1e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a508604{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a508d66{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a508d70{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a508d7a{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a508d7b{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a508d7c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a508d84{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a521906"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a508d66"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Track</span></p></td><td class="cl-4a508d70"><p class="cl-4a508604"><span class="cl-4a4f7c1e">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a508d7a"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Type</span></p></td><td class="cl-4a508d7b"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a508d7a"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Title</span></p></td><td class="cl-4a508d7b"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Development</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a508d7a"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Time</span></p></td><td class="cl-4a508d7b"><p class="cl-4a508604"><span class="cl-4a4f7c1e">16:45 - 17:33</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a508d7c"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Room</span></p></td><td class="cl-4a508d84"><p class="cl-4a508604"><span class="cl-4a4f7c1e">Bann: PFC/0G/024</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The Early Emotional Environment: What Facial Configurations Do Infants Typically See in Natural Social Interactions?</strong><br>
Time: 16:45-16:53<br>
Authors: <strong>Ogren, Marissa; Leotti, Lauren; Hoemann, Katie; Barrett, Lisa; LoBue, Vanessa</strong><br>
Abstract: Learning about emotions is crucial for early social and emotional development. Children begin this process from a young age, but it is unclear precisely how they do so. In particular, little is known about what specific emotional input infants and young children receive and learn from across the first few years of life. To address this, the present study used existing videos (SEEDLings; Bergelson &amp; Aslin, 2017) wherein infants wore head-mounted video cameras during naturalistic 60-minute home sessions. Videos from 6 to 8 months (N=44) and 9 to 11 months (N=34) were coded for when a face was within infants’ field of view and for facial muscle movements (using FACS; Ekman, Friesen, &amp; Hager, 2002). We examined how often these facial configurations aligned with stereotypes corresponding to 18 different emotions (happiness, sadness, anger, interest, etc.). At both ages, the most frequently observed facial configurations (6-8 months: visible for an average of 41.2 seconds; 9-11 months: 45.1 seconds) did not match any of the emotion stereotypes. The next most frequently visible facial configuration was the happy stereotype (6-8 months: 25.1 seconds; 9-11 months: 20.8 seconds). Each of the 17 other emotion stereotypes was visible for fewer than 5 seconds on average among both age groups. These results suggest that infants are more often exposed to variable rather than stereotypical emotional input. Accordingly, this work suggests that the facial configurations often used in studies of emotional development may not be not reflective of what infants typically see in real world social interactions.<br>
&nbsp;<br>
Title: <strong>Negative Emotion Has a Disruptive Role in the Formation of Relational Memory in Different Age Groups</strong><br>
Time: 16:53-17:01<br>
Authors: <strong>Önay, Neslihan (UNIGE); Ulrike Rimmele</strong><br>
Abstract: Episodic memory is a multi-component construct including place, people, and objects; these separate elements are integrated to form coherent memories of episodes of our lives. Age and emotion critically affect the integrating of different elements into a memory representation. Regarding age effects, a recent study showed associative memory to improve across development. On the other hand, emotion has been shown to reduce the memory for associations between the elements, decreasing the coherence with which a multi-element event is remembered. However, our knowledge about how emotion impacts associative memory and, thus, the coherence of memories in children compared to adults is very limited. In this study, we examine the effect of emotion on associative memory in children and adults. Children and adults learned events consisting of three elements (a face, a scene, an object). Half of the events contained a negative face expressing sadness. Memory was tested across all associations that had been presented in one event. We found that the presence of the negative face reduced memory for the associations between the event elements in all age groups. Our results replicate previous findings that show that associative memory for neutral stimuli develops with age and that emotion breaks memory coherence in adults. We extended the current knowledge by shedding light on the developmental aspect of emotional memory formation. These results bring a lot of new questions in the search for understanding the affective and developmental component of human memory and entail important information for clinical and educational settings.<br>
&nbsp;<br>
Title: <strong>Exploring Content of Children’s Discussions Related to a Shared Book Reading Intervention for Emotion Comprehension</strong><br>
Time: 17:01-17:09<br>
Authors: <strong>Bernard, Isabelle; Roy-Charland, Annie; Richard, Jacques F.; Mazerolle, Marie-Pier; Caissie, Julie; Perron, Mélanie</strong><br>
Abstract: One of the most important determinants associated with children’s mental well-being and school adaptation is emotion comprehension. According to Pons and Harris’s (2004) model, children develop nine emotional components from the ages of 3 to 12. In recent years, studies have shown that joint reading and dyadic reading of specialized books help stimulate emotional understanding (LaForge, 2017; Roy-Charland et al., 2021). Research has also suggested that adding an interactive component to reading leads to additional gains compared to reading alone (Grazzani &amp; Ornaghi, 2011; Grazzani et al., 2015; Ornaghi et al., 2014). With a qualitative approach, we examined discussions among four focus groups following a shared reading of two stories from an emotion-based book created by Roy et al.&nbsp;(2021). Our objective was to explore specific errors in emotional comprehension made by the children. Results show that children mostly have an understanding of the emotional component of desires but an incomplete understanding of the component of hiding, often interpreting these as mixed emotions. In comparison to third graders, some sixth graders could rectify these errors following the discussions. Additionally, we conducted a thematic analysis, revealing several key themes related to children’s emotional comprehension (e.g., disappointment, optimism, empathy, and frustration). These findings underscore the value of discussions in looking into and addressing specific errors in emotion comprehension. Furthermore, it highlights the importance of considering age-related differences in emotional development and the importance of integrating adapted interactive elements into interventions aimed at enhancing emotional comprehension and social skills in children.<br>
&nbsp;<br>
Title: <strong>Children’s Perception of Appraisal Dimensions in Emotional Contexts</strong><br>
Time: 17:09-17:17<br>
Authors: <strong>Özden, Zeynep B; Walle, Eric A</strong><br>
Abstract: Appraisals are central to many views of the emotion process (e.g., Lazarus, 1991). However, few studies manipulate appraisal dimensions as independent variables to test the development of emotion understanding. The current study investigated 5- (N= 13) 7- (N= 21), and 9-year-old (N=10) children’s understanding of agency and goal-congruency appraisal dimensions (data collection is in progress). Stories featured a goal-congruent or goal-incongruent outcome caused by either the self, another character, or fate to elicit 6 distinct emotions (joy, gratitude, relief, sadness, anger, and shame; see Roseman, 2001). Participants viewed a target story, which was followed by two stories: one with similarly manipulated appraisal dimensions and the other with appraisal dimensions not matching the target story. Participants matched the story that would elicit the same emotion with the target story. A validation study with adults (N = 178) confirmed the validity of the appraisal manipulations for categorizing the target emotions and revealed that adults were significantly more successful in correctly categorizing the illustrated stories than the stories as written vignettes (p = .04). Preliminary GLMM analysis of the child data revealed a developmental trend for matching accuracy improving with child age: 5-year-olds = 42%, 7-year-olds = 54%, and 9-year-olds = 62%. Additional comparisons across discrete emotions revealed further nuance to these developmental differences. Our initial findings suggest a developmental progression in children’s appreciation of appraisal dimensions in classifying discrete emotional experiences.<br>
&nbsp;<br>
Title: <strong>Neurophysiological Correlates of Emotional Words Processing in Primary School Children Impacted by Covid 19 Emergency</strong><br>
Time: 17:17-17:25<br>
Authors: <strong>Toro, Veronica Debora; Serio, Gianluigi; Marinelli, Chiara Valeria; Trotta, Eugenio; Decarolis, Diletta; Palladino, Paola; Quarto, Tiziana</strong><br>
Abstract: Previous literature suggests that emotions may substantially influence words processing, at both behavioral and neurophysiological levels. With regard to the latter, the N400 component, which is associated with the processes of lexical access and semantic and contextual integration that occur during reading, may be modulated by emotional valence. However, only few studies investigated neurophysiological correlates of this phenomenon in children and none of these studies focused on primary school children, thus investigating the early stages of reading’s ability acquisition and consolidation. Moreover, the literature lacks knowledge on the potential effect that an adverse event (such as covid-19 pandemic) may have on the neural processing of emotional words. Our study aims to investigate the effect of emotions on word processing and its related neurophysiological activity in primary school children and the potential impact of stress-related COVID-19 indexes. To achieve this, we used electroencephalography (EEG) with an event-related potential (ERP) approach, focusing on the N400 component. In our sample, in addition to neurophysiological and behavioral data during a word-processing task, information about stress conditions related to COVID-19 pandemic, individual emotional characteristics, and reading comprehension performances were acquired by self-administered questionnaires and standardized tests. Preliminary results show that in primary school children N400 component discriminates between words with different valence and arousal. Moreover, this modulation correlates with the degree of stress-COVID-19-related, individual emotional characteristics and reading comprehension performances. These findings underscore the effect that emotions, also in terms of experiencing a stressful event, such as the COVID-19 pandemic experience, as on word processing, especially if it occurs during a critical period for reading’s ability acquisition and consolidation.<br>
&nbsp;<br>
Title: <strong>Pacifiers at Play: Understanding Facial Emotional Exchange in Mother-Infant Dyads</strong><br>
Time: 17:25-17:33<br>
Authors: <strong>Šparemblek, Kristina; Polyzopoulou, Zoi; Hohulin, Elisabella; McGoldrick, Jodie; Cross, Jenny; Rychlowska, Magdalena; Vanderwert, Ross</strong><br>
Abstract: Facial mimicry, or the brief automatic mirroring of another person’s facial actions, is involved in the processing of facial expressions. Existing evidence suggests that altering mimicry with the use of pacifiers in infants not only influences their facial responses but also impacts caregivers’ responsiveness to their emotions and children’s long-term emotional development. Here we present novel evidence on pacifier use and its implications. A large questionnaire study examining pacifier use among 428 mothers of infants (0-36 months) showed that the use of pacifiers is associated with reduced parenting stress, better parent-child dynamics, and more positive perceptions of child’s affectivity. A second, experimental study, examined parental self-reports as well as video-recorded interactions of 62 mother-infant dyads (mothers aged 24-44 years; infants aged 8-11 months). Dyads engaged in two structured play tasks, where mothers demonstrated to infants stacking wooden rings or fitting objects into a cube. The tasks were performed in a randomized order with and without the pacifier in the infant’s mouth. We systematically coded and quantified facial expressions of the dyads during both tasks. Further analyses will examine expressive behavior of the dyads as a function of pacifier use and other characteristics, including infants’ temperament as well as mothers’ anxiety and depression. Together, the studies provide new insights into how pacifier use influences mother-infant interactions and provide methodological tools for human and automatic coding of such interactions.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-1-t2" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-1-t2">Flash Talks 1 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a5bd90a{}.cl-4a595180{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a5a51b6{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a5a5918{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a5a5922{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a5a5923{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a5a5924{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a5a5925{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a5a592c{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a5bd90a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a5a5918"><p class="cl-4a5a51b6"><span class="cl-4a595180">Track</span></p></td><td class="cl-4a5a5922"><p class="cl-4a5a51b6"><span class="cl-4a595180">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a5a5923"><p class="cl-4a5a51b6"><span class="cl-4a595180">Type</span></p></td><td class="cl-4a5a5924"><p class="cl-4a5a51b6"><span class="cl-4a595180">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a5a5923"><p class="cl-4a5a51b6"><span class="cl-4a595180">Title</span></p></td><td class="cl-4a5a5924"><p class="cl-4a5a51b6"><span class="cl-4a595180">Music, Aesthetics, and Creativity</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a5a5923"><p class="cl-4a5a51b6"><span class="cl-4a595180">Time</span></p></td><td class="cl-4a5a5924"><p class="cl-4a5a51b6"><span class="cl-4a595180">16:45 - 17:25</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a5a5925"><p class="cl-4a5a51b6"><span class="cl-4a595180">Room</span></p></td><td class="cl-4a5a592c"><p class="cl-4a5a51b6"><span class="cl-4a595180">Foyle: PFC/0G/007</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Mechanisms of Musical Emotion Transfer: Insights from Composers</strong><br>
Time: 16:45-16:53<br>
Authors: <strong>Varga, Peter J; Parkinson, Brian</strong><br>
Abstract: The process of evoking and transmitting emotions in music is both fundamental to cultural life and fundamentally understudied in our science. Much empirical literature has been dedicated to the affective experience of music listeners, but considerably less attention has been given to the role of composers and their intentions in the process of conveying emotion in music. The present research takes a mixed-methods approach to filling this gap by combining qualitative in-depth interviews with quantitative psychometric surveys that together probe composers’ engagement with emotion during their creative work. These studies investigated both composers’ practical considerations when deploying various musical elements and composers’ manipulation of those elements at a technical level to achieve the desired effects. The results show that whilst contemporary composers predominantly conceive of their work in terms consistent with a primarily Western classical idiom, they differ considerably in their use of distinct musical elements to evoke emotional responses in listeners as well as in the ways they approach listening to music qua composer versus qua listener and the practical ways in which they differentiate emotional reactions and cognitive perceptions. Composers’ felt and intended emotions were correlated in the creative process, but higher states (e.g., inspiration) and psychophysiological responses (e.g., the chills) were more closely associated with felt positive emotion whilst effort was more closely associated with negative intended emotion. By synthesizing these results with the musicological literature, this research attempts to provide a first empirical foray into better understanding the transmission of emotion and culture through music.<br>
&nbsp;<br>
Title: <strong>Measuring Aesthetic Emotions with the ShortAesthet</strong><br>
Time: 16:53-17:01<br>
Authors: <strong>Beermann, Ursula; Hosoya, Georg; Scherer, Klaus</strong><br>
Abstract: Aesthetic emotions are elicited by cultural activities like music, art, or other cultural activities. Cultural activities have positive effects on well-being, which may be mediated by the elicited emotions. Furthermore, personality dispositions affect the tendency to feel certain emotions. The Aesthetic Emotions Scale (AESTHEMOS, Schindler et al., 2017; Hosoya et al., 2017; Beermann et al., 2021) assesses aesthetic emotions across multiple aesthetic domains. However, for field research a shorter scale is necessary. To develop the Aesthetic Emotion Short Scale (ShortAesthet), 17 fuzzy sets were drawn from the AESTHEMOS item pool. In two online studies, participants answered questionnaires measuring personality, followed by 9 music excerpts (Study 1) or 9 paintings (Study 2). Each stimulus was followed by the ShortAesthet. The data were analyzed with an item response theory model for continuous responses (a simplified model of the one by Hosoya, 2019). Results demonstrated that the scale was able to depict the potential of the stimuli to evoke differential emotions. Canonical correlations indicated that participants’ dispositions (e.g., openness) predicted the tendency to respond with certain emotions (e.g., interest in the stimuli). More studies are currently undertaken to further shorten the scale and enhance the applicability in field research. This will help to further study beneficial effects of aesthetic emotions.<br>
&nbsp;<br>
Title: <strong>The Effect of Creativity on Cognitive Reappraisal Effectiveness in a Sample of Older Adults</strong><br>
Time: 17:01-17:09<br>
Authors: <strong>Telazzi, Ilaria; Balzarotti, Stefania; Crespi, Matilde; Colombo, Barbara</strong><br>
Abstract: Emotion regulation (ER) has been acknowledged as an important factor for older adults’ well-being. Recently, it has been suggested that creativity may play a role in the effectiveness of cognitive reappraisal, an adaptive form of ER. The present study aims to test whether creativity is linked to greater effectiveness in the use of cognitive reappraisal in a sample of older adults. 43 healthy older adults (age range 62-100) living in a nursing home were randomly assigned to either the experimental group (who completed a primer creativity task) or the control group (who completed a filler task). After this first step, all participants performed an ER task, involving the observation of thirty images (neutral or negative). Each image was preceded by an instruction to either watch or use positive reappraisal. After watching each image, the participants were asked to rate their affective experience (valence and arousal plus a list of emotional labels). Results showed that the experimental group reported less unpleasantness and less intense negative emotions when using positive reappraisal compared to the control group while observing negative images. However, no significant differences between groups were found concerning self-reported arousal. Overall, these findings support a significant effect of creativity on the use of cognitive reappraisal in older adults: Creativity seems to improve the effectiveness of this ER strategy in decreasing unpleasantness of negative stimuli. Providing new evidence about the links between creativity and ER, the results of this study hold significant implications to foster healthy aging.<br>
&nbsp;<br>
Title: <strong>Beyond Beauty: Does Visual Art Facilitate Social Cognitive Skills?</strong><br>
Time: 17:09-17:17<br>
Authors: <strong>Ozbay, Yagmur; Oosterwijk, Suzanne; Stamkou, Eftychia</strong><br>
Abstract: Engaging with art can move individuals through a myriad of emotions, provoke reflective thoughts, and lead to new ideas. Could art also influence interpersonal outcomes pertaining to the ways we interact with others and navigate the social world, that is, our suite of social cognitive skills? Here, we focus on visual art to explore the effect of art engagement on personal aesthetic experience and social cognitive skills. Across two studies, using veridical paintings and matched non-art photos, we examined the effect of art engagement on emotional (e.g., awe, being moved) and eudaimonic experiences (e.g., reflective thoughts), as well as social cognitive skills pertaining to Theory of Mind (ToM) and recognition of other’s emotions. Our findings showed that art engagement altered personal aesthetic experience through changes in emotional and eudaimonic outcomes. However, we did not find any support for the effect of art engagement on social cognitive skills.<br>
&nbsp;<br>
Title: <strong>Communicating Emotions Through Drawing: Cross-Cultural Similarities and Differences</strong><br>
Time: 17:17-17:25<br>
Authors: <strong>Fang, Xia; Sauter, Disa</strong><br>
Abstract: Understanding the impact of culture on emotion communication is crucial for studying human emotion processing. This research explores how culture shapes the expression and perception of emotions through drawings. Specifically, participants from China, a historically homogeneous culture, and Canada, a historically heterogeneous culture, were asked to express (Experiment 1) and recognize (Experiment 2) seven basic emotions, including a neutral expression, in drawings. The results revealed that the intended emotions in drawings by Canadian individuals were better recognized compared to those by Chinese individuals, supporting the Historical Heterogeneity Theory that suggests historically heterogeneous cultures express more distinct emotions. However, it is noteworthy that this difference was more pronounced among Canadian perceivers than their Chinese counterparts. To further explore the potential influence of the Emotion Dialect Theory, Experiment 3 included participants from India to identify emotions in Canadian and Chinese drawings. Indian participants also exhibited a greater ability to recognize the intended emotions in drawings by Canadian compared to Chinese individuals. However, this difference was more pronounced than that observed among Chinese perceivers and less significant than that among Canadian perceivers. These findings suggest that both historical heterogeneity and emotion dialects may play significant roles in the communication of emotions through drawings.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-1-t3" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-1-t3">Flash Talks 1 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a656326{}.cl-4a62e3d0{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a63e6fe{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a63ee9c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a63eea6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a63eea7{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a63eea8{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a63eea9{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a63eeb0{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a656326"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a63ee9c"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Track</span></p></td><td class="cl-4a63eea6"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a63eea7"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Type</span></p></td><td class="cl-4a63eea8"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a63eea7"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Title</span></p></td><td class="cl-4a63eea8"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Specific Emotions</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a63eea7"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Time</span></p></td><td class="cl-4a63eea8"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">16:45 - 17:25</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a63eea9"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Room</span></p></td><td class="cl-4a63eeb0"><p class="cl-4a63e6fe"><span class="cl-4a62e3d0">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Yawning Unveiled: The Elusive Interplay of Facial Mimicry and Contagious Yawning</strong><br>
Time: 16:45-16:53<br>
Authors: <strong>Diana, Fabiola; Norscia, Ivan; Kret, Mariska E.</strong><br>
Abstract: The relationship between facial mimicry and contagious yawning (CY) has been a subject of investigation, with researchers exploring whether there is a connection between the two phenomena. Facial mimicry refers to the unconscious imitation of facial expressions, often observed when individuals mimic the facial expressions of those around them. Contagious yawning, on the other hand, is the tendency for individuals to yawn in response to seeing or hearing others yawn. In this study, we will explore the link between facial mimicry and contagious yawning. We hypothesize that individuals exhibiting more facial mimicry will also be more susceptible to yawn contagion. 41 healthy participants performed several passive-viewing computer tasks while we measured facial EMG (Zygomaticus Major, Corrugator Supercilii), ECG, and EDA. In the computer tasks, participants had to passively observe videos of faces smiling or yawning. Moreover, participants filled out questionnaires assessing empathy, theory of mind, quality of sleep, and energy level. Contrary to our hypothesis, the analysis revealed no significant correlation between the proportion of facial mimicry and the proportion of contagious yawning shown by participants (p&gt;.155). Neither the questionnaires nor control variables affected the rate of contagious yawning. The lack of a link suggests that contagious yawning and facial mimicry may rely on different underlying mechanisms. We discuss the implication of these results by taking into account the limitation of the present study and suggest the incorporation of alternative forms of mimicry (e.g., pupil mimicry) in future investigations to shed light on the potential link between these two phenomena.<br>
&nbsp;<br>
Title: <strong>Frustration: A Language-Specific Concept?</strong><br>
Time: 16:53-17:01<br>
Authors: <strong>Soriano, Cristina; Ogarkova, Anna</strong><br>
Abstract: The English word “frustration” and its counterparts in Spanish (“frustración”), French (“frustration”) and German (“Frustration”) are quoted as translation equivalents in dictionaries and used as translation-equivalents in practice. However, they do not mean the same. We present linguistic and psycholinguistic evidence from 4 studies using observational (linguistic corpus) and elicited (self-report) data demonstrating that the English term is actually unique in meaning. In English, “frustration” is a typical anger word, very close in meaning to “anger” itself. By contrast, in the other languages the frustration terms are not close in meaning to the main anger words and can refer to other emotion families too. The reason is that in Spanish, French and German the meaning of “frustration” profiles goal-obstruction, and it is only in English that the term has further specialized to profile anger specifically. Possible reasons for this are proposed based on appraisal theory and cross-cultural psychology. The novelties and limitations of the findings are discussed, along with their implications for researchers in the affective sciences using the word “frustration” in their work.<br>
&nbsp;<br>
Title: <strong>What Happens when We Witness Other’s Excellence? Exploring the (Dis)Similarities of Moral Elevation and Admiration in Children</strong><br>
Time: 17:01-17:09<br>
Authors: <strong>Ali, Shazza; Abrams, Dominic; Allen, Melissa</strong><br>
Abstract: Studies with adults have shown that the good deeds of others (i.e., moral excellence) are positively evaluated, elicit feelings of moral elevation and motivate prosocial action, whereas extraordinary talent (i.e., non-moral excellence) can elicit admiration and motivate self-improvement. However, it is unclear whether children respond to others’ displays of (moral) excellence in the same way, and whether there are developmental differences. In Study 1 (N=213, 5-11 year-olds) and Study 2 (N=203, 9-11 year-olds), we explore children’s self-reported cognitive, affective, and motivational responses to videos of protagonists fundraising for outgroup members (moral excellence condition), excelling in sport (non-moral excellence condition) and attending a cooking class (control condition). In line with adults, 9-11-year-olds evaluated sporting ability as significantly more skilful than cooking and fundraising behaviours. They also evaluated the fundraising behaviour as significantly more benevolent and reported increased prosocial motivation compared to the other two conditions. In contrast, younger children (e.g., aged 5-7) showed no significant differences in how they evaluated the behaviour in the three conditions or in their subsequent motivations. There were no clear developmental trends for the affective experience associated with each condition (e.g., moral elevation and admiration), measured via self-reported emotions and physical sensations. Our findings suggest that by mid-late childhood, children may distinguish between different types of behaviour, which inspire different motivations, in a way that is similar to adults. Thus, exposure to, and acknowledgement of others’ prosocial behaviour, may be key components in increasing prosocial motivation during this developmental period.<br>
&nbsp;<br>
Title: <strong>Exploring Loneliness as a Multidimensional Experience: Social, Emotional, and Existential Dimensions Across the Adult Lifespan</strong><br>
Time: 17:09-17:17<br>
Authors: <strong>McKenna-Plumley, Phoebe; Turner, Rhiannon; Yang, Keming; Groarke, Jenny</strong><br>
Abstract: Experiences of loneliness are prevalent across the lifespan and confer harmful health and wellbeing outcomes. Accurately conceptualising loneliness is therefore important to allow effective research, assessment, and interventions to manage it. While loneliness is usually measured as a unidimensional emotion, it can also be conceptualised as multidimensional, including social, emotional, and existential dimensions. No previous research examines these three dimensions concurrently in a cross-lifespan sample and knowledge of their prevalence is lacking. This study tested the validity of this three-dimensional model and evaluated the levels of these dimensions in three age groups. Data were gathered from 714 adults in the UK and Ireland via an online survey using validated scales of social, emotional, and existential loneliness. One-way ANOVAs assessed age group differences in the levels of these loneliness dimensions across younger, middle, and older adulthood. Structural equation modelling tested the model fit of competing dimensional models of loneliness. Age group analysis revealed a linear decline in emotional and existential loneliness, with the highest levels in younger adulthood. Social loneliness showed a different pattern with significantly higher levels in midlife. The three-dimensional model including social, emotional, and existential loneliness was found to provide the best fit to the data. This research makes a significant contribution by validating a multidimensional model of loneliness and describing lifespan patterns of these dimensions in the same sample. The findings indicate that dimensions of loneliness are experienced to different degrees at different life stages. Implications for loneliness research will be discussed.<br>
&nbsp;<br>
Title: <strong>Is the Emotion Disgust Culturally Invariant?</strong><br>
Time: 17:17-17:25<br>
Authors: <strong>Kupfer, Tom R</strong><br>
Abstract: Although emotion terms vary across cultures and languages, for decades emotion scholars have debated the extent to which this variation is superficial or reflects fundamental differences in emotion experience. We examined this question with regard to the emotion disgust in over 60 countries. While the emotion term “disgust” and its referents varies across cultures, we found the oral-gastric rejection response towards pathogen cues involving subjective experiences such as nausea, to be invariant across cultures. Moreover, the response towards ectoparasite cues, a closely related threat, differed in line with functional expectations. We discuss the extent to which our findings support the claim that disgust is a universal, functional emotion, despite superficial differences in emotion terms across cultures.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-1-t4" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-1-t4">Flash Talks 1 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a6f5958{}.cl-4a6ca4a6{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a6dba4e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a6dc1d8{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a6dc1d9{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a6dc1e2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a6dc1e3{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a6dc1e4{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a6dc1ec{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a6f5958"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a6dc1d8"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Track</span></p></td><td class="cl-4a6dc1d9"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a6dc1e2"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Type</span></p></td><td class="cl-4a6dc1e3"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a6dc1e2"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Title</span></p></td><td class="cl-4a6dc1e3"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Emotion, Perception and Expression</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a6dc1e2"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Time</span></p></td><td class="cl-4a6dc1e3"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">16:45 - 17:25</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a6dc1e4"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Room</span></p></td><td class="cl-4a6dc1ec"><p class="cl-4a6dba4e"><span class="cl-4a6ca4a6">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Do the Six Archetypal Facial Expressions Exist in Spontaneous Social Interaction?</strong><br>
Time: 16:45-16:53<br>
Authors: <strong>Waller, Bridget M; Buckee, Andrew; Kavanagh, Eithne; Whitehouse, Jamie; Micheletta, Jérôme</strong><br>
Abstract: The six archetypal facial expressions of anger, disgust, fear, happiness, sadness, and surprise are often considered to be universal components of human behaviour and intrinsic to human social communication (Ekman, 1992). These facial expressions are widely assumed to serve fundamental social functions during day-to-day spontaneous social interactions. Empirical work has, however, focussed almost exclusively on how these expressions are understood, with only a small number of studies documenting the actual occurrence of these facial expressions within naturalistic settings. To quantify the evidence for spontaneous production of the six archetypal facial expressions during real-life social interaction, we conducted a thorough review of the literature on facial expression production between 1979 and 2023. We summarised 1) which of the six archetypal facial expressions was documented, 2) whether specific morphological features were recorded systematically (e.g.&nbsp;using the Facial Action Coding System: Ekman et al., 2002) to confirm similarity to the archetypes, and 3) whether quantitative data of occurrence (rates, frequency) was given. Except for happiness (smiling), this search yielded a very poor database with few studies providing sufficient quantitative evidence. In sum, we argue that there is an insufficient body of research to justify the prevailing view that these six facial expressions occur commonly during everyday social communication. The study of facial behaviours, including their social function, therefore, needs a radical rethink.<br>
&nbsp;<br>
Title: <strong>Navigating Truth: Unraveling the Impact of Emotional Expressions on News Credibility in the Era of Misinformation</strong><br>
Time: 16:53-17:01<br>
Authors: <strong>Klewes, Geraldine; Mauersberger, Heidi; Kastendieck, Till; Hareli, Shlomo; Hess, Ursula</strong><br>
Abstract: Emotions play a pivotal role in the manipulation of information, particularly in the realm of fake news where they serve as a strategic tool to captivate audiences. Taking into account the rise of fake news in recent years and the consequent shift in informational dynamics, our study explored how individuals perceive and react to news reports with content aligned or misaligned with displayed emotions. For this, 237 participants rated the credibility of news reports containing positive, negative, and neutral information about an (unknown) public figure. The news reports were presented either in a happy, sad, angry, or neutral tone of voice, accompanied by the corresponding facial expression. Participants also evaluated the appropriateness of the emotions shown during the news report and their perceived closeness to the news reporter. We found that the perceived truthfulness of a news report and the trustworthiness of the news reporter are influenced by both the emotions conveyed by the news reporter and the congruence between these emotions and the content of the report. First of all, adopting a neutral tone of voice alongside a neutral expression increased the perceived truthfulness across various types of news reports. Further, emotions congruent with the content, such as displaying happiness while reporting positive news, increased the perceived appropriateness of news reporters’ behaviors and the interpersonal closeness to news reporters, subsequently elevating the perceived trustworthiness of the news reporter and the truthfulness of a news report. Our findings shed light on the nuanced relationship between emotional expressions and credibility in the context of news reporting—an issue of growing significance in the era of misinformation.<br>
&nbsp;<br>
Title: <strong>Mimicking the Emotional Expressions of Others : Are all Expressive Features Made Equal?</strong><br>
Time: 17:01-17:09<br>
Authors: <strong>Verschoor, Stephan; Küster, Dennis; Schultz, Tanja; Hommel, Bernhard</strong><br>
Abstract: What determines whether and how much we mimic others? The Theory of Event Coding (TEC) proposes that the intensity of mimicry in dyadic interaction is a function of perceptual-feature overlap, with more overlap leading to more mimicry. TEC makes no provisions for the potential social signaling value of different types of facial expressions. In contrast, the Emotional Mimicry in Context (EMC) view suggests that the social signal value of the to-be mimicked target behavior, can modulate mimicry. We present four online Me-Other Overlap Tasks (MOOT, N = 256) featuring real-time interaction with avatars to manipulate behavioral similarity (synchronous, asynchronous). Additionally, we manipulated the attention of participants to their relationship with avatar. In the mimicry phase, the avatars produced three expressions: smile (affiliative), frown (counter-affiliative)and head-roll (neutral). In line with both TEC and EMC, we found significant mimicry for all three expressions. However, contrary to predictions derived from EMC, our current results revealed no significant differential mimicry effects between expressions. Thus, as predicted by TEC, mimicry was modulated only by perceptual-feature overlap , not by the social signaling value of facial expressions. We discuss possible interpretations of these results and how the MOOT could be further leveraged to produce contrasting tests of TEC and EMC accounts of facial mimicry.<br>
&nbsp;<br>
Title: <strong>Understanding the Process of Physiological Metonymy in Expressing Emotions</strong><br>
Time: 17:09-17:17<br>
Authors: <strong>Kim, Haejin; Lee, Donghoon</strong><br>
Abstract: We often use such physiological metonymy as saying ‘I am trembling’ to describe our emotions. However, the speaker’s intention may be ambiguous unless it is lexicalized to convey the referenced target (e.g., fear), as trembling can also be experienced in response to cold temperatures. In the current research, we aimed to compare the comprehension processing differences when the physiological metonymic expressions were used with non-literal meaning (emotion) versus literal meaning (physical). We conducted the experiment by dividing participants into two groups: physical meaning (literal), and emotional meaning (non-literal). In a maze task, sentences were presented word by word. For instance, in the physical group: ‘While suffering from a cold, my face flushed …’ and in the emotional group: ‘When I experienced racial discrimination, my face flushed …’ Participants were then provided with a two-word choice, such as in the physical group: feverish (target word) vs.&nbsp;shame (distractor) and in the emotional group: shame (target word) vs.&nbsp;feverish (distractor). Linear mixed-effects analysis of RTs revealed a significant interaction between group (emotion, physical) and distractor (distractor, control) (b=-71.00, SE=10.91, t=-6.51, p &lt;.001). When the physiological metonymic expressions were used in their emotional sense, there was a significant interference effect, with response times being slower for distractor words compared to control words. However, there was no significant difference in the physical sense. Current results suggest that when expressing emotions non-literally, the non-literal senses emerge through the comprehension of literal meaning, whereas literal meaning can be directly understood.<br>
&nbsp;<br>
Title: <strong>A Systematic Evaluation Framework on Emotion Perception for Large Language Models Using Appraisal Theory</strong><br>
Time: 17:17-17:25<br>
Authors: <strong>Yongsatianchot, Nutchanon; Thejll-Madsen, Tobias; Marsella, Stacy C</strong><br>
Abstract: Large language models (LLMs) demonstrate competencies in many areas, including science, medicine, laws, story generation, and basic emotion perceptions. Crucially, we begin to see more LLM’s applications involving emotion content, such as role-playing characters or actors and LLMs as therapists. In such applications, LLM’s responses could have significant impacts on the user’s well-being and social life. Therefore, it is important to understand how existing LLMs perceive and respond to emotion content in comparison to humans. Researchers have begun to investigate LLMs on various emotion capabilities, but a structured evaluation framework guided by an emotion theory is still lacking. Without a theory, it is unclear what the evaluation tries to probe. Further, a theory provides a way to identify critical aspects of the space of possible stimuli. Toward that end, in this work, we propose a systematic evaluation based on the appraisal theory of emotion and coping. Our evaluation framework consists of two steps. The first step is emotional scenario generation, whereby we create a diverse set of scenarios by systematically manipulating key appraisal dimensions. We then ask human participants to rate emotions in these scenarios. The second step is the reverse appraisal test, in which we turn these scenarios into multiple tests by removing key appraisal dimensions, such as goals and beliefs, to be filled in by LLMs using the remaining dimensions and emotions. This evaluation offers a deeper understanding of the emotion perception capability of LLMs by examining how they predict emotion and their sensitivity toward key appraisal dimensions.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-1-t5" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-1-t5">Flash Talks 1 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a79bd80{}.cl-4a7721d8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a78300a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a7837bc{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a7837c6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a7837c7{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a7837c8{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a7837d0{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a7837d1{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a79bd80"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a7837bc"><p class="cl-4a78300a"><span class="cl-4a7721d8">Track</span></p></td><td class="cl-4a7837c6"><p class="cl-4a78300a"><span class="cl-4a7721d8">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a7837c7"><p class="cl-4a78300a"><span class="cl-4a7721d8">Type</span></p></td><td class="cl-4a7837c8"><p class="cl-4a78300a"><span class="cl-4a7721d8">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a7837c7"><p class="cl-4a78300a"><span class="cl-4a7721d8">Title</span></p></td><td class="cl-4a7837c8"><p class="cl-4a78300a"><span class="cl-4a7721d8">Emotions In Context</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a7837c7"><p class="cl-4a78300a"><span class="cl-4a7721d8">Time</span></p></td><td class="cl-4a7837c8"><p class="cl-4a78300a"><span class="cl-4a7721d8">16:45 - 17:33</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a7837d0"><p class="cl-4a78300a"><span class="cl-4a7721d8">Room</span></p></td><td class="cl-4a7837d1"><p class="cl-4a78300a"><span class="cl-4a7721d8">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Limited Impact of Synergistic Mindsets Intervention on Esports Performance: Preliminary Findings</strong><br>
Time: 16:45-16:53<br>
Authors: <strong>Behnke, Maciej; Lakens, Daniël; Petrova, Kate; Chwiłkowska, Patrycja; Jęśko Białek, Szymon; Kłoskowski, Maciej; Krzyżaniak, Wadim; Maciejewski, Patryk; Szymański, Kacper; Jamieson, Jeremy; Gross, James</strong><br>
Abstract: Affective responses during high-stakes situations play an important role in shaping performance outcomes. Feeling shaky at a job interview can undermine performance, whereas feeling excited during a sporting competition can optimize performance. Thus, affect regulation – the way people influence their affective responses – might also play a key role. To test this hypothesis, we adapted synergistic mindsets intervention (SMI; Yeager et al., 2022) to high-stakes situations. It was motivated by the idea that (1) mindsets both about situations and one’s response to situations can be shaped to maximize challenge vs.&nbsp;threat responding, and (2) challenge vs.&nbsp;threat affective responses are linked to enhanced performance. We focused on esports, a context that permits the measurement of affective responses and well-defined outcomes. We randomly assigned gamers (N = 300) to the SMI or a control condition (learning about the brain). After two weeks of daily gaming, players competed in a cash-prize tournament. Despite changes in beliefs about the usefulness of negative emotions (d = .48, 95% CI [.25, .71]), and stress responses (d = .39, 95% CI [.16, .62]) and increased usage of reappraisal (d = .47, 95% CI [.24, .70]), compared to the control condition, synergistic mindset gamers did not show greater challenge affective responses nor superior performance outcomes (ds &lt; .15). This questions the previous assumptions about the relationship between affective changes and performance outcomes and suggests that synergistic mindset intervention’s effectiveness might vary across contexts.<br>
&nbsp;<br>
Title: <strong>Emotional Witness Effect and Misinformation: Implications for Misidentification, Reliability, and Memory Accuracy in Forensic Contexts</strong><br>
Time: 16:53-17:01<br>
Authors: <strong>Zloteanu, Mircea</strong><br>
Abstract: The emotional state of a witness can impact how they are perceived within a forensic setting. If the emotions a witness portrays seem incongruent with their statement, they are perceived as deceptive, untrustworthy, or inaccurate. This study considers the dynamics of this effect on subsequent (mis)identification, perceptions of reliability and honesty, and observer memory accuracy of the event, with a focus on susceptibility to misinformation. Here, the role of misinformation within the recall stage will be measured, offering a novel insight into cross-over effects with gender and emotional states. It is predicted that the emotional tone of a witness’s video statement (congruent versus incongruent) influences how observers perceive the statement and subsequently recall its details, as well as the influence of misinformation (low, medium, high). The interaction of emotional expression and the gender of the witness is also considered. The analysis will emphasise congruency and expectation effects concerning emotions and gender, exploring the potential beneficial aspect of emotions enhancing accurate witness recall and identification, contrasted with the detrimental effects where emotional cues may divert attention from factual statements and susceptibility to misinformation. By investigating these cross-over effects, the findings aim to contribute to our understanding of how emotions impact judgments in forensic settings.<br>
&nbsp;<br>
Title: <strong>Racial Differences in Emotion Socialization and Racial Socialization: The Need for an Integrated Lens</strong><br>
Time: 17:01-17:09<br>
Authors: <strong>Montague, Diana P. F.; Logan, Faith; Lozada, Fantasy T</strong><br>
Abstract: We addressed the role of racial socialization goals in explaining differences in Black American and White American parents’ responses to their children’s emotions. Black (n = 67) and White (n = 90) parents of young adolescents (9 to 14 years) completed measures of their racial and emotion socialization goals and responses to their adolescent’s negative emotions. We found that Black parents rated preparation for bias and protective emotion socialization goals as more important than did White parents and reported greater likelihood of non-supportive responses than White parents. Preparation for bias goals significantly predicted two of three non-supportive responses and mediated the relation between parent race and non-supportive responses. We argue for viewing emotion socialization and racial socialization through an integrated lens, which would support the advancement of research and clinical practice guidelines that are more culturally sensitive to Black families.<br>
&nbsp;<br>
Title: <strong>The Impact of Shame, Humiliation, and Criminal Justice Experiences on Revenge in Crime Victims</strong><br>
Time: 17:09-17:17<br>
Authors: <strong>McGaughey, Katie; McGlinchey, Emily; Hanna, Donncha; Armour, Cherie</strong><br>
Abstract: Background: Criminal victimisation has been linked to an increased risk of violent offending, often motivated by revenge (Jackson et al., 2019). Experiencing revenge desire could also be harmful for crime victims’ mental health (Barcaccia et al., 2020). To limit revenge’s harmful effects, researchers have examined the predictors of revenge. However, little is known about the predictors of revenge in crime victims specifically. Additionally, anger’s impact on revenge has been extensively researched. Yet the role of the negative self-conscious emotions, including shame and humiliation, is understudied. Objectives: To identify whether experiencing feelings of shame and humiliation increases revenge desire and behaviour in crime victims. The impact of criminal justice system experiences, mental health factors, and emotional regulation on revenge desire and behaviour in crime victims is also examined. Method: 150 participants completed a comprehensive questionnaire, measuring criminal justice satisfaction and its impact on coping, revenge desire, shame-proneness, depression, anxiety, and emotional regulation. Participants then completed an investing game, in which they were betrayed by their partner. Participants were randomly assigned to one of three groups: shame and humiliation induction, pride induction, and a control group. After emotions were induced, participants were given the chance to take revenge against their partner via noise blasts. Results: Descriptive and inferential results (available in March 2024) will be discussed and interpreted. Conclusions: Identifying victims who are experiencing revenge desire, or at risk of taking revenge, is vital due to revenge’s potentially harmful effects. This knowledge could inform clinicians, victim support agencies, and violence prevention strategies.<br>
&nbsp;<br>
Title: <strong>Activist Interpreting in Abortion Clinics: Emotional Challenges and Self-Care Strategies</strong><br>
Time: 17:17-17:25<br>
Authors: <strong>Bartlomiejczyk, Magdalena; Poellabauer, Sonja; Straczek-Helios, Viktoria</strong><br>
Abstract: Emotionality in interpreting has been addressed within “the psycho-affective turn in Interpreting Studies” (Korpal 2016). The fact that interpreters react emotionally to the content they interpret reflects human tendency to empathy (Merlini 2015), and this has repeatedly been confirmed by self-reports obtained from community interpreters working for refugees (Mahyub-Rayaa and Baya-Essayahi 2021; González Campanella 2023), unaccompanied child migrants (Sultanić 2021), or survivors of domestic violence (Toledano Buendía and del Pozo Triviño 2015). Based on a review of studies on emotionality and interpreting, including coping and self-care strategies among interpreters, we present a case study of a group of activist interpreters Ciocia Wienia, a Vienna-based informal pro-choice collective. The activists provide information and facilitate abortion travel from Poland to Austria. They offer on-site support to their clients, including interpreting in abortion clinics. We present original data from a corpus of 13 qualitative in-depth interviews with members and associates of Ciocia Wienia. Based on a qualitative content analysis, this contribution investigates which situations and stressors are described as emotionally challenging and which coping strategies and techniques of self-care and mental hygiene are employed to process burdensome emotions. Our results suggest that negative feelings such as sadness, frustration and anger, stress, uncertainty, and the strain of having to finetune empathetic communication make work in such a context emotionally taxing, even though positive emotions are reported as well. Apart from sharing with the group and supervision, only a few activists seem to have developed a set of distinct individual self-care and coping strategies. References: González Campanella, Alejandra. 2023. “‘Trauma informs so much of what happens’: Interpreting Refugee-Background Clients in Aotearoa New Zealand.” Perspectives 31 (3): 413–430. Korpal, Paweł. 2016. “Interpreting as a Stressful Activity: Physiological Measures of Stress in Simultaneous Interpreting.” Poznań Studies in Contemporary Linguistics 52 (2): 297–316. Merlini, Raffaela. 2015. “Empathy: A ‘Zone of Uncertainty’ in Mediated Healthcare Practice.” Cultus 8: 27–49. Mahyub-Rayaa, Bachir, and Moulay-Lahssan Baya-Essayahi. 2021. “Linguistic–cultural Mediation in Asylum and Refugee Settings and its Emotional Impact on Arabic-Spanish Interpreters.” European Journal of Investigation in Health, Psychology and Education 11 (4): 1280–1291. Sultanić, Indira. 2021. “Interpreting Traumatic Narratives of Unaccompanied Child Migrants in the United States: Effects, Challenges and Strategies.” Linguistica Antverpiensia, New Series: Themes in Translation Studies 20: 227–247. Toledano Buendía, Carmen, and Maribel del Pozo Triviño. eds.&nbsp;2015. La interpretación en contextos de violencia de género. Valencia: Tirant lo Blanch.<br>
&nbsp;<br>
Title: <strong>Preliminary Evidence for Physiological Markers of Core Affective Experience: Results from a Team-Science Competition</strong><br>
Time: 17:17-17:25<br>
Authors: <strong>Perz, Bartosz; Behnke, Maciej; Saganowski, Stanisław; Coles, Nicholas</strong><br>
Abstract: Emotions are fundamental to the human condition, but is there physical - or more specifically, physiological - evidence that emotions exist? One reason this debate has persisted for over a century is that links between physiological elements and subjective emotional experiences may be multi-dimensional, non-linear, and highly interactive, posing challenges for formal computational models. Thus, machine learning may usefully advance these debates. As part of the Emotion Physiology and Experience Collaboration, we organized a competition wherein 12 teams (50 researchers) with machine learning experience/background aimed to predict continuous self-ratings of core affect (valence and arousal) from multi-modal measures of peripheral nervous system activity (e.g., cardiography and respiration). By comparing instances where top-performing models made predictions on test data with (a) real physiology data vs.&nbsp;(b) simulated random physiology, we uncovered evidence that models did indeed leverage physiology to make predictions about emotion reports. These results provide preliminary evidence that emotion does indeed manifest in physiology. Furthermore, even though relationships between emotional experiences and physiology may be too complex to interpret, these results provide preliminary evidence that such relationships can nonetheless be captured using machine learning methods. These preliminary results are based on a small dataset and will be further investigated on larger datasets.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-2-t1" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-2-t1">Flash Talks 2 : T1</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a83ba6a{}.cl-4a812782{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a822d62{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a8234f6{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a823500{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a823501{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a823502{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a823503{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a82350a{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a83ba6a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a8234f6"><p class="cl-4a822d62"><span class="cl-4a812782">Track</span></p></td><td class="cl-4a823500"><p class="cl-4a822d62"><span class="cl-4a812782">T1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a823501"><p class="cl-4a822d62"><span class="cl-4a812782">Type</span></p></td><td class="cl-4a823502"><p class="cl-4a822d62"><span class="cl-4a812782">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a823501"><p class="cl-4a822d62"><span class="cl-4a812782">Title</span></p></td><td class="cl-4a823502"><p class="cl-4a822d62"><span class="cl-4a812782">Empathy and Perspective-taking</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a823501"><p class="cl-4a822d62"><span class="cl-4a812782">Time</span></p></td><td class="cl-4a823502"><p class="cl-4a822d62"><span class="cl-4a812782">16:30 - 17:10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a823503"><p class="cl-4a822d62"><span class="cl-4a812782">Room</span></p></td><td class="cl-4a82350a"><p class="cl-4a822d62"><span class="cl-4a812782">Bann: PFC/0G/024</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>The Impact of Empathic and Counter-Empathic Emotions on Social Evaluations</strong><br>
Time: 16:30-16:38<br>
Authors: <strong>Feng, Roujia; van Dijk, Eric; van Dijk, Wilco</strong><br>
Abstract: The way in which individuals emotionally respond to the fortunes or misfortunes of others can influence how they are perceived by third parties. In 12 studies (N = 1,694), we examined the impact of expressing empathic (happy-for-ness &amp; sympathy) and counter-empathic emotions (schadenfreude &amp; glückschmerz) on the evaluations of the expressers of these emotions. First, we explored in Studies 1.1 and 1.2 the perceived appropriateness of empathic and counter-empathic emotions following the fortunes or misfortunes of others. Next, we examined in Studies 2.1 and 2.2 the impact of expressing empathic and counter-empathic on the evaluations of expressers of these emotions in terms of warmth, competence, and morality. Last, we examined the perceived prosociality of (Studies 3.1-3.5) and willingness to interact (Studies 4.1-4.3) with expressers of empathic and counter-empathic emotions. Findings from the four series of studies consistently revealed that, compared to empathic emotions and expressers showing these emotions, counter-empathic emotions and expressers showing them were evaluated more negatively. Moreover, results of the first two series of studies showed that these differences in evaluation were more pronounced for major events than for minor events. In the first two series of studies, we also found that expressions of happy-for-ness led to more positive evaluation than sympathy. Whereas expressions of schadenfreude led to more negative evaluation than glückschmerz. These findings, however, were not found in the subsequent two series of studies.<br>
&nbsp;<br>
Title: <strong>Effects of Emotion Recall Instructions and Valence on Self- And Other-Perceived Emotion Intensity and Empathy</strong><br>
Time: 16:38-16:46<br>
Authors: <strong>Braun, Nadine; Schouten, Iris</strong><br>
Abstract: Competing theories, e.g., emotions as basic categories, appraisals, or dimensions, may affect practical applications such as autobiographical recall for scientific research or psychotherapeutic purposes by leading to variations in emotion recall instructions (ERI). This could affect the recall, particularly recalled emotion intensity (EI) and others’ perceptions of the recalled experience. Therefore, we investigate the effects of ERI (discrete emotion / appraisals) and valence (positive: happiness / negative: anger) on self-perceived (s-EI) and other-perceived (o-EI) emotion intensity in a preregistered two-part study. We first conducted a 2x2 between-participants online experiment (N=153). Trait cognitive reappraisal (TCR) was considered a potential moderator between valence and s-EI. Contrary to our expectation that appraisals foster more intense recall, we found no significant effect of ERI on s-EI. Expectedly, positive (M=5.99, SD=1.14) compared to negative recall (M=5.20, SD=1.10) led to higher s-EI, F(1,149)=18.41, p&lt;.001, ηp2=.11. TCR did not moderate this relationship. There was no interaction effect. Part 2 explores the recall-text corpus produced in Part 1, comparing s-EI and o-EI. Although ERI did not affect s-EI, appraisal-based ERI might result in (partial) replications of the respective appraisal structures in the produced texts, possibly influencing others’ perceptions of writers’ experiences. In a within-participants experiment, we thus ask different participants to annotate the texts on the same measures as the writers. Moreover, we analyze writer-directed empathy, TCR, and trait empathy. Since data collection for Part 2 is still ongoing at the time of abstract submission, the complete results of the study will be presented at ISRE2024.<br>
&nbsp;<br>
Title: <strong>Mixed Methods Comparison of Relationships with Love vs Those with Ambivalence</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Aumer, Katherine V; Blake, Robert; Gray, Kristin; Ford, Keʻala</strong><br>
Abstract: This study explored the quantitative and qualitative differences between relationships with only love versus those with both love and hate (i.e., ambivalence). A sample of 654 participants from a local university answered questions regarding the quality of their relationships and the personalities of a person they only love and a person they both love and hate. We hypothesized that ambivalent targets would be seen as having less of the desirable big five personality traits and ambivalent relationships would be less intimate and satisfying than relationships with only love. Participants were asked to describe why they love both persons and themes were extracted. Controlling for the relationship category, participants rated the person they felt ambivalent about lower on all big five personality traits. Additionally, participants reported more intimate and frequent contact with participants they only love versus those they felt ambivalent about. Finally, thematic analysis revealed that participants described their love in ambivalent relationships with more negative emotion words and references to discovery. No differences were found regarding the degree of care for the target. Ambivalence is associated with lower quality in a relationship, however thematic analyses show that these relationships are still important. Interpersonal relationships research should consider the likelihood of complex emotions, especially ambivalence, across a variety of relationship categories. Our study suggests that many relationships may experience ambivalence and it may be an important part of relationship or personal development.<br>
&nbsp;<br>
Title: <strong>Unveiling the Dynamics of “Seeing Afresh”: Enacted Perspective-Taking Through Role-Play Dialogues with Climate Emotions</strong><br>
Time: 16:54-17:02<br>
Authors: <strong>Gao, Jie</strong><br>
Abstract: Background and objectives: What should be taught to support young people’s emotional capability development in the Anthropocene and digital age? Against the backdrop of medicalizing climate emotions which can be understood as both appropriate response to structural injustice and valuable for moral functioning, our design-based research project echoes an increasing educational emphasis on pedagogical approaches that promote holistic development, and aims to create a space where reflective explorations of a plurality of values and perspectives are supported. To this end, and informed by Dewey’s pragmatism, Varela’s enactivism, and Freire’s critical pedagogy, we repurposed an educational game initially designed for teaching critical thinking with philosophy for children (P4C), to incorporate role-play and open-ended questions that reflect the needs and queries of today’s Youth living in the global north. The game experience encourages players to alternate between roles of active listeners and speakers, engaging in reflective dialogues, observation, and collective debriefings. Method: Fourteen young adults from an university volunteered to play the game, and participated in one-on-one post-game interviews for unveilling the experiential processes. Both the gameplay and the interview were filmed for observation and transcribed for analysis. Combining systematic coding strategy from both qualitative (reflexive thematic analysis) and (micro)phenomenological methods, we conducted analyses of the transcripts for emergent patterns and structures. Result: The analysis of observational data show that our participants are able to (1) adopt the perspectives of their characters, (2) interact with another player/character’s perspective, (3) leap beyond their immediate situations and proactively seek out specific perspectives beyond those encountered in the gameplay, and (4) engage in reflections on their character portrayals across the different stages of dialogic interactions. These processes capture the temporal extendedness of perspective-taking and possibilities of nurturing moral imagination through affectively scaffolded dialogic interactions. Furthermore, preliminary analysis of interview data revealed individual differences in their journeys and pathways towards sustainability, suggesting both potentials and limits of eliciting self-transcendent emotions for sustainability education.<br>
&nbsp;<br>
Title: <strong>Mapping Empathy’s Oeuvre: Toward a Typology of Empathy in Media Selection, Processing, and Reception</strong><br>
Time: 17:02-17:10<br>
Authors: <strong>Kalny, Callie S.; Sukalla, Freya; Walter, Nathan; Balint, Katalin</strong><br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-2-t2" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-2-t2">Flash Talks 2 : T2</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a8daa20{}.cl-4a8b1486{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a8c1a34{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a8c21c8{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a8c21d2{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a8c21d3{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a8c21d4{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a8c21d5{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a8c21d6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a8daa20"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a8c21c8"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Track</span></p></td><td class="cl-4a8c21d2"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">T2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a8c21d3"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Type</span></p></td><td class="cl-4a8c21d4"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a8c21d3"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Title</span></p></td><td class="cl-4a8c21d4"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Emotion Understanding, Complexity and Theory</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a8c21d3"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Time</span></p></td><td class="cl-4a8c21d4"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">16:30 - 17:02</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a8c21d5"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Room</span></p></td><td class="cl-4a8c21d6"><p class="cl-4a8c1a34"><span class="cl-4a8b1486">Foyle: PFC/0G/007</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Labeling Behaviors is Associated with Identification of Emotion Event</strong><br>
Time: 16:30-16:38<br>
Authors: <strong>Li, Zhimeng</strong><br>
Abstract: Emotion labels index categorical knowledge of emotions, the activation of which can guide emotion inferences. Previous work suggested that the level to which one identifies emotional events in agreement with others is associated with a broader and more sophisticated emotion vocabulary. However, the impact of labeling behavior on the emotion perception process remains unknown. Here, we examined this using the Emotion Segmentation Paradigm, where people identify emotion events from documentary clips. We randomly assigned participants to the labeling (N=163, 89 men, 71 women, 3 nonbinary) or no-labeling condition (N=193, 85 men, 102 women, 6 nonbinary). In the no-labeling condition, participants were instructed to click whenever they observed emotions. In the labeling condition, participants were instructed to click only when they had a label for the emotion in mind, and then to provide the label. To quantify emotion perception, we located within each condition timepoints where the group collectively agreed that emotions occurred (i.e., consensus events). We then used Signal Detection Theory measurements to compute the sensitivity at discriminating emotion from non-emotion (sensitivity) and the threshold for identifying an event (criterion). We found that compared to the no-labeling group, the labeling group was less sensitive at discriminating consensus events from non-events (t(349)=5.23, p &lt; .001) and was more conservative at identifying events (t(341)=-4.15, p &lt; .001). Future research will focus on exploring factors driving these differences.<br>
&nbsp;<br>
Title: <strong>Accurate Perception of both Quality and Quantity of Blended Emotions Conveyed Through Dynamic Multimodal Expressions</strong><br>
Time: 16:38-16:46<br>
Authors: <strong>Israelsson , Alexandra Ai; Laukka, Petri</strong><br>
Abstract: Although people frequently report that they experience more than one emotion at the same time, few studies have investigated how blended emotions are communicated nonverbally. In a previous study, we showed that participants could accurately judge which emotions were expressed in blended emotion-pairs, conveyed through dynamic multimodal (facial/bodily/vocal) expressions. The current study in addition asked if participants can accurately judge how prominently different emotions are expressed in blended emotion-pairs. Actors were instructed to express all pairwise blends of anger, disgust, fear, happiness, and sadness – using facial gestures, body movement, and vocal sounds. Each blended emotion was portrayed with three different proportions: 30:70 (e.g., 30% happiness and 70% sadness), 50:50 (e.g., 50% happiness and 50% sadness) and 70:30 (e.g., 70% happiness and 30% sadness). Participants rated each recording on two scales (out of 5 available scales: anger, disgust, fear, happiness, and sadness). Results showed that all emotion blends were accurately perceived with significantly higher ratings on scales corresponding to intended vs.&nbsp;non-intended emotions, for all emotion proportions (30:70, 50:50, 70:30). Participants were also able to correctly judge which was the dominant and the less dominant emotion in the 30:70 and 70:30 stimuli. These findings show that it is possible to recognize both the quality (i.e., which emotions are present) and the quantity (i.e., how much of each emotion is present) from blended emotion-pairs. This suggest that emotion perception is more nuanced and flexible than previously thought, which may help us to understand and adaptively respond to a complex environment.<br>
&nbsp;<br>
Title: <strong>Anticipation of Positive and Negative Counterfactual Emotions Shape Behaviour</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Feeney, Aidan; Lorimer, Sara; Hoerl, Christoph; McCormack, Teresa; Beck, Sarah; Johnston, Matthew</strong><br>
Abstract: Anticipation of emotion can shape decisions about future behaviour. The paradigmatic example, anticipated regret, has been implicated in health-related decision-making but it is not known whether it is the valence of regret or its counterfactual nature which is important. Recent work on influenza vaccination suggests that anticipated relief, too, may influence decisions to engage in positive health behaviours. To explore these affective components further and address the generality of possible mechanisms underlying these associations, we examined whether anticipated relief and anticipated regret independently predict testicular self-examination (TSE) intention and behaviour. We distinguished between counterfactual relief (relief that a worse outcome did not obtain) and temporal relief (relief that an unpleasant experience is over). 567 cis-gendered males completed measures of anticipated regret, anticipated counterfactual and temporal relief, attitudes, norms, perceived behavioural control, intention, and measures of anxiety and shame. One month later the same participants were re contacted and asked about their engagement in testicular self-examination in the previous month. Anticipated counterfactual relief and anticipated regret are independent, positive, predictors of intention to engage in testicular self-examination and, indirectly, testicular self-examination behaviour itself. Although anticipated temporal relief was negatively associated with intention to engage in TSE, it was not associated with TSE behaviour when other predictors were controlled for. Our results suggest that it may be the counterfactual nature of anticipated regret and relief that underlie their association with TSE and other health-promoting intentions and behaviours. Both positively and negatively valenced counterfactual emotions may be useful in helping to promote healthful behaviour.<br>
&nbsp;<br>
Title: <strong>Practical Irrationality Mystified: A Reply to Agnes Moors</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Kılıç, Ongun</strong><br>
Abstract: Agnes Moors, in her book “Demystifying Emotions” provides a goal-directed account of practical irrationality in emotional episodes (Moors 2022). Moors claims that the goal-directed processes governing emotional episodes do not differ in kind from goal-directed processes governing mundane forms of goal-pursuit. It follows that emotion plays no distinctive explanatory role in making sense of the practical irrationality in emotional episodes. Moors’ argument is two pronged: (i) some instances of practical irrationality are merely apparent, (ii) instances of real practical irrationality are explained by an error made by the agent within the goal-directed cycle itself. This amounts to reducing all forms of practical irrationality to forms of theoretical irrationality. I will argue, contra (ii), that the agent often represents an action option as having the highest expected utility for attaining a goal, but nevertheless does not implement such representation into the goal-directed cycle, thereby acting in ways that, by their own lights, do not have the highest expected utility. In these cases, the error is not contained within the goal-directed cycle itself, but consists of the failure to choose what the agent deems to have the highest expected utility. This should make us doubtful of Moors’ claim that emotions are not required for making sense of the practical irrationality of emotional episodes. It might turn out that we indeed need the concept of emotion in explaining cases of practical irrationality that do not hinge on the theoretical irrationality of the goal-directed process itself. If so, emotional behaviors differ in kind from garden-variety goal-directed behaviors.<br>
&nbsp;<br>
Title: <strong>The Human Affectome</strong><br>
Time: 16:54-17:02<br>
Authors: <strong>Yu, Alessandra N. C.; Schiller, Daniela; Lowe, Leroy</strong><br>
Abstract: Theoretical perspectives in the interdisciplinary field of the affective sciences have proliferated rather than converged due to differing assumptions about what human affective phenomena are and how they work. These metaphysical and mechanistic assumptions—shaped by academic context and values—have dictated the field’s affective constructs and operationalizations. However, an assumption about the purpose of affective phenomena can guide us to a common set of metaphysical and mechanistic assumptions. In this capstone paper, we home in on a nested teleological principle for human affective phenomena in order to synthesize metaphysical and mechanistic assumptions. Under this framework, human affective phenomena can collectively be considered algorithms that either adjust based on the comfort zone (affective concerns) or monitor those adaptive processes (affective features). Those for affective concerns indicate the adaptive relevance of the environment. These can be organized hierarchically according to distance from metabolic impact (immediate to distal), including physiological and operational concerns, and can also act as global summaries of concerns across time, such as trajectory and optimization. Those for affective features monitor how the adaptive process is going on a momentary basis, include valence (how well or not) and arousal (the extent to which various systems are mobilized), and can inform global concerns. This teleologically-grounded framework offers a principled agenda and launchpad for organizing existing perspectives as well as generating new ones. Ultimately, we hope the Human Affectome brings us a step closer to not only an integrated understanding of human affective phenomena—but an integrated field for affective research.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-2-t3" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-2-t3">Flash Talks 2 : T3</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4a97a052{}.cl-4a9510bc{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a961610{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a961d90{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a961d9a{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a961d9b{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a961d9c{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a961d9d{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a961da4{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4a97a052"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a961d90"><p class="cl-4a961610"><span class="cl-4a9510bc">Track</span></p></td><td class="cl-4a961d9a"><p class="cl-4a961610"><span class="cl-4a9510bc">T3</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a961d9b"><p class="cl-4a961610"><span class="cl-4a9510bc">Type</span></p></td><td class="cl-4a961d9c"><p class="cl-4a961610"><span class="cl-4a9510bc">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a961d9b"><p class="cl-4a961610"><span class="cl-4a9510bc">Title</span></p></td><td class="cl-4a961d9c"><p class="cl-4a961610"><span class="cl-4a9510bc">Meta Emotions, Thoughts and Language</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a961d9b"><p class="cl-4a961610"><span class="cl-4a9510bc">Time</span></p></td><td class="cl-4a961d9c"><p class="cl-4a961610"><span class="cl-4a9510bc">16:30 - 16:54</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a961d9d"><p class="cl-4a961610"><span class="cl-4a9510bc">Room</span></p></td><td class="cl-4a961da4"><p class="cl-4a961610"><span class="cl-4a9510bc">Lagan: PFC/02/026</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Feelings About Feelings: Accounting for Meta-Emotions in Persuasion</strong><br>
Time: 16:30-16:38<br>
Authors: <strong>Dobmeier, Christopher M; Kalny, Callie S.; Walter, Nathan; Nabi, Robin</strong><br>
Abstract: Meta-emotions refer to the emotional reactions that arise in response to an individual’s primary emotions. In simple terms, meta-emotions are emotions about emotions. From experiencing guilt about being happy or feeling embarrassed about being sad, to feeling happy about being hopeful or being angry at yourself for being angry, meta-emotions are a critical, albeit underexamined, component of the emotional experience that not only influence how emotional states are interpreted but also how they direct cognitive and behavioral responses across a wide range of social contexts. The persuasive potential of emotions has intrigued researchers and thinkers for centuries and yet, several meta-analyses on the relationship between emotions and persuasion report inconsistent and often contradictory findings (e.g., Turner, 2021; Walter, 2019). One possible explanation for these discrepancies is that persuasion research has largely neglected to assess and account for the critical layer of meta-emotions. To fill this empirical and theoretical lacuna, the current project argues that it is worth considering whether, how, and why meta-emotions influence responses to persuasive communication; specifically, how are message processing factors (e.g., message elaboration, counterarguing) and persuasive outcomes (e.g., attitudes, behavioral intentions) impacted by a meta-emotional experience? As a first step toward answering these questions, the current project advances an argument for incorporating meta-emotions into commonly used persuasive frameworks, suggests preliminary approaches to measuring meta-emotions, and articulates an agenda for future research and theory-building.<br>
&nbsp;<br>
Title: <strong>Looking into Meta-Emotions: The Manager-Employee Emotion Dialogue from Cross-Cultural Perspective</strong><br>
Time: 16:38-16:46<br>
Authors: <strong>Unler, Ela; Caliskan, Sibel</strong><br>
Abstract: Expressing emotions may not always be comfortable for managers; however, emotional awareness may contribute to employee well-being. In our study, we have aimed to answer “how managers’ feelings about their own emotions (meta-emotions) and recognizing their subordinates’ feelings affect managing diverse emotions at work”. Based on the meta-emotions scale (Mitmansgruber et al., 2009), participants were requested to provide emotion-laden work experiences within the last month, where they felt anger, compassionate care, interest, shame/contempt, control, and suppression toward themselves. The questions were conveyed by semi-structured interviews. Through an interpretative phenomenological analysis (IPA), we collected the “meta-emotion” (total of separate 71) work experiences of 13 managers from service and production sectors in Turkey (TR). Meta-emotions are gathered under four basic themes, as in the literature: NN (negative primary, negative secondary), NP (negative primary, positive secondary), PP (positive primary, positive secondary, and PN (positive primary, negative secondary). Besides, two more separate themes, “self” or “other” orientation of emotions, emerged in TR sample: 1)the primary emotions were mainly other-oriented for NN cases (e.g., anger toward subordinates), PP cases (e.g., proud of themselves after recognition by superiors), and PN cases (e.g., suspicious after an unexpected toleration of their mistake by others), 2) and self-oriented in NP cases (e.g., sparing time to themselves after a distressful workday). From cross cultural perspective, we have started collecting data from British managers (with same methodology) to compare the managers’ emotion-orientation. Supported assumptions will be compared and how studying emotions in different contexts contributes to emotion literature will be discussed. Keywords: primary emotions, secondary emotions, meta-emotions, emotional awareness, well-being<br>
&nbsp;<br>
Title: <strong>Neural Correlates of Written Emotion Word Processing in Bilinguals: An fNIRS Study</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Ortega Manchego, Daniela Andrea; Dewey, Dan P.</strong><br>
Abstract: A growing body of literature investigating the neural correlates of emotion word processing has emerged in recent years. Moreover, research on how the processing of written emotional words may differ for bilinguals suggests that emotional word recognition is modulated by language dominance (Ayçiçegˇi and Harris 2004). Written words represent a suitable means to study emotion processing (Citron, 2012) and, most notably, to tap into the complex interaction between language dominance and the perception of the emotional valence of written words. As a new contribution to the existing literature on emotional word processing, the present study uses functional near-infrared spectroscopy (fNIRS) to explore the neural correlates of emotional word processing in Chinese-English bilinguals. Thirty Chinese-English bilingual university students participated in this study. Half of the group were native English speakers who spoke Mandarin Chinese as their second language, and the other half were native Mandarin Chinese speakers who spoke English as their second language. Participants rated the valence of 60 emotion words (taken from Kousta et al., 2009) in their native and second languages. At the same time, brain activity patterns in response to the emotional content of written words were recorded using fNIRS. Behavioral data analysis indicates no statistically significant differences in ratings or response times across groups. Nevertheless, the preliminary analysis of neural data revealed significant differences in brain activity patterns across groups, specifically in location and intensity. Brain areas related to social cognition were activated in response to positive and negative emotion words. These results are intriguing as they suggest that brain activity patterns reflect differences when processing emotion words in a native language compared to a second language. These research findings show that the manipulation of single words is a suitable means to study emotion processing and the intersection between language dominance and emotion valence. Moreover, single words can elicit cortical brain responses comparable to those elicited by pictures and facial expressions. Ayçiçegˇi, A., &amp; Harris, C. (2004). BRIEF REPORT Bilinguals’ recall and recognition of emotion words. Cognition and emotion, 18(7), 977-987. Citron, F. M. (2012). Neural correlates of written emotion word processing: A review of recent electrophysiological and hemodynamic neuroimaging studies. Brain and Language, Kousta, S., Vinson, D. P., &amp; Vigliocco, G. (2009). Emotion words, regardless of polarity, have a processing advantage over neutral words. Cognition, 112(3), 473-481.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-2-t4" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-2-t4">Flash Talks 2 : T4</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4aa155de{}.cl-4a9eda20{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a9fd92a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a9fe078{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a9fe079{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a9fe082{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a9fe083{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a9fe08c{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a9fe08d{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4aa155de"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4a9fe078"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Track</span></p></td><td class="cl-4a9fe079"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">T4</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a9fe082"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Type</span></p></td><td class="cl-4a9fe083"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a9fe082"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Title</span></p></td><td class="cl-4a9fe083"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Psychopathology and Health</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a9fe082"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Time</span></p></td><td class="cl-4a9fe083"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">16:30 - 17:10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4a9fe08c"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Room</span></p></td><td class="cl-4a9fe08d"><p class="cl-4a9fd92a"><span class="cl-4a9eda20">Roe: PFC/02/018</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Boredom Proneness in Psychopathic Traits: Evidence from Clinical and Non-Clinical Samples</strong><br>
Time: 16:30-16:38<br>
Authors: <strong>Eriksen, Line A.; Pfattheicher, Stefan</strong><br>
Abstract: Past research has established boredom as a powerful motivator of destructive behavior. At the same time, destructive behavior has frequently been related to psychopathy. Interestingly, throughout the literature on psychopathy, researchers have indicated a relation between psychopathy and a tendency to be bored (i.e.&nbsp;boredom proneness). If this is true, boredom could potentially prompt destructive behavior in psychopathy. However, the assumed relation between boredom and psychopathy remains empirically untested. The purpose of this paper is to address this gap in research on psychopathy. Using both a clinical sample consisting of people with Dissocial Personality Disorder, other diagnoses, and no diagnoses (N = 175) and a non-clinical sample from the general population of the US (N = 301), this paper empirically explores the association between boredom proneness and psychopathy. Results from the two studies reveal that across different samples and six different psychopathy measures, psychopathy is consistently related to boredom proneness. Here, the majority of effect sizes were relatively large (r &gt; .30). In sum, the present work contributes to a better understanding of the construct of psychopathy and points to boredom as a potential motivator of destructive behavior in individuals with psychopathic traits.<br>
&nbsp;<br>
Title: <strong>Does Emotional Regulation Have an Impact on the Perception of Body Health and Eating in Food Science College Students?</strong><br>
Time: 16:38-16:46<br>
Authors: <strong>Aguilera, Mari ; de Moraes Prata Gaspar, Maria Clara ; Soar, Claudia; Celorio, Ricard; Comas , Oriol; Vidal-Carou, Mari Carmen</strong><br>
Abstract: The relationship between the emotional process and eating has become a topic of great interest in current literature. Despite, there are still few studies that address topic. The objective of our work is to analyze the difference between emotional regulation between Human Nutrition and Dietetics (HND) and Food Science and Technology (FST) college students, as well as to explore the relationship of emotional regulation with food perceptions. For this, a total of 297 students completed a survey created adhoc to assess food perceptions, and a standardized questionnaire on emotional regulation. The results indicate that there is no difference in emotional regulation between the two grades evaluated, nor between the years of the degree, just as there is no difference between men and women. Moreover, results indicate that a greater capacity for emotional regulation is related to a greater perception of healthy eating, a healthier and less conflictive perception of the body and less bodily control, as well as fewer feelings of guilt related to eating. Therefore, the analysis of emotional regulation seems key to understanding the relationship we build with food and the construction of the perception of our own body, which is why it becomes a relevant target to address in the training of food specialists, as well as, in the prevention and treatment of eating disorders.<br>
&nbsp;<br>
Title: <strong>Redefining OCD: A Novel Framework Integrating Anxiety, Compulsivity, and Decision-Making</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Avbersek, Lev K; Moors, Agnes</strong><br>
Abstract: Obsessive-Compulsive Disorder (OCD) has long been categorized as an anxiety disorder, primarily recognized for persistent, intrusive thoughts (obsessions) and corresponding repetitive behaviors or mental acts (compulsions). Historically, anxiety has been central to the understanding and treatment of OCD, because it was attributed the role of mediation between obsessions and compulsions. However, this emphasis on anxiety has blurred the boundary between OCD and other anxiety-related disorders. Recent research (Gillan et al., 2017) has tackled this problem, by exploring the role of habitual processes as a transdiagnostic mechanism to differentiate between various diagnostic categories. In this perspective, habits can play a bridging role between disorders characterized by anxiety (e.g., generalized anxiety disorder) and those characterized by compulsivity (e.g., addiction). However, the evidence regarding the involvement of habitual processes in OCD remains inconclusive. We propose an alternative theoretical framework grounded in the parallel-competitive goal-directed model (Moors et al., 2017) that allows us to integrate the constructs of anxiety and compulsivity. Our model underscores two key deficits in OCD: response-outcome (R-O) contingency rigidity and aversion to discrepancy. Here, anxiety is viewed not as the primary etiological factor but rather as an epiphenomenon of the identified deficits. This shift allows for a mechanistic delineation of different types of seemingly opposing obsessive-compulsive behaviors and has transdiagnostic potential. Adopting this framework deepens our understanding of OCD, surpassing limitations of a habit-oriented view. It places anxiety within a broader perspective of decision-making, prompting a reevaluation of the role of anxiety and uncovering overlooked aspects of OCD etiology.<br>
&nbsp;<br>
Title: <strong>Somatoaffective Responses to Emotional Films</strong><br>
Time: 16:54-17:02<br>
Authors: <strong>Chentsova Dutton, Yulia; Li, Jiahan</strong><br>
Abstract: Our bodies play a central role in emotions; however, most studies on emotional reactivity do not measure the experienced somatic changes. Although research suggests a role for beliefs regarding one’s knowledge of and response to bodily sensations (e.g., interoceptive awareness, somatosensory amplification), we lack sufficient understanding of whether they predict somatic experiences. This study examined the tendency to report bodily sensations in response to emotional stimuli.Participants (N = 292) watched five emotional film clips (calm, amusing, scary, sad, and disgusting) and reported how they felt during each clip, rating their positive and negative emotions (e.g., sadness, happiness) and somatic experiences (e.g., feeling cold, shivers). The tendency to experience bodily sensations was reliable across films. We examined whether interoceptive awareness and somatosensory amplification predicted the intensity, variability, and diversity of reported somatic sensations, beyond the intensity of emotions experienced during the films. We found that the intensity and variability of somatic sensations were predicted by the intensity of experienced positive and negative emotions, with no additional variance predicted by interoceptive awareness and somatosensory amplification. Somatic diversity was also predicted by the intensity of experienced emotions, with additional variance explained by higher interoceptive awareness. These results suggest individual differences in the inclination to experience intense, variable and diverse bodily sensations in response to emotional stimuli, with this tendency partly explained by the intensity of emotional response and, for diversity, interoceptive awareness. Future work will examine whether these findings hold across cultures and samples of people with high levels of emotional distress.<br>
&nbsp;<br>
Title: <strong>Social-Emotional Outcomes in Emerging Adults with ADHD: Exploring Self-Compassion, Interpersonal Concerns, and Psychological Distress</strong><br>
Time: 17:02-17:10<br>
Authors: <strong>Hussain, Alia; Abela, Katrina R; Law, Danielle</strong><br>
Abstract: Emerging adulthood, a critical developmental stage between the ages of approximately 18 and 29, encompasses social skill growth, goal attainment, greater independence, and cognitive development influenced by environment and experience. Attention-deficit/hyperactivity disorder (ADHD), affecting approximately 5 to 8% of emerging adults (EA), is associated with adverse interpersonal experiences. Thus, EAs with ADHD are at a higher risk for unfavourable developmental outcomes, potentially mitigated by self-compassion, as seen in typically developing (TD) populations. This work examined whether and how ADHD predicted peer rejection (PR) and rejection sensitivity (RS; i.e., a learned disposition to be extremely sensitive to perceived or real criticism and rejection) compared to TD EAs, how these respective relationships contributed to psychological distress (i.e., depression, anxiety, and perceived personal stress levels), and how self-compassion might moderate this relationship. Participants for this study included 604 EAs between the ages of 17 and 22 (nADHD = 315) who completed an online questionnaire. Results revealed that ADHD predicted frequent PR experiences and higher RS levels. Moreover, self-compassion decreased stress when individuals reported more PR incidences but increased anxiety and stress when individuals reported higher RS levels. Within-group moderation analyses yielded different effects, implying that self-compassion differentially influences the impact of PR and RS on psychological distress in EAs with ADHD and their TD peers. These results may be explained by well-documented nervous system dysregulation in people with ADHD. These findings have implications for the emotional and social cognitive development of and developing preventative and therapeutic interventions fostering self-compassion for youth with ADHD.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-2-t5" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-2-t5">Flash Talks 2 : T5</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4aab67d6{}.cl-4aa8d796{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4aa9e212{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4aa9e992{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e993{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e99c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e99d{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e99e{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e99f{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e9a6{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e9a7{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4aa9e9b0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4aab67d6"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4aa9e992"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Track</span></p></td><td class="cl-4aa9e993"><p class="cl-4aa9e212"><span class="cl-4aa8d796">T5</span></p></td><td class="cl-4aa9e99c"><p class="cl-4aa9e212"><span class="cl-4aa8d796">T5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4aa9e99d"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Type</span></p></td><td class="cl-4aa9e99e"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Flash Talks</span></p></td><td class="cl-4aa9e99f"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4aa9e99d"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Title</span></p></td><td class="cl-4aa9e99e"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Virtual Emotions</span></p></td><td class="cl-4aa9e99f"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Attention and Eye-tracking</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4aa9e99d"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Time</span></p></td><td class="cl-4aa9e99e"><p class="cl-4aa9e212"><span class="cl-4aa8d796">16:30 - 17:26</span></p></td><td class="cl-4aa9e99f"><p class="cl-4aa9e212"><span class="cl-4aa8d796">16:30 - 17:26</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4aa9e9a6"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Room</span></p></td><td class="cl-4aa9e9a7"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Farset: PFC/02/025</span></p></td><td class="cl-4aa9e9b0"><p class="cl-4aa9e212"><span class="cl-4aa8d796">Farset: PFC/02/025</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Emotion Recognition in Cyberspace: Distinct Emotion Recognition Abilities and Underlying Mechanisms for Emojis and Faces</strong><br>
Time: 16:30-16:38<br>
Authors: <strong>Löchner, Nana; Olderbak, Sally; Moshagen, Morten; Kannen, Christopher; Montag, Christian</strong><br>
Abstract: In cyberspace, especially in digital text communication, emojis are often used as substitutes for facial emotion expressions that are important nonverbal clues in face-to-face social interactions. Therefore, the first aim of this preliminary work was to research if emotion recognition in emojis and in faces are distinct abilities. Additionally, we investigated if emotion recognition in emojis and faces are similarly influenced by a facial mimicry instruction in combination with trait empathy. The online study included 690 participants who completed emotion recognition tasks twice in one session, with a random assignment to an experimental group receiving a mimicry instruction or a control group receiving an attention instruction the second time. Results of confirmatory factor analyses showed separate but correlated emotion recognition abilities for emojis and faces. Moreover, latent mean change analyses using multi-group structural equation models revealed an improvement in emotion recognition in emojis in both groups. The improvement in the control group was larger than in the experimental group. The emotion recognition in faces only improved in the control group which was moderated by cognitive empathy. The benefits from the attention instruction were greater for individuals with lower cognitive empathy compared to those with higher cognitive empathy levels. The results of the current study suggest that emotion recognition in emojis and faces are two distinct abilities with differing underlying mechanisms.<br>
&nbsp;<br>
Title: <strong>Associations Between Social Media Use and Negative Affect among Young, Middle-Aged, and Older Adults</strong><br>
Time: 16:38-16:46<br>
Authors: <strong>Miller, Lisa MS; Huo, Meng</strong><br>
Abstract: Social networking sites, such as Facebook and X (Twitter), are increasingly popular among older adults (Auxier &amp; Anderson, 2021). This may be in part because these sites offer opportunities for social connectedness, which can be restricted in later life due to age-related decreases in physical mobility (Cotton et al., 2013). Although the literature indicates that social media use can improve feelings of social connectedness (Ballantyne et al., 2010; Bell et al., 2013; Sheldon, 2012), the potential dark side, such as negative affect, is less well-researched. Greater social media use has been associated with higher levels of negative emotion in young adults (Aalbers et al., 2019; Lin et al., 2016), but research also suggests the harm may be less evident with age (Sewall et al., 2022). We examined age differences in the association between social media use and negative affect (little interest, hopeless, nervousness, and worrying) in a nationally representative sample of 14,306 U.S. adults aged 18–104. Using generalized linear models for complex samples, we observed a significant age × social-media-use interaction on participants’ overall negative affect, indicating larger differences between social media users and nonusers at younger relative to older ages (after controlling for demographic variables). Younger-adult users reported higher levels of negative affect than nonusers, whereas older-adult users and nonusers showed similarly low levels of negative affect. Together with past work showing benefits of social media use on social connectedness, this study identifies the unique role social media use may play in promoting older adult mental health.<br>
&nbsp;<br>
Title: <strong>Exploring Sensory Modalities to Simulate Touch from a Virtual Agent</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Richard, Grégoire; Thouvenin, Indira; Boucaud, Fabien; Pelachaud, Catherine</strong><br>
Abstract: Social interactions are multi-factorial by nature, and engage multiple sensory channels, through visual, audio, and touch. Particularly, touch allows communicating emotions. Integrating social touch in virtual reality (VR) with virtual agents (VA) requires haptic feedback, which is technologically invasive. Previous work (de Lagarde et al, 2023) has shown that touch can be substituted by other senses, such as audio, and still be perceived as socio-emotional intentions. Our aim is to explore the perception of visual/audio/tactile feedback during social interactions with VAs on the recognition of social touch gestures, their underlying intentions and emotions. We are exploring how the different sensory modalities drive recognition of social gestures together, and separately. We hypothesize participants perceive social touch the most under the congruent combination of visual, audio and tactile feedback. In their work, De Lagarde and colleagues (2023) proposed and validated audio recordings of different social touch gestures. We first designed tactile patterns based on the audio recordings (stroking, tapping and hitting), using a matrix of actuators fitted on a user’s arm. With a first preliminary experiment, involving only tactile and audio stimuli, we tuned the parameters of those tactile patterns. We are designing a VR experiment where a VA touches participants, using motions representing the different social touch gestures, combining congruent and incongruent visuo-audio-tactile stimuli. The expected results are to provide insight regarding the parameters to elicit the perception of social touch through visual and audio feedback, and how sensory substitution and perceptual supplementation can be implemented for a VA to plausibly touch users in VR.<br>
&nbsp;<br>
Title: <strong>Investigating Pupil Mimicry in Pet Dogs</strong><br>
Time: 16:54-17:02<br>
Authors: <strong>Lonardo, Lucrezia; Jaasma, Linda; Radovanovic, Kia; Zijlstra, Tonko; Völter, Christoph; Huber, Ludwig; Kret, Mariska</strong><br>
Abstract: Pupil mimicry happens when the pupils in the eyes of two interacting partners converge towards the same size. This phenomenon has been considered at the basis of the human ability to detect and share emotions, it enhances cooperation between social partners, but its function and evolutionary origins remain debated. While there is evidence that humans resonate with other species’ emotions to some extent, the pupil mimicry effect was found to be stronger between conspecifics than between members of different species in humans and chimpanzees (Pan troglodytes). With the present eye-tracking study, we are investigating whether pet dogs (Canis familiaris) show pupil mimicry in response to animations of conspecific and human eyes showing constricting and dilating pupils. The dog-human dyad constitutes an interesting model to address pupil mimicry between members of different species due to their shared evolutionary history. First domesticated animals, dogs have become one of the (evolutionarily) most successful species, colonizing the globe alongside humans, helping us with several activities, from herding to assisting people with disabilities. Moreover, human faces are highly familiar and salient for dogs. After months of training, dogs’ eye-movements and pupil sizes are now being recorded in two different labs. If pupil mimicry has evolved as a mechanism facilitating inter-species communication and cooperation, we expect dogs’ pupils to be larger when watching conspecific and human pupils that dilate compared to when watching the same pupils constrict. This study has the potential to reveal whether the ability to automatically empathise with other species is uniquely human.<br>
&nbsp;<br>
Title: <strong>Do Threatening Faces Hold Attention Automatically? Evidence from an Eye-Tracking Study</strong><br>
Time: 17:10-17:18<br>
Authors: <strong>Severom, Mario Carlo M; Mulckhuyse, Manon</strong><br>
Abstract: Swiftly responding to threatening cues in the environment is vital for survival. While existing research indicates the automatic attentional capture of threatening faces, the automaticity of delayed attentional disengagement by task-irrelevant threatening faces remains unexplored. As such, this study employs an eye-tracking methodology to investigate the influence of threatening and non-threatening facial expressions as task-irrelevant cues within contexts of varying working memory load. Sixty participants perform an adapted spatial cueing paradigm where their saccadic response latencies to neutral peripheral targets are compared when either a task-irrelevant angry or a neutral facial expression is presented at fixation, while at the same time maintaining either 1 digit or 6 digits in working memory. Moreover, the study examines the impact of trait anxiety on attentional disengagement from threatening faces, building upon prior findings of attentional bias in high anxious individuals. We expect participants to display longer saccadic latencies when an angry face is presented in comparison to a neutral face, irrespective of the working memory load condition. Additionally, we expect this pattern to be more pronounced in high anxious individuals than their low anxious counterparts. Overall, the findings of the study at hand can deepen current understanding of the automaticity involved in attentional processing of threatening faces and offers valuable insights into addressing attentional bias in anxious individuals.<br>
&nbsp;<br>
Title: <strong>Emotion and Eye Contact as Joint Primers of the Gaze-Cueing Effect</strong><br>
Time: 17:18-17:26<br>
Authors: <strong>Guillin, Amandine; Vergilino-Perez, Dorine; Chaby, Laurence</strong><br>
Abstract: Efficient processing of others’ gaze direction is essential for the detection of environmental clues and is a key mechanism in nonverbal communication. The tendency for individuals to automatically shift their attention in the direction of someone else’s gaze is known as the gaze-cueing effect and is typically reflected in faster reaction times when detecting targets that are being looked at, as opposed to targets that are being looked away from. While some authors have found that emotional expressions do not modulate the gaze-cueing effect (Coy et al., 2018; Uono et al., 2022), others have established influences of expressed emotions from an early age (Niedźwiecka &amp; Tomalski, 2015), and demonstrated a priming effect of threatening faces (Ishikawa et al., 2021). Factors such as the prior establishment of a direct eye contact or the individual traits of the observer (e.g., anxiety) also seem to modulate the visuo-spatial orientation of attention and could thereby increase the gaze-cueing effect (Dalmaso et al., 2020; Kaur et al., 2023). Using eye-tracking technology, we aim to explore how emotional facial expressions (happiness, anger, disgust and neutral) and eye contact (direct vs.&nbsp;averted gaze) jointly facilitate or inhibit ocular saccades in a gaze-cueing task. We also seek to investigate the potential effects of the avoidance temperament (Elliot &amp; Thrash, 2002) - characterized by an emotional hypervigilance - on these attentional processes. Our results emphasize the importance of socio-emotional cues in the establishment of joint attention, and their relevance to the development of defensive or social bonding strategies.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
</section>
<section id="flash-talks-2-t6" class="level2">
<h2 class="anchored" data-anchor-id="flash-talks-2-t6">Flash Talks 2 : T6</h2>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-4ab5773a{}.cl-4ab2efe2{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4ab3f176{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4ab3f8e2{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f8ec{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f8ed{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f8ee{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f8f6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f8f7{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f900{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f901{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4ab3f902{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-4ab5773a"><tbody><tr style="overflow-wrap:break-word;"><td class="cl-4ab3f8e2"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Track</span></p></td><td class="cl-4ab3f8ec"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">T6</span></p></td><td class="cl-4ab3f8ed"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">T6</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4ab3f8ee"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Type</span></p></td><td class="cl-4ab3f8f6"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Flash Talks</span></p></td><td class="cl-4ab3f8f7"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Flash Talks</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4ab3f8ee"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Title</span></p></td><td class="cl-4ab3f8f6"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Behavior, Decision-Making, Intergroup</span></p></td><td class="cl-4ab3f8f7"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Behavior, Decision-Making, Intergroup, Intergroup</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4ab3f8ee"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Time</span></p></td><td class="cl-4ab3f8f6"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">16:30 - 17:18</span></p></td><td class="cl-4ab3f8f7"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">16:30 - 17:18</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-4ab3f900"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Room</span></p></td><td class="cl-4ab3f901"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Moyola: PFC/02/017</span></p></td><td class="cl-4ab3f902"><p class="cl-4ab3f176"><span class="cl-4ab2efe2">Moyola: PFC/02/017</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Title: <strong>Impact of Approach and Avoidance Behavioral Tendencies on Risky Decision Making</strong><br>
Time: 16:30-16:38<br>
Authors: <strong>Pastwa, Maciej; Imbir, Kamil</strong><br>
Abstract: The influence of happiness on taking risky decisions is a well-known phenomenon (O’Neill et al., 2008; Hu et al., 2015). Interestingly, happiness is not only a positive emotion, it also evokes the behavioral tendency of approach, which, together with valence, may push towards more risky behavior. To test this hypothesis we picked two emotion dyads, based on the Plutchik’s taxonomy of emotions (1982), happiness-sadness and anger-fear, with only one of the dyads differing in valence, but both of them differing in the evoked emotional tendency. Using emotionally charged pictures to evoke affect, we conducted two experiments which tested the influence of the aforementioned emotions on the risky decisions taken in a game of chance. In the conditions of unlimited time of presentation of the affective pictures, the emotions influenced both the decisions and reaction times, with participants in the condition of happiness predictably taking the most risky decisions in the shortest time. When the presentation time of the stimuli had been limited, the emotions had impact only on the reaction times, with anger evoking the fastest reactions. In both experiments participants played more risky and faster after winning in the previous round. The results of the experiments show the importance of exploring the influence of behavioral tendencies evoked by emotions on decision making in risky and ambiguous situations, especially in the context of games involving gambling, where emotionally charged graphics are an integral part of the decision environment.<br>
&nbsp;<br>
Title: <strong>The Reduced Ability to Detect Pain Expressions on the Faces of Black Individuals is Linked with a Strict Decision Criterion Rather than Sensitivity to Visual Information</strong><br>
Time: 16:38-16:46<br>
Authors: <strong>Sénécal, Daphnée; Saumure, Camille; Plouffe-Demers, Marie-Pier; Fiset, Daniel; Gosselin, Frédéric; Blais, Caroline</strong><br>
Abstract: Studies reveal that the pain experienced by individuals of Black ethnicity is underestimated in countries where most individuals are of White ethnicity. Moreover, when it comes to detecting pain based on facial expressions, White observers have more difficulty with Black faces compares to White faces. This detection of pain in facial expressions involves at least two processes: the sensitivity to the visual information embedded in pain facial expressions and the criteria used to ascertain that a face genuinely conveys pain. The present study aims at verifying if the difficulty at detecting pain in faces of Black ethnicity is associated with an altered sensitivity, an altered criterion, or both. We conducted a series of four experiments where participants saw either Black or White faces depicting pain facial expressions or neutrality. On each trial, participants had to determine whether the face displayed pain or not (Exp. 1,3,4) or they were asked to decide which of two faces was expressing pain (Exp. 2a and 2b). For experiments 1, 2a and 2b, White participants (n=150) from predominantly White countries were recruited on Prolific. In experiments 3 and 4, White participants (n=100) coming from predominantly white countries, and Black participants (n=100) coming from predominantly Black countries were recruited. Overall, the impairment in detecting pain in Black faces is mostly associated with an altered criterion. Consequently, further studies should explore the theoretical implications of these results, specifically considering the potential contribution of our mental representations and expectations concerning the pain experienced by Black ethnicity.<br>
&nbsp;<br>
Title: <strong>Loss Aversion, not Risk Aversion: The Impact of Incidental Emotions</strong><br>
Time: 16:46-16:54<br>
Authors: <strong>Treiss, Stephan; Pothos, Emmanuel; Corr, Philip; White, Lee</strong><br>
Abstract: This study explores the effects of specific emotions — happiness, sadness, fear, and anger — on Loss Aversion and Risk Aversion through two experiments. Utilising a Prospect-theory inspired model, Loss and Risk Aversion are estimated. The first experiment adopts a between-participants design, while the second allows for an exploration of changes in Loss and Risk Aversion, along with associated incidental emotions, within participants across two sessions. The results indicate that incidental emotions have a more pronounced influence on Loss Aversion rather than Risk Aversion. Some consistency across the two experiments was observed, with happiness and fear demonstrating an inclination to increase Loss Aversion, while the relationship with sadness proved more variable. Some preliminary exploration into potential explanations for this pattern of results is offered. Interestingly, while group emotions of sadness have previously shown a negative correlation with Loss Aversion (Hermalin &amp; Isen, 2008; Isen et al., 1988), the individual experience of feeling “blue” positively correlates with Loss Aversion in the second experiment. The study also delves into whether control variables, such as personality traits or anxiety (Charpentier et al., 2016), mediate the relationship between incidental emotions and Loss Aversion, but we cannot offer concrete conclusions from the present results. In summary, this study illuminates the impact of incidental emotions on Loss and Risk Aversion, contributing to a better understanding of decision-making influencers and potential avenues for improvement.<br>
&nbsp;<br>
Title: <strong>Infant-Centered Behavioral Response Patterns to Discrete Emotions</strong><br>
Time: 16:54-17:02<br>
Authors: <strong>Özden, Zeynep B; Reschke, Peter; Walle, Eric A</strong><br>
Abstract: Responding to others’ emotions entails the coordination of multiple behaviors. Yet, research on such responding typically analyses each behavior separately. We investigated the heterogeneity of 16-, 19-, and 24-month-old infants’ (N = 296) behavioral response patterns to 5 discrete emotions (joy, sadness, fear, anger, disgust) during a naturalistic interaction. Various infant behaviors (social avoidance, security seeking, stimulus exploration, prosocial responding, information seeking, relaxed play) in response to the emotional context were coded. A latent class analysis (LCA) was then used to reveal groups of individuals that shared commonalities in their behavioral response patterns across the sample. Next, a GLMM examined differences in class prevalence across discrete emotions, age groups, and across age groups within emotions. The LCA revealed 4 distinct classes of infants (Table 1): Prosocial Explorers (19.4%), Information Seeker-Explorers (42.5%), Cautious Information Seekers (19.6%), and Relaxed Players (18.3%). The GLMM revealed several interesting differences in the frequency of each class across emotions and ages. Notably, there was a main effect of emotion for Prosocial Explorers F(4, 365) = 3.40, p = 0.01, and Relaxed Players F(4, 294) = 6.18, p &lt; .001, a main effect of age for Relaxed Players, F(2, 212) = 6.79, p = .001, and a significant interaction effect for Information Seeker-Explorers F(8, 438) = 2.51, p = .01, and Cautious Information Seekers F(8, 320) = 3.05, p = .003. (See Table 2 for pairwise comparisons). This is the first study to utilize an infant-centered analysis to identify subgroups of individuals with similar patterns of goal-directed behaviors in response to discrete emotions.<br>
&nbsp;<br>
Title: <strong>The Hateful People: Populist Attitudes Predict Interpersonal and Intergroup Hate</strong><br>
Time: 17:02-17:10<br>
Authors: <strong>Martínez, Cristhian A.; van Prooijen, Jan-Willem; Van Lange, Paul</strong><br>
Abstract: Do populist attitudes predict a growth in feelings of hate? Or does experiencing hate predicts a growth in populist attitudes? Previous research has not yet examined the relation between populist attitudes and hate feelings over time. Drawing on the match between previous theorizing on the nature of hate and the main features of populism, we propose that the populist worldview meets particularly well the conditions for the emergence of hate feelings over time (and not the other way around). To examine this, we conducted a two-wave study with a large pre-stratified Dutch adult sample in the Netherlands and tested the time-extended associations between populism and hate, thereby focusing on other individuals (N = 943) or groups (N = 851) as targets of hate. Using cross-lagged panel models for interpersonal and intergroup hate, results revealed that hate feelings and populist attitudes are stable over time, that they are positively associated and its association is stable over time, and as expected, that earlier populist attitudes predict later feelings of hate, while the reverse associations were virtually absent. The findings highlight the intense and strong negative feelings that the populist worldview can inspire among people, and illuminate how the populist strategy intended to gain supporters, both from the left and right, may fuel further antagonism, division, and prolonged hate in societies.<br>
&nbsp;<br>
Title: <strong>Do Emotional Carryover Effects Carry Over?</strong><br>
Time: 17:10-17:18<br>
Authors: <strong>Masters, Nikhil; Lloyd, Tim; Starmer, Chris</strong><br>
Abstract: Existing research has demonstrated carryover effects whereby emotions generated in one context influence decisions in other, unrelated ones. We examine the carryover effect in relation to valuations of risky and ambiguous lotteries with a novel focus on the comparison of carryovers arising from a targeted stimulus (designed to elicit a specific emotion) with those arising from a naturalistic stimulus (expected to produce a more complex emotional response). We find carryover effects using both types of stimuli, but they are stronger for the naturalistic stimulus and in the context of ambiguity, providing a proof of concept that carryover effects can be observed when moving away from highly stylised settings. These effects are also gender-specific with only males being susceptible. To probe the emotional foundations of the carryover effect, we conduct analysis relating individual self-reports of emotions to valuation behaviour. Our results cast doubt on some previously claimed links between specific incidental emotions and risk taking.<br>
&nbsp;<br>
</p>
<div style="page-break-after: always;"></div>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="poster-abstracts" class="level1">
<h1>Poster Abstracts</h1>
<div style="page-break-after: always;"></div>
<p>Title: <strong>Heightened Physiological Arousal and Emotional Transference: Prosocial Implications of Narrative Transportation among College Students</strong><br>
Poster Number: 1<br>
Authors: <strong>Seddio, Kaylee R; Yates, Tyler; Blaszka, Aana; Quinn, Mary</strong><br>
Abstract: Our study investigated whether individuals’ levels of narrative transportation while reading a first-hand account of survival contributed to later empathetic outcomes. We used heartrate variability (HRV) as a measure of physiological arousal throughout the reading paradigm. We found that emotionally transporting oneself into a story produced greater levels of personal distress, allowing for individuals to see themselves in the place of the story’s characters. There were increases in sympathetic activation dependent on both prior levels of empathy and state-levels while reading. Results of the study suggest empathy provides a mechanism for individuals to connect to others on a cognitive, affective, and even behavioral level. To empathize with someone is to understand their perspective and to experience another’s emotions. Narrative transportation is a combination of attention, imagery, and feelings, in which an individual becomes immersed in a narrative world, influencing beliefs, attitudes, and behaviors towards others. Transportation into a narrative is an effective way to establish and even stimulate feelings of empathy and emotional connection. This provides us with opportunities to develop curricula or interventions that foster empathetic responses. If empathy can be taught, then methods can be established that effectively reduce feelings of hatred or bias towards others. Individuals who are more transported are more likely to adopt beliefs, attitudes, and behaviors that are adapted to fit the narrative. By providing individuals with the opportunity to change or adapt their feelings, society can move forward, reducing negative attitudes towards others and creating a more balanced environment with acceptance and empathy.<br>
&nbsp;<br>
Title: <strong>Emotion Signals by Contemporary Relationship Labels: Modeling Relational Change with Affective Expectation</strong><br>
Poster Number: 2<br>
Authors: <strong>Kelly, Chelsea Rae</strong><br>
Abstract: Hookup culture’s middle ground of “undefined” romantic relationships (talking to, hanging out, hooking up, etc.) offers an agentic realm for the study of emotion signals as predictors of relational change. I explore the interconnection of self, identity, and emotion by generating and empirically testing novel theoretical predictions concerning felt-emotion feedback and its deviation from expectation as an indicator of future relationship change in a longitudinal sample of young adults in defined (N=50) and undefined (N=43) relational dyads. Through MANOVA, two-sample t-test, regression, and structural equation model analyses conducted using variables of respondent identities and emotions, affect control theory-computed emotions, and variables of respondent identity discrepancy (squared Euclidian distance between affective ratings of personas (true selves) and relational selves (selves in relationship)) and emotion discrepancy (squared Euclidean distance between affective ratings of respondent emotion expectations and respondent emotion experiences), I find that (1) undefined relationship labels are affectively distinct and culturally shared, (2) affective ratings of personas do not differ by cultural framework while those of relational selves do, (3) identity discrepancy and emotion discrepancy have a positive and statistically significant correlation (respondents seek to affirm personas, not relational selves), (4) relationship emotional optimism (evident in computations for both defined and for undefined relationship participants) is justified in defined, but not undefined, relationship experiences, and (5) identity discrepancy-generated emotion signals account for a 17% reduction in the direct effect of relationship type on relationship dissolution likelihood: empirical evidence that emotion signals in the present significantly influence relationship behaviors in the future.<br>
&nbsp;<br>
Title: <strong>Testing the Ecological Validity of Mechanistic Emotional Memory Models</strong><br>
Poster Number: 3<br>
Authors: <strong>Talmi, Deborah; Mekjan , Nikoline; Attwood, Will; Dupertuys, Juliette ; Shulhan, Anastasiya</strong><br>
Abstract: Human brains evolved to utilise goal-relevant information and therefore likely implement multiple mechanisms to retain such information preferentially and to retrieve it in relevant contexts. Recent context Maintenance and Retrieval models (eCMR and CMR3) bring some of these mechanisms within a single formal framework to explain the dynamics of recalling personally meaningful information. The models predict increased recall of emotionally negative information as well as the specific dynamics of the recall output. Here we test whether these predictions are confirmed for real-world stimuli with emotional significance. A sample of participants who reported that the war in Ukraine was personally relevant to them were asked to view sets of very negative and less negative photographs of the war, all taken from Instagram accounts of European correspondents, and then described what they recalled from these images. The data confirmed two key predictions of the models: participants recalled those photographs studied closer in time to each other contiguously, and they recalled more of the very negative photographs. However, in contradiction to the prediction of the models, participants did not recall those more negative images contiguously. Follow-up work explored the reasons this effect was not observed by differentiating between the global, visual, emotional and semantic similarity of images to understand the underlying reasons for clustering in recall of complex novel scenes. Taken together, the results support eCMR as a model of recall of goal-relevant information, but also point to limitations in its ability to simulate strategic encoding processes.<br>
&nbsp;<br>
Title: <strong>Threat-Induced Prosocial Behavior: Enhanced Exogenous Attention to Protect Others from Harm</strong><br>
Poster Number: 4<br>
Authors: <strong>Mulckhuyse, Manon; Lojowska, Maria; Lucchi, Federica</strong><br>
Abstract: Humans are in general willing to demonstrate prosocial behavior if they can prevent harm to others. However, to what extent pro-social behavior involves less controlled cognitive processes when aiding others remains unclear. Here we examined the impact of threat exposure to an anonymous other on stimulus-driven attention. Participants performed an exogenous spatial cueing task in dyads whilst their performance determined if electric shocks were delivered as punishment. The experiment was conducted under three conditions: when participants themselves were under threat, when an anonymous co-participant was under threat, and under no threat conditions. In both threat of shock conditions, participants were faster in orienting and reorienting than in the no threat condition. Importantly, this enhanced performance was not due to a speed-accuracy trade off. Moreover, this behavioral improvement was associated with increased pupil dilation in both threat of shock conditions. Together, these findings suggest that engaging in pro-social behavior when others are in danger enhances automatic attention and triggers autonomic responses at a level comparable to when individuals themselves are under threat.<br>
&nbsp;<br>
Title: <strong>Reporting on an Interactive, Public Installation of Android Andrea - Peoples’ Reactions and Opinions</strong><br>
Poster Number: 5<br>
Authors: <strong>Becker-Asano, Christian; Heisler, Marcel</strong><br>
Abstract: We report on the opinions that visitors of a public museum stated after having interacted, actively or passively, with a our very humanlike, android robot “Andrea”. It is a human-sized, sitting android robot with a total of 52 pneumatic actuators that can be programmed to move the upper body, its fingers and hands, its head, and its face including the eyes. It was installed in the museum for six days from end of October to beginning of November 2023. Visitors could interact with the robot by pressing a button to start the audio recording and releasing it to start the audio processing. A combination of machine learning algorithms then generated a response that was played back as audio in synchrony with an auto-generated animation of the robot’s face. In total, 44 structured interviews were conducted asking the visitors to describe their respective interaction, rate the usefulness of the android in its current version, and comment on future scenarios that they either judge appropriate or inappropriate for the android in the museum. Also, we asked which parts needed to be improved before the android could be employed in the museum again. The results suggest that the visitors had a predominantly positive opinion about Andrea. A minority of the visitors were concerned about the risk that such robots could substitute humans in the workplace. Some also reported feeling uncanny. The majority, however, could imagine that such a robot could fulfill a certain purpose in the museum after the response time has been improved and multi-language support implemented. To the best of our knowledge this was the first time that an interactive, fully autonomous android robot has been installed and evaluated in a public space in Europe, if not in the world.<br>
&nbsp;<br>
Title: <strong>Leveraging Large Language Models to Generate Targeted Reappraisals</strong><br>
Poster Number: 6<br>
Authors: <strong>Ong, Desmond C; Zhan, Hongli; Lee, Yoon Kyung; Li, Junyi Jessy</strong><br>
Abstract: Language is a powerful means for us to regulate each other’s emotions, and Large Language Models (LLMs) have the potential to help people achieve better emotional well-being—but we must do so scientifically and ethically. We describe a multi-step (and multi-paper) research program using LLMs, combined with psychological theory, to offer targeted reappraisals—alternative ways of evaluating a situation that result in better well-being—via a novel neurosymbolic approach. First, we show that LLMs can accurately identify a narrator’s cognitive appraisals from text, for example, feeling like they were causally responsible for a negative event). Next, we leverage empirical data from a recent meta-analysis as weights in a model to select the most relevant appraisals to target. That is, if the narrator is feeling guilt and we would like to help them downregulate, we could target the self-responsibility appraisal. Finally, we prompt the LLM to generate a targeted reappraisal, and compare these with human responses, baseline model responses simply prompted to generate an empathic response without mention of appraisal, and models using other prompting strategies. At each step, we discuss our evaluation strategy, which is crucial to establish scientific validity. We highlight gaps between current model capabilities and human-level emotional intelligence, and we end with thoughts about deploying such systems ethically. This work has the potential to inform emotionally intelligent (and empathic) conversational agents that could help people live emotionally healthier lives.<br>
&nbsp;<br>
Title: <strong>Uncovering the Neural Representation of Epistemic Emotions</strong><br>
Poster Number: 7<br>
Authors: <strong>Erdemli, Asli; Santavirta, Severi; Saarimäki, Heini; Sander, David; Nummenmaa, Lauri</strong><br>
Abstract: Epistemic emotions refer to emotions triggered by information, its qualities or the processing of information. In an fMRI study on 104 healthy adults we mapped the cortical topographies of appraisals, basic and epistemic emotions. Here, we only discuss the findings related to epistemic emotions. Results suggest that curiosity and interest are differentially represented in the brain. Excitement, interest, surprise and enjoyment all displayed similar activation maps. Amygdala, thought to reflect perceived relevance, was active in interest, surprise and enjoyment. Implications for relevant theories of the field are discussed.<br>
&nbsp;<br>
Title: <strong>Sensory Processing Sensitivity Mediates the Relationship Between Externally Oriented Thinking and Fantasizing</strong><br>
Poster Number: 8<br>
Authors: <strong>Jakobson, Lorna S; McQuarrie, Amanda; Van Landeghem, Chantal; Smith, Stephen D</strong><br>
Abstract: Alexithymia is a trait characterized by difficulties identifying and describing feelings and by an externally oriented thinking (EOT) style; however, whether alexithymia is also associated with a deficit in fantasizing abilities as originally postulated is unclear. In two studies, we investigated whether links between EOT and fantasizing are mediated by sensory processing sensitivity (SPS). University students completed self-report measures of alexithymia, SPS, and fantasizing. In Study 1 (N = 700) we identified two clusters of SPS traits: a positive facet (sensitivity to subtle sensory cues) and a negative facet (sensitivity to uncomfortable sensations). In the 499 participants who completed the fantasy measure, we found that those who turned their attention inward (low EOT) reported stronger SPS positive traits and that this predicted a stronger tendency to imagine how fictional characters feel. In Study 2 (N = 600), we showed that the link between EOT and this tendency was mediated by emotional reactivity and fantasy proneness. We suggest that having an impoverished fantasy life mainly characterizes alexithymic individuals who score high on EOT. We argue that alexithymic individuals who score relatively low on EOT and are highly sensitive to subtle stimuli (including internally generated mental images) display fantasy proneness and develop a cognitive style characterized by using imagery-based strategies for reasoning and problem solving. As a result, they tend to become deeply absorbed in books, plays, and movies and find it easy to imagine what the characters are thinking and feeling. These studies clarify the relationship between alexithymia and fantasy impairment.<br>
&nbsp;<br>
Title: <strong>Defining Resilience Following a Potentially Traumatic Event in Psychological Research: A Delphi Study</strong><br>
Poster Number: 9<br>
Authors: <strong>Delaney, Rian; Robinson, Martin; Hanna, Donncha; Armour, Cherie</strong><br>
Abstract: The term psychological resilience is often limited by the lack of consensus surrounding what exactly researchers are referring to when they use the term resilience. Debates and contradictions within psychological resilience literature threaten the utility of the term. A total of 22 experts from within the field of resilience research were recruited to partake in an online e-Delphi with the aim of reaching a consensus on items that could help define resilience. The items included in this Delphi study were derived from the literature and generated by participants in the study. The items were rated based on their essentiality to defining resilience with 13 reaching the pre-set requirements. Of these 13 items, 4 were deemed essential to defining resilience and 9 were deemed non-essential. Referring to resilience as a trait was largely rejected. The view that resilience is a dynamic and multifactorial concept was preferred by this expert group. This study provides a discussion of these items in relation to the wider literature and potential direction for future research and debates on this topic.<br>
&nbsp;<br>
Title: <strong>Types of Envy among Russian Speakers on Social Networks</strong><br>
Poster Number: 10<br>
Authors: <strong>Pryakhina, Tatiana</strong><br>
Abstract: Studies distinguish different types of envy. For example, all Russian methods of envy research focus on its destructive manifestations. However, there is another point of view on the manifestations of envy. In foreign sources it is accepted to distinguish between benign and malicious envy. Our goal was to find out what kind of envy will be triggered among the Russian-speaking sample (N=72) on the example of evaluation of material and experiential purchases in social networks and to identify the distinctive properties of envy. Participants were required to complete several questionnaires about envy and rate envy of material and experiential purchases (Lin, Van de Ven, Utz, 2017). Statistical analysis showed that experiential purchases trigger more envy among the purchases, despite the equality in price. The hypothesis of a negative correlation between the propensity to materialism and envy of experiential purchases was not confirmed, because, on the contrary, a positive correlation between the two scales was obtained, and the strength of the correlation between the scale of materialism and the scale of envy of experiential purchases is stronger than in relation to material purchases.<br>
&nbsp;<br>
Title: <strong>Avoiding the Negativity: An Investigation on Avoided Affect in Mexicans</strong><br>
Poster Number: 12<br>
Authors: <strong>Espinosa, Natalia; Salvador, Cristina</strong><br>
Abstract: Three decades of research in cultural psychology show that viewing the self as independent vs.&nbsp;interdependent powerfully shapes emotional experiences. One hallmark of the interdependent self is the tendency to be self-effacing and hold a weaker positivity bias in emotional experiences in order to promote social harmony. However, the basis for this conclusion was drawn by comparing East Asians, a more interdependent group, to European Americans, a prototypically independent group. Thus, our current understanding of interdependence is conflated with the specific way in which interdependence is achieved in East Asia. To test whether this effect generalizes to other interdependent groups, we compared 100 Mexicans living in Mexico (an understudied interdependent group) with 100 European Americans living in the U.S. Participants were recruited through Prolific and completed a modified version of the Affect Valuation Index (AVI). Participants were asked about how often they felt, wanted to feel, and wanted to avoid a series of positive and negative emotions that varied in whether they promoted independence (socially disengaging emotions) or interdependence (socially engaging emotions). As predicted, Mexicans participants wanted to avoid negative emotions more than European Americans particularly those that were socially disengaging, such as anger and pride. We found no cultural differences for the avoidance of positive emotions. This work contributes to research on culture and emotion by showing that Mexicans have a style of interdependence characterized by the avoidance of negative and independence-promoting emotions.<br>
&nbsp;<br>
Title: <strong>Emotions and Behavioral Intentions in Response to Norm Violations</strong><br>
Poster Number: 13<br>
Authors: <strong>Karinen, Annika K; van Kleef, Gerben</strong><br>
Abstract: Although norms are essential for the functioning of society, norm violations commonly occur. Whether norm violations spread or are contained likely depends on the emotions elicited by them. Here, we will examine perceived emotional reactions and behavioral intentions in response to norm violations. The study will be a between-subjects survey, and participants will be UK citizens recruited through Prolific. Participants will read a description of a norm violation, and the disruptiveness, threat, and benefit of the norm violation will be manipulated across conditions. Using an intersubjective approach, participants will rate the emotions that they believe observers witnessing the norm violation would experience. Participants will also rate the behavioral tendencies they believe the observers would undertake (opposition, acquiescence, and support). We predict that when the norm violation is disruptive it elicits anger, when the norm violation is threatening it elicits fear, and when the norm violation is beneficial it elicits admiration. We further hypothesize that anger predicts opposition of the norm violation, that fear predicts acquiescence, and that admiration predicts support of the norm violation. Participants will also complete the Brief HEXACO Inventory to measure personality, the Short Schwarz Value Survey, and a measure of (economic and social) political orientation. Data collection is about to commence and the study is to be completed in early 2024. These results will give insight into the emotional dynamics of norm violations, and help to understand how emotions elicited contribute to the spread or containment of norm violations.<br>
&nbsp;<br>
Title: <strong>Not Feeling It: No Emotion Effects on Breadth of Attention</strong><br>
Poster Number: 14<br>
Authors: <strong>Kolnes, Martin MK; Uusberg, Andero</strong><br>
Abstract: There are numerous studies showing that emotional states impact the breadth of attention. However, recent inconsistent results in high-powered studies raise the question of what kind of emotional state robustly influences the breadth of attention. In two web-based experiments, we used two different types of emotion manipulations with complementary strengths to explore this relationship. In Experiment 1 (n = 193), we used autobiographical recall to elicit a personally relevant emotional experience. In Experiment 2 (n = 200), we used viewing emotional images to elicit more immediate and less variable emotional experiences that may lack personal relevance. Importantly, in neither experiment did we observe any emotion effects on the breadth of attention measured by the Navon task. These findings add support to the growing number of failed attempts to replicate the emotion effect on the breadth of attention. The findings also highlight that it is still necessary to clarify which kind of emotional state robustly influences the breadth of attention, as the relationship appears to be weaker than expected based on the literature.<br>
&nbsp;<br>
Title: <strong>“Don’t Ruin the Balance of Nature”: Positive Awe and Threat-Based Awe About Nature and Support for Pro-Environmental Policies During the Pandemic</strong><br>
Poster Number: 15<br>
Authors: <strong>Solak, Nevin ; Uluğ, Özden Melis; Kanık, Betül; Chayinska, Maria</strong><br>
Abstract: The Coronavirus pandemic has brought different discussions about how nature works to the fore (e.g., “Nature has a balance, but if you ruin it, it takes revenge”). As the pandemic is considered a natural disaster, its potential to induce awe about nature, particularly threat-based awe, has also come to the fore. In the current study, we investigated whether the different types of awe would mediate the relationship between perceptions about nature (balance of nature and punitive nature) and support for pro-environmental policies. We conducted three correlational studies. We run Study 1 in Turkey (N = 1305), Study 2 in the U.S. (N = 212), and Study 3 in the U.K. (N = 600). Results showed that belief in natural balance was a stronger predictor of positive awe than threat-based awe. Belief in a punitive nature positively predicted threat-based awe. Only positive awe emerged as a significant mediator between perceptions about nature and policy support. In sum, this set of studies points out the importance of considering types of awe and their relationships with beliefs about nature in understanding attitudes toward environmental policies, especially during natural disasters.<br>
&nbsp;<br>
Title: <strong>Maternal and Preschooler Vocal Expression of Emotions</strong><br>
Poster Number: 16<br>
Authors: <strong>Gornik, Megan E; Soderstrom, Melanie; Reynolds, Kristin; Roos, Leslie</strong><br>
Abstract: Mothers and their children 3-4 years old were recruited to participate in a reading activity, where mothers read an emotion-focused story to their children (N = 24). This was followed by a brief conversation where mothers were asked to discuss five questions about the book with their children. These interactions were recorded and coded by trained research assistants, where maternal and child vocal affect was categorized and measured by overall maternal vocal affect, as well as how sad, frustrated, and happy they sounded. A correlational analysis found that the overall affect of children was significantly correlated with overall affect of mothers (r(22) = .48, p &lt; .05), happy affect of children was significantly correlated with happy affect of mothers (r(22) = .64, p &lt; .01), and sad affect of children was significantly correlated with frustrated affect of mothers (r(22) = .71, p &lt; .01). These findings demonstrate that the affect in which a mothers speaks is associated with the affect in which their children speaks, further suggesting mothers may have a significant emotive influence over their children. Mothers’ speech was also measured in total number of utterances as well as number of emotion-focused words spoken. A summary analysis showed that approximately half of the utterances mothers spoke were made up of emotion-focused words, suggesting a high level of conversation was based on discussing feelings. While these overall findings should not be interpreted as causal, these results may indicate the importance of maternal emotional expression when interacting with children.<br>
&nbsp;<br>
Title: <strong>Understanding Microexpressions: The Science of Detecting Hidden Emotions</strong><br>
Poster Number: 17<br>
Authors: <strong>Mishra, Riya; Bhushan, Braj; Venkatesh, K. S.</strong><br>
Abstract: Microexpressions are brief facial expressions that reveal true emotions, particularly in situations where individuals are trying to conceal them. Researchers and practitioners find these expressions valuable for gaining insight into hidden emotional states. Detecting microexpressions requires either manual approach or automated approaches. Manual detection involves trained observers who analyze high-speed video recordings, while automated detection uses computer software that analyzes facial movements. However, the relative advantages of these approaches are unclear. This study compares the effectiveness of manual and automated approaches in detecting microexpressions. The study characterized microexpressions by their brief duration, subtle facial muscle movements, and occurrence in response to emotional stimuli. The detection of microexpressions requires specialized training and equipment. Manual detection involves trained observers who analyze high-speed video recordings to identify microexpressions. Observers undergo specialized training to recognize microexpressions accurately, with the Facial Action Coding System (FACS) being a common approach to manual detection. Automated detection involves the use of computer software to extract, analyze facial movements and identify microexpressions. Result of this study discusses and compares the accuracy, efficiency of manual and automated approaches in detecting microexpressions. In conclusion, the study highlights the strengths and weaknesses of manual and automated approaches in detecting microexpressions. Researchers should consider these factors when choosing a detection method. A combination of both approaches may yield the most accurate results.<br>
&nbsp;<br>
Title: <strong>Subjective and Physiological Responses to Social Stress in Pre-Teens with Autism and Specific Learning Disorders</strong><br>
Poster Number: 18<br>
Authors: <strong>Lievore, Rachele; Maffei, Antonio; Sessa, Paola; Mammarella, Irene C.</strong><br>
Abstract: Children and adolescents with different neurodevelopmental disorders, such as Autism Spectrum Disorders (ASD) and Specific Learning Disorders (SLD), might experience emotional dysregulation during social-evaluative threat. Within an evolutionary framework, heart rate variability (HRV) has been described as a biomarker of social functioning. The aim of the study was to investigate subjective and autonomic responses towards social stress in youth with and without these conditions. The study involved 55 participants aged 10-16 years old divided into three groups: 15 with ASD, 15 with SLD, and 25 non-diagnosed (ND) matched peers. We asked participants to complete a social performance task adapted from the Trier Social Stress Test, during which we registered the electrocardiogram to measure psychophysiological responses (HR, RMSSD - a measure of HRV) across all phases of the protocol: baseline, preparation, public speech, recovery (i.e., phase). Participants were asked to report their subjective experiences (valence, arousal, perception of competence, worries) before and after the public speech. Linear mixed-effects models were run to examine the predictive role of phase, group, and phasegroup, on subjective and autonomic responses. Significant interaction effects of phasegroup resulted for valence, χ2(df=2)=6.66, p=.03 (ASD&gt;ND), perception of competence, χ2(df=2)=8.83, p=.01 (ASD&gt;SLD, ND), and HR, χ2(df=6)= 13.49, p=.03 (HR change: ASD&lt;SLD). Results also showed a trend towards significance for the effect of group for arousal, χ2(df=2)=5.51, p=.05 (ASD&lt;ND), and of phasegroup for RMSSD, χ2(df=6)= 12.28, p=.05 (baseline, recovery, change: ASD&lt;SLD). All in all, findings suggest that the three groups might experience unique subjective responses, and specific patterns associated with autonomic flexibility towards social stress.<br>
&nbsp;<br>
Title: <strong>Scraping Auditory Hate Speech from Social Media: A Comparison of Keyword-Based and Channel-Based Approaches</strong><br>
Poster Number: 19<br>
Authors: <strong>Rammohan, Rathi Adarshi; Rippe, Tabea; Puchała, Dominik Jakub; Swiderska, Aleksandra; Küster, Dennis; Schultz, Tanja</strong><br>
Abstract: Hate speech, defined as speech that incites, spreads, justifies hatred, discrimination or violence against specific individuals or groups poses a serious challenge to society. Despite increasing interest among researchers in the field of affective computing, almost all studies to date have used written contents (i.e., “hate text”), rather than spoken content aka “hate speech”. As automatic crawling and content moderation largely depend on text, this renders collecting genuine acoustic signals of hate speech from social networking sites (SNS) essential. We compared current keyword-based crawling for hate speech (7 hours of audio) from two SNS (YouTube, BitChute) with a more targeted channel-based approach (257 hours of audio). This latter approach focuses on the personal channels of individuals suspected of spreading hate speech included in a public listing (www.wikipedia.com). Our preliminary results for keyword-based crawling (7 days) revealed more hits on BitChute (8 out of 59 samples; 14%) than on YouTube (no hits), despite a much smaller overall volume of BitChute posts. However, in an initial balanced annotation (80 of 1290 videos) over 4 different personal BitChute channels, we identified hate speech in 54% of the examined auditory samples. We speculate that these results may reflect a consequence of hate speech posters learning to avoid certain keywords in the title and metadata of their posts. Going forward, we discuss how data-crawling could be improved through generating updated keywords from automatically transcribed auditory speech from channel-based approaches. We conclude with discussing implications and challenges of multimodal crawling for hate speech on the Internet.<br>
&nbsp;<br>
Title: <strong>Specific Social Emotions Predict Tennessee Healthcare Providers’ Responses to Patients with Opioid Use Disorder</strong><br>
Poster Number: 20<br>
Authors: <strong>Henniger, Nicole E.; Young, McKenna; Budesa, Zach; Luke, Chad</strong><br>
Abstract: Stigma research usually focuses on the general positive and negative feelings that individuals have towards the stigmatized group. However, examining specific emotions like shame, guilt, disgust, and contempt can provide unique information about appraisals and motivations. We surveyed a sample of mental and physical healthcare providers in the southern United States. The providers were asked about their thoughts, feelings, and motivations towards patients with Opioid Use Disorder, including specific emotions these healthcare providers felt when thinking about working with patients who use heroin. Consistent with theories about self-conscious emotions, healthcare providers’ shame (but not guilt) was uniquely associated with more negative cognitions such as moral disengagement and negative medical condition regard, as well as weaker recommendation of medication-assisted treatment and stronger perception of opioid addiction as being the result of moral failings. Comparing between two downward-facing social emotions, disgust and contempt, disgust was associated with much stronger negative attitudes and motivations. For example, greater disgust (but not contempt) was associated with lower support for medication-assisted treatment and less willingness to accept a patient who used heroin to be scheduled at their healthcare practice. Although pity can be considered a prosocial emotion, pity was one of the strongest and most consistent predictors of stigmatizing beliefs. Such a negative pattern is consistent with Fiske’s Stereotype Content Model, which conceptualizes pity as prejudice towards groups with low perceived competence. These findings provide a unique test of specific emotion theories in an applied context with implications for stigma reduction efforts.<br>
&nbsp;<br>
Title: <strong>The Role of the Body in Altered Facial Emotion Perception in Autism and Social Anxiety</strong><br>
Poster Number: 21<br>
Authors: <strong>Folz, Julia; Nikić, Kristina; Nikolic, Milica; Kölkebeck, Katja; Kret, Mariska</strong><br>
Abstract: Alterations in the perception of facial emotional expression and their physiological resonance, as well as in accurately sensing bodily states (i.e., interoception), have been reported in both individuals on the autism spectrum and individuals with social anxiety. Yet, despite the rise of embodied perspectives on emotion processing, past studies have mostly investigated them separately. In the current study, we aimed to examine the association between physiological responses, their sensation, and facial emotion perception in the two clinical conditions and neurotypical, healthy controls. Individuals on the autism spectrum (N = 40), with a diagnosis of Social Anxiety Disorder (N = 27) and with no psychiatric or neurodevelopmental condition (N = 40) first passively viewed short videos of spontaneous facial expressions (anger, happiness, sadness, fear and neutral) while facial muscle responses over the Corrugator supercilii and the Zygomaticus major regions, as indicator of facial mimicry, and skin conductance, as indicator of emotional arousal, were recorded. In a separate task, the same emotional expressions were judged regarding the presented emotion category, the confidence in the accuracy of this judgment, and the intensity of the observed emotional experience. Perceived emotional intensity was more strongly linked to physiological arousal in individuals with social anxiety compared to controls for sadness displays, and less strongly linked to congruent facial muscle activations to anger displays in individuals on the autism spectrum. Differences in self-reported interoception seemed to play a role in the latter link, suggesting alterations in sensing and integrating embodied emotions in autism.<br>
&nbsp;<br>
Title: <strong>Novel Emotion Regulation Training to Reduce Contingent Self-Worth and Improve Mental Health in Daily Life</strong><br>
Poster Number: 22<br>
Authors: <strong>Lopez, Richard; Hayes, Nicole; Nephew, Benjamin; King, Jean; Roemer, Lizabeth; Dixon-Gordon, Katherine; Boudreaux, Edwin</strong><br>
Abstract: Rates of depression and anxiety among young people have been steadily increasing worldwide, with the COVID-19 pandemic further exacerbating these trends. This led the US Surgeon General to declare a youth mental health crisis in December, 2021. Some research indicates that social media use has contributed to young people’s poor mental health, but reviews and meta-analyses have revealed that associations between social media use and mental health and wellbeing are weak and inconsistent at best. Thus, emotion researchers may benefit from examining psychological risk factors associated with social media use that might predispose someone to be at greater risk for developing anxiety disorders and depression in the first place. Contingent self-worth (CSW), which describes situations in which a person’s self-esteem is easily impacted—in both positive and negative ways—by various factors (e.g., others’ approval, family relationships, academic performance, etc.) may be an important, understudied risk factor. Here, we will discuss findings from an emotion regulation training study that adapted aspects of Acceptance and Commitment Therapy, specifically values articulation, in order to target approval-related CSW as experienced on social media and reduce daily anxiety and depression symptoms. We also will unpack brain mechanisms that underlie training efficacy, specifically functional connectivity between the ventral striatum and medial prefrontal cortex, which may reflect more positive self-appraisals and altered CSW rooted in self-endorsed values and thereby less susceptible to external influences (e.g., others’ approval). We will conclude with future directions and policy implications of this novel approach to emotion regulation training.<br>
&nbsp;<br>
Title: <strong>Let’s Talk About Mindfulness: Assessing Mindfulness in Adolescents: A Polish Validation of the Child and Adolescent Mindfulness Measurement (CAMM)</strong><br>
Poster Number: 23<br>
Authors: <strong>Wasylkowska , Maria Anna; Kobylińska, Dorota; Holas, Paweł; Mituniewicz , Julian</strong><br>
Abstract: Mindfulness-based programs for adolescents have lately become popular all over the world. Research already shows that these types of interventions result in positive effects on both mental and physical health. Mindfulness practice is considered emotionally, socially and academically beneficial for adolescents delivering lasting improvement in well-being. Since number of interventions and research on it is rapidly increasing, there is a need for valid and reliable measurements of mindfulness skills in adolescents. The CAMM is a single-factor self-report measure developed to asses present-moment awareness, non-judgmental and no avoidant responses to thoughts and feelings. The present study was checking the theoretical validity of the questionnaire in the sample of Polish adolescents aged 12 to 15 years (N = 325). Correlations with measures of suppression and psychological inflexibility were calculated as well as correlations with measures of psychological well-being and general health. Similarly, to original validation study, the following tools were used: The White Bear Suppression Inventory (WBSI), Avoidance and Fusion Questionnaire (AFQ), Warwick Edinburgh Mental Well Being (WEMBWS), General Health Questionnaire (GHQ-12). Overall, results suggest that CAMM is theoretically valid in the Polish group of adolescents. Mindfulness correlated positively to well-being and negatively to thought suppression, psychological inflexibility and health problem symptoms, which suggests that mindfulness is an adaptive skill.<br>
&nbsp;<br>
Title: <strong>Disgust and Pain: If you can Tolerate the Pain, Do you also Tolerate the Gross?</strong><br>
Poster Number: 24<br>
Authors: <strong>Skolnick, Alexander J</strong><br>
Abstract: Disgust and pain are both unpleasant responses to stimuli that are typically threatening. Pain signals potential immediate harm and disgust signals potential threat of contamination and/or disease. Research also finds similar gender effects with men responding with lower disgust and lower pain than women. We hypothesized individual differences in both disgust and pain responses, such that disgust responsiveness (touching disgust-evoking items) would be negatively correlated with pain measures of threshold and tolerance (lower scores indicate more pain). Additionally, we tested whether a measure of emotional control (ATEE, Attitudes Toward Emotional Expression) predicted both disgust and pain responsiveness. 82 (48M,34W) participants were first tested on standard cold-pressor task, recording first vocalized pain (Threshold) and hand removal from icy water (Tolerance). Afterward, disgust ratings obtained (Mean-combined disgust ratings) for 4 disgust-evoking objects. Surprisingly, significant gender differences only found for disgust measures, not for pain. As predicted, a negative relationship between Mean-combined and mean Pain Tolerance (r=-.31, p&lt;.004) was significant; but not for Threshold. The ATEE was significantly correlated with both Pain Threshold (r=.260, p=.019) and Tolerance (r=.320, p=.003) suggesting the more control over one’s emotions the better pain control. However, ATEE was unrelated to any disgust measure. A linear regression confirmed Mean-combined disgust (beta=-.279, p=.008) and ATEE (beta=.285, p=.007) as negative and positive predictors of mean Tolerance, respectively. Correlations among evoked disgust and pain measures suggest similar underlying psychological mechanisms. Those who reported higher disgust exhibited lower pain tolerance. Emotional control might be an important factor in pain (and disgust?) responsiveness.<br>
&nbsp;<br>
Title: <strong>Children Dancing for Social-Emotional Skills: A Mixed Methods Study</strong><br>
Poster Number: 25<br>
Authors: <strong>Stutesman, Megan; Goldstein, Thalia</strong><br>
Abstract: Childhood engagement in the arts has been connected to improved social-emotional skills. However, connections between childhood dance engagement and a critical social-emotional skill, affective theory of mind (AToM), has not yet been studied. AToM is the ability to read and understand others’ emotions. In this study, we examine connections between childhood dance participation and AToM using a longitudinal mixed-methods study. In the quasi-experimental quantitative strand, children aged 7-12 years old in the dance group (N = 65) participated in one academic year of dance and were compared to a treated control group (N = 47) who participated in one academic year of sports. Children were assessed pre- and post- on quantitative measures of facially-cued, bodily-cued, and contextually-cued AToM. In the qualitative strand, dance teacher interviews (N = 17) and child and parent open ended responses (N = 65) were thematically coded. Preliminary results suggest that overall, dance training was related to better performance for bodily-cued AToM (p’s &lt; 0.05) but not for facially-cued or contextually-cued AToM (p’s &gt; 0.05). Qualitative emergent themes suggested that dance education can improve body-focused AToM because it provides a coached embodied practice of expressing and deciphering emotions and provides children a safe space to practice social-emotional skills. This is the first study, to our knowledge, to empirically examine the relationship between childhood dance engagement and AToM development as well as elucidate processes within dance education that might support this emotion-related skill growth. Results may inform how dance may be another avenue for childhood social-emotional intervention.<br>
&nbsp;<br>
Title: <strong>Vocal Emotional Expression in Parkinson’s Disease: Roles of Sex and Emotions</strong><br>
Poster Number: 26<br>
Authors: <strong>Gnerre, Martina; Biassoni, Federica</strong><br>
Abstract: Gendered vocal expressions of fear, anger, sadness and happiness were investigated for mild to moderate Parkinson’s disease (PD). Prosodic features (related to fundamental frequency (F0), intensity (I) and time domain) and acoustic correlates of voice quality (CPPS, jitter, shimmer and HNR) were collected from 14 patients with PD (mean age = 69.93; SD = 7.12; 8 males, 6 females) and 13 healthy controls (HC) (mean age = 68.13; SD= 8.27; 5 males, 8 females) matched for age, sex, and years of education. The utterances were extracted from four emotional and one neutral text. The neutral utterance and the emotional utterances were compared. Intra-sex comparison (female with PD vs female HC and male with PD vs male HC) and inter-sex comparison (female with PD vs male with PD) were performed with the Mann-Whitney test. A Mann-Whitney test was also used to compare the different emotional conditions, considering sex and diagnosis as well. No significant intra-sex differences were found for the neutral speech but inter-sex differences emerged. Regarding emotional speech, females with PD featured lower MaxF0 than female HCs for happiness and higher intensity variability (SD I) for sadness. Utterances by females with PD had lower CPPS than utterances by HCs for anger and fear. Utterances by males with PD had lower minimum intensity (MinI) than utterances by male HCs when expressing fear. PD emotional vocal expression proved impaired and differs by sex. Such findings may have a big impact on the quality of life of patients with PD.<br>
&nbsp;<br>
Title: <strong>Emotional Injustice: Emotion Policing</strong><br>
Poster Number: 27<br>
Authors: <strong>Pismenny, Arina</strong><br>
Abstract: Emotion policing is a form of emotional injustice that occurs when efforts are made to distort the nature of the emotions that an individual or a social group is disposed to have, or the ways those emotions are expressed. It is often an attempt to establish or maintain an oppressive emotion norm, i.e., when specific people are expected to have specific emotions in specific circumstances. Emotion policing can take several forms, including Emotion Stereotyping, Emotion Display Suppression, and Emotion Hegemonizing. The talk will analyze these forms of emotional injustice, delineating their application to marginalized groups, as well as sketch possible paths to resisting these forms of oppression.<br>
&nbsp;<br>
Title: <strong>Employing a Speech Act Framework to Examine the Negotiation of Deontic Authority During Episodes of Conflict in Acute Adult Mental Health Wards</strong><br>
Poster Number: 28<br>
Authors: <strong>Fallon, Roisin; Deamer, Felicity; Brew, Benjamin; Lavelle, Mary</strong><br>
Abstract: Deontic authority is the idea that one person has the ‘power’ to make decisions or bring about consequences for the other person (Lukes, 1978). Patient safety is a priority in mental health inpatient settings and as such, it is often necessary for staff to have deontic authority over the patients they care for. Indeed, a high percentage of service users on mental health wards are admitted involuntarily under the mental health act, making the deontic authority of staff explicit. Service users within these situations may display behaviours of agitation, frustration, distress, or conflict. Healthcare staff attempt to diffuse escalating behaviours through verbal and non-verbal communication, known as de-escalation. However, we know little about how this occurs in practice, or the impact of staff communication strategies on the outcome of these interactions. The aim of this study is to explore how staff communicate to negotiate their deontic authority during incidents of de-escalation in real world settings. We will also examine the relationship between their approaches and de-escalation success. De-escalation success has been operationalised as halting the sequence of conflict for that service user avoiding the need to use restrictive practices such as restraint (held to limit movement), seclusion (locked in isolation) and rapid tranquilisation (involuntarily injected with psychotropic medication). Methods: De-escalation incidents (n=46), involving a service user and one (or multiple) members of staff, on acute adult mental health wards are being recorded using body cameras worn by staff. Analysis Staff communication will be annotated in ELAN, providing a behavioural time series that can be exported for statistical analysis. A speech act coding framework, specifically developed for this context, will be applied to the transcriptions. The relationship between specific speech acts (as well as the degree of direct or indirectness) and de-escalation success will be examined. Results Analysis of this data is currently underway and the findings will be presented. We hope to identify patterns of staff communication that can enhance agency of service users, despite the disempowering context. References: Lukes, S. 1978. “Power and authority”. In A history of sociological analysis, Edited by: Bottomore, T. and Nisbet, R. 633–676. London, , England: Heinemann.<br>
&nbsp;<br>
Title: <strong>Towards a Collective, Theory-Agnostic, and Loosely Structured Database of Componential Emotions</strong><br>
Poster Number: 29<br>
Authors: <strong>Fritz, Mattia A.</strong><br>
Abstract: Componential theories posit that emotion elicitation and differentiation result from the synchronization of several subsystems such as cognitive, motivational, physiological, motor expression, and experiential. Theories differ, though, in (1) the nature of the synchronization, such as causal, associative, or connectionist (Barrett, 2017; Scherer, 2019; Suri &amp; Gross, 2022); and (2) the kind of components and features within them (e.g.&nbsp;evaluative criteria, lexicalized emotions). Attempts to characterize emotions with componential profiles must therefore face the sheer number of possible combinations. For instance, the GRID system (Fontaine et al., 2013) provides 142 columns-like features shared by every row representing a discrete emotion. A rectangular data representation, though, forces a profile that is difficult to fit and scale to a wide variety of emotion structures. It may thus be worth investigating the feasibility and interest for a collective, theory-agnostic, and loosely structured database of componential emotions in which entries can leverage on more flexible data structures provided by NoSQL databases. These structures present the following advantages: (1) entries don’t have to provide the same number or kind of components and features; (2) the structure can be nested, for components to be sub-organized in more fine-grained criteria, including multiple and alternative options; and (3) entries can be augmented by multi-modal features such as images, videos, or sounds. The many potential applications of the database include measures of distance/similarity between emotions, computable both from the structure and values of entries, or complex queries adopted to retrieve richer profiles from partial inputs.<br>
&nbsp;<br>
Title: <strong>Investigating the Temporal Unfolding of Facial Muscle Responses of Emotion and Regulation</strong><br>
Poster Number: 30<br>
Authors: <strong>Gentsch, Kornelia; Dietrich, Anya; Kaiser, Sarah; Tüscher, Oliver; Wessa, Michèle</strong><br>
Abstract: Effects of emotion elicitation and regulation unfold dynamically over time. However, research usually investigates these two processes separately. Whether this approach leads to conclusive results is highly debated (cf.&nbsp;Kappas, 2011). Thus, we investigated the time course of facial muscle responses of emotion and regulation in a standard emotion regulation paradigm (e.g., Schönfelder et al., 2014) in which the information of required regulation (viewing vs.&nbsp;reappraisal vs.&nbsp;distraction) was presented first followed by the emotion (negative vs.&nbsp;neutral pictures). Facial electromyography was recorded over corrugator and zygomaticus regions. Data (N=105) were analyzed time-locked to emotion-stimulus onset. We predicted that separate processes would reveal first an emotion main effect followed by a regulation main effect. As predicted, over the corrugator region, the first emotion main effect was found at 300 ms after emotion-stimulus onset; whereas emotion regulation had only marginally significant effects at 1100 ms. Over the zygomaticus region, at 1700 ms a first significant emotion main effect was found; no other significant effects emerged. The results support the idea that emotion is processed first, and subsequently regulation. The absence of an interaction effect needs further investigation.<br>
&nbsp;<br>
Title: <strong>Understanding Children’s Accuracy in Recognizing Facial Expressions of Pain</strong><br>
Poster Number: 31<br>
Authors: <strong>Michaud, Mylène; Gallant, Adele; Savoie, Erica; Perron, Mélanie; Roy-Charland, Annie</strong><br>
Abstract: Facial expressions of pain have an adaptive function in informing others of the need of attention and care. The detection of these nonverbal cues is particularly important in children since they are not always capable of expressing their needs verbally. Nevertheless, research recurrently shows that distinguishing between genuine, suppressed, and simulated pain expressions produced by children is a difficult task for adults; even when their professions require such a skill (e.g., doctors or nurses). Only a few studies have explored the development of this specific ability amongst children’s peers. The current study aims to fill this literature gap by exploring children’s ability to recognize and judge genuine, simulated, and suppressed expressions of pain produced by other children their age. Seventy-nine children from kindergarten to fourth grade viewed videos in which children encoders expressed the three aforementioned types of pain while plunging their hand in cold or warm water. Participants were asked to select the type of pain that was expressed. They were also asked their level of confidence in their answer and the level of pain they thought the children were experiencing. Despite having a high level of confidence in their answers, kindergarteners had a significantly lower proportion of correct answers compared to children in third and fourth grade. Furthermore, regardless of their grade level, children were better at recognizing suppressed pain expressions and had lower performance rates for genuine pain recognition. Our overall findings revealed an improvement in children’s performance with aging.<br>
&nbsp;<br>
Title: <strong>“i Don’t Like this Positive Colour” but Why?</strong><br>
Poster Number: 32<br>
Authors: <strong>Jonauskaite, Domicele</strong><br>
Abstract: Links between colour and emotion are systematic and cross-culturally stable. For instance, lighter colours as more positive and darker colours as more negative. Then, yellow, pink, and most other colour categories are linked to positive emotions, while black, grey and brown are linked to negative emotions. It is thus not surprising that researchers and the public more widely assume that positive colours are liked, while negative colours are disliked. Indeed, the most prominent theory of colour preferences – the Ecological Valence Theory (EVT, Palmer &amp; Schloss, 2010, PNAS) explained colour preferences through valence associations with coloured objects. Yet, there are inconsistencies that do not fit this proposition, most notably yellow, pink, blue and black. The former two are largely disliked but carry positive connotations, while the latter, in particular blue, are liked a lot but have some negative connotations. We question where such discrepancies between affective connotations and preferences come from. Here, I reason that colour preferences are rooted in aesthetic pleasantness while colour-emotion associations are rooted in conceptual associations. In other words, colour preferences are based on a very basic arousal/motivation system, being thus more individual, while colour-emotion associations are based on a conceptual system, which is likely shared across people. Colour is not an exception in this regard, similar discrepancies have been reported for music and odours. Overall, understanding relationships between the different types of affect (here, emotion associations and preferences) might shed light on other domains in the affective science.<br>
&nbsp;<br>
Title: <strong>Assessing How Social Signals Differ Between Naturalistic and less Naturalistic Contexts</strong><br>
Poster Number: 33<br>
Authors: <strong>Doran, Gerard; Pereira, Monica</strong><br>
Abstract: Emotions have been traditionally examined in a third-person context with emotions being induced by stimuli presented from a monitor. These approaches are usually non-naturalistic in design, observing participants simultaneously viewing stimuli without them interacting with each other. Second-person approaches on the other hand, have been utilised to investigate the social interactions between individuals and whether this has an impact on social signals processing. Our research is interested in the differences in neural signal when participants interact with each other in a naturalistic way versus neural signal generated from viewing the same stimuli. We are interested in whether classification approaches such as convoluted neural networks differ when they are trained using EEG signals obtained in naturalistic interactions versus inducing them through stimuli from a monitor. We are currently recruiting participants for an EEG-hyperscanning study where participants will perform an emotion recognition paradigm to induce discrete emotions, as well as a naturalistic interaction where participants will discuss experiencing emotions with the neural signal of the listener in this interaction examined. We will then apply machine-learning classification methods to these differing data types and assess the validity and classification accuracy from either approach. The data collected will be used to develop an emotionally intelligent avatar that is more naturalistic based from this emotional classifier with improved human-agent interactions from increased empathy and trust. This research will hopefully demonstrate key differences in neural signals between naturalistic and non-naturalistic conditions and highlight how social signal processing differs between conditions.<br>
&nbsp;<br>
Title: <strong>When I Think About Your Reaction to Pain: Theory of Mind Informed by Embodiment or Perceived Closeness?</strong><br>
Poster Number: 34<br>
Authors: <strong>Gupta, Hritik; Singh, Varsha</strong><br>
Abstract: This study delves into shared pain perception, investigating how individuals distinguish between their own pain and that of others, grounded in the theory of mind. The research posits that emotional embodiment results in similar pain perception for oneself and others, with a particular focus on the influence of perceived closeness between individuals in such processes. All participants (N = 102) underwent a pre-experimental mood assessment (PANAS-SF) and reported their relationship closeness to a friend (the “other” was contextualised in the study by asking participants to think of a friend) using the unidimensional relationship closeness scale (URCS). Further, each participant viewed and rated pain and neutral stimuli images (taken from the International Affective Picture System or IAPS) in a 2 x 2 [stimuli type (pain, neutral) x rating type (self, friend)] block design for the three parameters of valence (unhappy-happy continuum, 9-point Likert scale), arousal (calm-excited continuum, 9-point Likert scale), and confidence (not confident-highly confident continuum, 9-point likert scale). Results revealed no significant difference (t = -0.455, p = 0.649) for the self and other (friend) ratings for pain stimuli images given by participants, underscoring the significance of self-embodiment in estimating pain affect for others. Perceived closeness and valence differences (self valence - friend valence difference) exhibited a mild negative correlation (r = -0.25, p = 0.01), emphasizing the role of perceived closeness in pain affect processing for self and others. Furthermore, participant age and gender moderated the relationship between valence ratings for self and other (friend) ( p &lt; 0.05). Overall, the study explores the pivotal role of embodiment and perceived closeness in shaping theory of mind regarding affect processing for pain for self and other.<br>
&nbsp;<br>
Title: <strong>openVIMO: An Open Platform for Video-Based Interactions and Monitoring in Online Studies</strong><br>
Poster Number: 35<br>
Authors: <strong>Dudzik, Bernd; Vargas Quiros , Jose; Matej Hrkalovic, Tiffany; Balliet, Daniel; Hung, Hayley</strong><br>
Abstract: Video-based online interactions have proven advantageous for collecting data on human socio-emotional interactions, allowing for effective recruitment of diverse study participants and scalability without needing specific facilities. However, the common practice of using ad hoc solutions, such as combining off-the-shelf video conferencing software with surveys and manual participant management, introduces challenges. These challenges include the cumbersome and time-consuming adjustment of methods for specific study purposes, potential privacy risks from relying on cloud-based tools, the necessity of special software installations by participants, and limited customization options. Given these challenges, we present “openVIMO,” a software platform for conducting video-based online interaction experiments built on open-source technologies. It can be deployed on a server under a researcher’s control without relying on additional commercial third-party services. Concretely, it enables (1) the creation of web-based experiments and surveys involving video calls between participants, as well as (2) the remote monitoring of participants’ progress throughout a study, including means for communication and intervention throughout a protocol. Moreover, openVIMO facilitates (3) collecting and storing survey and interaction data (incl.&nbsp;audio and video). Finally, the platform has been designed to (4) allow the staging of highly customized experimental protocols and to be dynamically expanded by the research community. We propose that openVIMO can contribute to studying human socio-emotional interactions at scale, addressing both existing practical limitations and contributing to responsible data collection practices. To this end, we reflect on its design rationale and development, especially highlighting experiences gained from developing a prototype for a previous large-scale online study.<br>
&nbsp;<br>
Title: <strong>Recognizing Facial Expressions of Emotions Made by Seniors While Controlling their Mental State</strong><br>
Poster Number: 36<br>
Authors: <strong>Jasielska, Aleksandra; Patalas, Daria</strong><br>
Abstract: Facial expressions are a universal and innate nonverbal signal that individuals use to communicate their emotional states. It is an essential aspect of social interactions as it allows for interpreting other people’s experiences. Although many studies are conducted on the cultural, social, and individual determinants of emotion recognition skills, only a few focus on seniors. Moreover, most research focuses on the facial expression of basic emotions. We conducted two studies investigating how seniors recognise facial expressions of complex emotions. In study 1, we aimed to verify whether Alzheimer’s Disease (AD) patients of an institution in Poland (N = 46; 50% women; Mage = 73) would display higher difficulties concerning emotion recognition ability due to deficits resulting from progressing disease in comparison to the healthy elderly without mental disability (N = 46; 51% women; Mage = 72.7). We studied using the Emotional Intelligence Scale-Faces (EIS-F). The study’s results indicated that patients suffering from early stages of AD performed significantly lower facial emotion recognition (t = -1.83, df = 90, p &lt; 0.001, AD group: M = 59.50; healthy group: M = 63.8). In study 2, we wanted to assess the impact of mental ability on recognising mimic expressions of complex emotions. The participants (N = 122; 70% women; Mage = 73.5) were tested by Mini-Mental State Examination (MMSE) and EIS-F. The outcomes showed that age and education were better predictors of facial emotion recognition than mental ability, that both older men and women recognised emotions equally well, and that the best-recognised feeling was delight expressed by the woman. The worst-recognised emotion was the hostility triad represented by a man. The data would be interpreted as a polarization of biological against mental ageing, positive-negative asymmetry, and socioemotional selectivity theory.<br>
&nbsp;<br>
Title: <strong>The Role of Encoder and Decoder Personality Traits in Smile Judgment</strong><br>
Poster Number: 37<br>
Authors: <strong>Cloutier, Karolyn; Belliveau, Adèle; Gallant, Adele; Carruthers, Calvin A; Roy-Charland, Annie</strong><br>
Abstract: The effect of context on basic emotion recognition is well documented. However, fewer studies have explored its effect of smile sincerity judgements. Furthermore, no study has explored the interaction between the personality traits of individuals and the judgment of Duchenne and non-Duchenne smiles, nor the interaction between context associated with the encoders and individual differences of the decoders. The goal of the present study is to observe the effect of personality traits of decoders, using the HEXACO-60 questionnaire, in the judgment of the sincerity of smiles while contexts associated with the encoder personality traits are presented. 200 participants read a paragraph related to the encoder’s personality traits, either from the positive or negative pole of the trait. After judging the sincerity of Duchenne and non-Duchenne smiles on a 7-point scale, participants proceeded to complete the HEXACO questionnaire. Simple regressions and equivalence test analyses suggested that personality traits of the decoders are not significant predictors of smile judgment responses. There is also no significant relationship between the personality traits of the decoders and the personality traits of the encoders. Machine learning techniques (variable selection using random forests) showed relevant avenues regarding the influence of individual variables in the judgement of smiles, particularly for the honesty-humility and emotionality traits of the decoders. However, the type of smile and the valence of the context appeared to be the most important factors in predicting smile judgment.<br>
&nbsp;<br>
Title: <strong>Emotion Components and Brain Networks: a Video Game Paradigm Testing Expectation and Uncertainty</strong><br>
Poster Number: 38<br>
Authors: <strong>Nonni, Martina; Vuilleumier, Patrik</strong><br>
Abstract: The nature and generation of emotions and emotion episodes remain subjects of ongoing debate in the literature, but prevailing theories seem to suggest their multicomponent nature. This project aims to link multiple components of emotions to functional brain systems by developing and validating a novel procedure to actively elicit emotions in a naturalistic and dynamic manner. Drawing inspiration from appraisal models of emotion causation, we designed a first-person perspective, interactive videogame task to be experienced in virtual reality, which will be used to assess emotion components and brain networks. In the current iteration, we are manipulating uncertainty and expectation appraisals, influencing in-game gains and losses. Upon validation, the task will be integrated with fMRI to explore the effects of manipulating expectation and uncertainty appraisals on respiration, heart rate, skin conductance, and brain responses. The primary goal is to observe their impact on emotion causation, brain networks, and determine whether patterns of multicomponent responses can predict discrete emotions. We predict that different manipulations will be reflected in different elicited emotions, functional brain patterns and physiology patterns. This research aims to contribute valuable insights into the intricate interplay between emotions, their elicitation processes, and underlying neural mechanisms.<br>
&nbsp;<br>
Title: <strong>School Performance of Autistic Children: The Role of Socio-Emotional Skills</strong><br>
Poster Number: 39<br>
Authors: <strong>Costa, Andreia P.; Franco, Maïte</strong><br>
Abstract: Autistic children, particularly those with average or higher IQ, often have worse school performance than expected given their cognitive abilities. Research with neurotypical children shows that, among other factors, difficulties with emotions are linked to impairments in cognitive processes, which lead to poorer school performance. Autistic children often have emotional difficulties, and these difficulties may play a role in their school performance too. In the present study, we compared 21 autistic children to 18 neurotypical children aged 6 to 14 years old, with similar IQ and socio-economic status (SES), regarding their school grades, and their parent-reported social communication skills, emotion regulation, and alexithymia. We found that compared to neurotypical children, autistic children had lower school grades, lower social communication skills, lower emotion regulation skills, and more alexithymia. Hierarchical regression analyses revealed that not being autistic, having a higher SES, having lower social communication skills, and having lower alexithymia were significant predictors of higher school grades. IQ and emotion regulation skills were not significant predictors. These results suggest that some aspects of emotional ability like having low alexithymia may indeed significantly contribute to explain the school success of autistic children beyond their diagnosis, IQ, and SES. However, surprisingly, social communication skills seem to have a negative relation, with more social skills being indicative of lower school grades. Furthermore, emotion regulation skills did not contribute to predict academic success.<br>
&nbsp;<br>
Title: <strong>Differential Habituation to Positive and Negative Stimuli: Implications for Disgust Research and Practice</strong><br>
Poster Number: 40<br>
Authors: <strong>Quinlan, oksana; Kron, Assaf</strong><br>
Abstract: Introduction: The attenuation of response to repeated stimuli is termed ‘habituation’, and it is considered the most primitive form of learning. The goal of the study is to examine whether habituation can generalize based on semantic knowledge, to the entire category of the object. In two experiments, we asked whether affective habituation occurs for perceptual, conceptual and/or affective properties of the stimulus. Methods: Participants were repeatedly presented with an affective image, followed by a set of test images that shared perceptual, conceptual, or affective properties with the repeated stimulus. Results: habituation across different components of the emotional response (self-reported feelings, facial expressions) was generalized up to the conceptual level of the repeated stimulus for pleasant, but not for unpleasant stimuli. Conclusions: The findings of the present study are discussed in relation to disgust research by highlighting differences in habituation of pleasant and unpleasant stimuli.<br>
&nbsp;<br>
Title: <strong>Emotion Labels Modulate Prediction Error Response in Pre-Attentive Pre-Attentive Facial Emotion Processing: Evidence for the Role of Verbal Labels in Predictive Coding of Emotion Perception</strong><br>
Poster Number: 41<br>
Authors: <strong>Yang, Hyeonbo; Lee, Donghoon</strong><br>
Abstract: The theory of constructed emotion (TCE, Barrett, 2017) describes how language can play a key role in emotion perception based on the predictive coding view. However, there is a lack of empirical evidence showing whether language influences emotion perception in terms of immediate predictive processing. To investigate the effect of emotion labels on the predictive processing of facial expressions, we used passive oddball task and visual mismatch negativity (vMMN) ERP component interpreted as prediction error (PE) signal. In study 1, participants responded to the emotion labels (“Happiness,” “Anger,” or “Shape”) as target amid repeated presentations of fixation cross. In Study 2, participants responded to target animal labels amid repeated presentations of either “Happiness,” “Anger,” or “Shape” label. In both studies, task-irrelevant standard (Study 1: happy-angry morphed face; Study 2: neutral face, about 80% of the trials) or deviant (happy or angry face, about 10% each) stimuli were presented in the background of repeated stimuli. VMMN was obtained by subtracting the ERP elicited by standard faces from that elicited by happy or angry deviant faces. The convergent results of Studies 1 and 2 showed that when emotion label and facial expression were incongruent, a greater amplitude of vMMN was evoked in occipito-temporal electrodes compared to congruent or irrelevant conditions. These results suggest the possibility that prior expectation activated by emotion labels does not significantly affect predictive processing when it matches the sensory input but increases prediction error responses when it does not match. These results suggest that prior expectation activated by emotion labels increases prediction error responses when it does not match the sensory input.<br>
&nbsp;<br>
Title: <strong>“This Pandemic Challenged Our Oath to the Public”: Feeling Rules and Rule-Breaking in the Context of Nursing During Covid-19</strong><br>
Poster Number: 42<br>
Authors: <strong>Cottingham, Marci</strong><br>
Abstract: Through the Nightingale oath, nurses affirm their devotion to the wellbeing of those committed to their care. As a profession, nursing emphasizes compassion and care and with this comes taboos on anger and aggression. Hochschild was the first to identify “feeling rules” in association with particular occupational roles. The professional “feeling rules” of nursing were reinforced in the collective framing of nurses as heroes during the COVID-19 pandemic, with their stories and struggles catalogued copiously by major news outlets. The unprecedented nature of the pandemic, however, raises questions about the durability of professional feeling rules during times of crisis. Using a sample of 21 diaries from U.S. nurses during the first year of the pandemic (May 2020 – January 2021), we examine the role of feeling rules and rule-breaking among this emotionally-restricted profession during the crisis. We ask: how were feeling rules upheld, resisted, or reframed by nurses during the pandemic? We find evidence of some emotional rule-breaking in the form of rage and anger directed at diverse sources (the public, nurse managers, and hospital policies), but the majority of nurses used metaphors, references to “frustration” or “strong feelings,” or softened their anger discourse to manage these feelings in real time. We also identify feelings of disorientation, numbness, routinization to manage fear, and a range of negative and positive emotions. Diary methods are particularly well-suited to capturing the situated, dynamic, and complex nature of emotions, including taboo emotions, within a profession facing an unprecedented crisis.<br>
&nbsp;<br>
Title: <strong>How is State Awe Different from Interest and Curiosity?</strong><br>
Poster Number: 43<br>
Authors: <strong>Goclowska, Malgorzata A; Noordewier, Marret</strong><br>
Abstract: According to Izard (1977) awe might be an intense variant of interest that motivates curiosity and exploration. However, recent work shows that state awe (vs.&nbsp;interest) is linked to a greater appreciation of present circumstances, a greater sense of smallness, and a lesser sense of exploration (Campos et al., 2013), and that it broadens attentional scope on a global-local attention processing task (Sung &amp; Yih, 2015). To directly compare how awe (NS1 = 56, NS2 = 67) differs from interest (NS1 = 68, NS2 = 66) and curiosity (NS1 = 68, NS2 = 61), we reanalysed data from our recent paper (in press) in which 6 emotions were manipulated through retrospective recall. While the original paper compared awe to the mean of 5 other epistemic emotions, here, using simple contrasts, we compared awe directly to interest and to curiosity. Across both studies we found that awe (vs.&nbsp;interest and curiosity) was less likely to arise when the situation contained insufficient information, and was more likely to arise when the situation exceeded one’s expectancies. Awe (vs.&nbsp;interest and curiosity) was also linked to a greater sense of smallness, and awe was higher in positive valence when compared to curiosity, but not when compared to interest. Finally, we uncovered no significant differences for action tendencies (exploration and avoidance).<br>
&nbsp;<br>
Title: <strong>Racialised Emotions and Research Methodology</strong><br>
Poster Number: 44<br>
Authors: <strong>Cohen, Rae-Anne</strong><br>
Abstract: This oral presentation seeks to explain the unique methodology used in my PhD study exploring racialised emotions amongst Black students in an elite British university. In the context of Equality, Diversity and Inclusion (EDI), racial equity policies and mental health concerns within higher education, understanding the emotional experiences of racially marginalised communities within the university is imperative. This research not only adds to growing literature around these topics but also joins scholarly works around emotion and affect into the discussion. However, researching emotions from a sociological lens lacks an established methodology for best practice. Therefore I intend to discuss the varying opinions around researching emotions with a strong emphasis on Black feminist thought which has provided valuable insight into emotions experienced by racialised minorities for the purpose of this study. I will then proceed to delve into my own study exploring the different methods chosen and justifying their uses. The research methods chosen for this study are: semi-structured interviews; walking observations; creative methods; and focus groups. By drawing attention to the methodology, I seek to increase knowledge and understanding of emotion and affect that can be applied in differing sociological contexts as well as provide practical implications for promoting a stronger sense of belonging and personal well-being for Black students in higher educational environments.<br>
&nbsp;<br>
Title: <strong>Alone with My Thoughts: Using Natural Language Processing to Distinguish Lonely from Calm Aloneness</strong><br>
Poster Number: 45<br>
Authors: <strong>Lay, Jennifer C</strong><br>
Abstract: Time spent alone is common in daily life, and particularly in old age; it may at times be experienced as lonely, and at times as calming (positive solitude). The use of machine learning to interpret human language (e.g., natural language processing or NLP) has been growing in psychology, and NLP has been used to distinguish experiences of loneliness from positive solitude in social media data (e.g., tweets). How effective might such NLP techniques be for classifying naturally-occurring aloneness experiences in older adults’ everyday lives? The present study uses 1,546 thought samples collected from 133 adults aged 18-85 (M = 49.6 years; 73% female) at moments when they were alone over a 1-3 week period; participants reported their current thoughts (open-ended) and affective states (lonely, calm) at each assessment. Support vector machines were then used to classify moments of aloneness as being lonely (vs.&nbsp;not lonely) and calm (vs.&nbsp;not calm) based on the words participants used when describing their thoughts. When compared against participants’ actual reported affective states, these classifications achieved up to 67% accuracy for “lonely” and 79% accuracy for “calm”. “Lonely” thought reports included the word “work” more frequently, whereas “calm” thought reports more frequently included the words “reading” and “think/thought”, suggesting individuals engage in quiet or contemplative activities during positive solitude. Age differences therein are also examined. Findings suggest that NLP may be a useful tool for identifying older adults at risk of loneliness (and its negative health implications) by using brief reports of their everyday thoughts.<br>
&nbsp;<br>
Title: <strong>The Social Influence of Emotions in Nested Social Dilemmas</strong><br>
Poster Number: 46<br>
Authors: <strong>Rychlowska, Magdalena; van der Schalk, Job; Manstead, Antony</strong><br>
Abstract: The present research examines whether and how emotions promote fairness and cooperation in nested social dilemmas. These economic games (adapted from Wit &amp; Kerr, 2002) model situations where a person’s individual interests are at odds with the interests of their group or a larger collective. In six studies, involving vignettes (N = 814) and real-time interactions between humans and avatars (N = 353), participants were led to categorize themselves as individuals, as subgroup members, or as members of a larger collective. They were then exposed to out-group individuals who displayed positive or negative emptions after resource allocation decisions that directly benefitted the out-group rather than the superordinate collective. Neither outgroup emotions nor the parochial behavior of the out-group consistently impacted participants’ own allocations to the private, group, and collective accounts. However, findings of the four vignette studies revealed that participants’ decisions were influenced by the context in which the social dilemma was presented. Specifically, people consistently allocated more resources to the larger collective in a context referring to the Ebola epidemic in West Africa than in the context of a neighborhood improvement project. These choices were strongly associated with prescriptive social norms. Together, the studies illustrate the challenges of adapting social dilemmas to realistic scenarios and highlight the importance of context in decision-making.<br>
&nbsp;<br>
Title: <strong>Interaction of Awe and Embodied Metaphor to Foster Creativity in Virtual Environment</strong><br>
Poster Number: 47<br>
Authors: <strong>Batal, Thibaut; Biancardi, Beatrice; Buisine, Stéphanie</strong><br>
Abstract: Creativity, one of the 21st-century key soft skills, is the ability to produce something that is both original and appropriate (e.g., Tang &amp; Gruszka, 2017). Virtual reality (VR) offers new ways to support creativity, for example by engaging users in new experiences (Bourgeois-Bougrine et al., 2022). These can include experiencing complex emotions like awe, a mix of joy, wonder and fear (e.g., Chirico, 2020). Awe occurs when perceiving an immense and unfamiliar environment, physical or virtual as well, leading to a flexibilization of mental patterns (e.g., Chirico &amp; Gaggioli, 2018). Not surprisingly, awe has been found to foster creativity (e.g., Chirico et al., 2018). VR also allows investigating embodied cognition, the influence of gestures on thought (Wiepke, 2023). Embodying creative metaphors such as “breaking the walls” can enhance creativity in VR (Leung et al., 2012). As mentioned, previous studies showed how inducing awe or including embodied metaphors, separately, affects creativity performance. In this work, we investigate whether this effect is enhanced when combining both factors. We present a VR experimental study where we manipulate (1) the environment: awe-inducing (mountains landscape) vs neutral (urban park); (2) the embodied metaphor “taking a step up”: moving like a bird (freely flying and landing along the road path), vs classic VR moves. Creativity is measured using the Alternative Use Task (Benedek et al., 2013). We hypothesize that both awe and embodied cognition positively influence the creativity performance, with awe having the strongest effect and embodied cognition acting as mediator.<br>
&nbsp;<br>
Title: <strong>Antipathy as an Emotion</strong><br>
Poster Number: 48<br>
Authors: <strong>DE VLIEGER, Bertille</strong><br>
Abstract: Antipathy is an affective phenomenon which has not received much attention by philosophers and psychologists, unlike its antonym, sympathy. However, antipathy is a phenomenon that contributes to and fuels many of the challenges related to our social behaviours and interpersonal relationships. Antipathy’s exact nature needs to be identified, if only because of the importance it has, for example, in political opposition, in loss of civility, but also in situations that cause poor psychological well-being. It would be then essential to be able to determine whether antipathy is a phenomenon that could be felt on a short term (an episode) or last in the long term (a disposition), since it would allow to study and measure more precisely the nature of the acts it gives rise to, the range of its intensity or/and its social consequences. Like sympathy, antipathy is most often understood as an affective phenomenon that lasts over time. Antipathy is often presented as an instinctive and irrational aversion to something or someone. Yet this common definition is too similar to the definition of other affective phenomena such as disgust or even fear. This talk will therefore examine the nature of antipathy by differentiating it from other emotional phenomena that resemble it. However, while the limited existing literature on antipathy characterises it primarily as an affective disposition, I will argue that antipathy is a conscious emotion, i.e., an emotion that occurs consciously and has a phenomenology (i.e., a phenomenal character). The talk is organized as follows. In §1, I introduce the affective phenomenon of antipathy by contrasting it with sympathy. In §2, I clarify what an affective disposition is, what a conscious emotion is and how they relate and differ. In §3, I present the most common theory or standard theory of antipathy, the one according to which antipathy is a disposition. Then, in §4, I argue that antipathy can be defined as a conscious emotion rather than as an affective disposition. In §5, I examine an objection to the idea that antipathy could be considered as an emotion and propose a response to this objection.<br>
&nbsp;<br>
Title: <strong>An Abstract Mindset Favors more Positive Outgroup Emotion</strong><br>
Poster Number: 49<br>
Authors: <strong>Laforet, Bronwyn D; Carrera, Pilar ; Caballero, Amparo</strong><br>
Abstract: Previous research on construal level theory shows that people who have a more abstract (vs concrete) thinking style tend to focus less on contextual characteristics and difficulties, making broader categorizations of situations or events. A more global categorization could facilitate perceiving outgroups as less different and then promotes perceiving less competitiveness and more positive feelings towards them. As a first step to explore these influences, the present study aimed to test how the adoption of a more abstract thinking style favors these links. In an experimental design, which used a sample of undergraduate university students (n= 99), we manipulated construal level (concrete vs.&nbsp;abstract thinking style) and measured perception of group competitiveness and emotions (threat, security, and positive and negative affect) towards a fictitious outgroup of migrant students described as being unfriendly but intelligent. Results showed that participants who had been primed with a more abstract thinking style (vs.&nbsp;concrete) perceived the outgroup as less competitive and reported feeling higher security and positive affect towards outgroup members. Given that it is possible to induce an abstract mindset through a variety of different methods, these results offer support for new strategies for interventions which aim to increase positive intergroup emotions and to improve the relationships between different groups of people.<br>
&nbsp;<br>
Title: <strong>Signal or Consequence! How Does Insight Affect Emotion?</strong><br>
Poster Number: 50<br>
Authors: <strong>Khalil, Radwa; Agnoli, Sergio; Ross, Wendy; D’Anselmo, Anita; scrimin, Sara ; Rominger, Christian; Kappas, Arvid</strong><br>
Abstract: Most creative ideas result from hard work, yet an outstanding idea can arise spontaneously from an insight. This sudden experience of a solution to a given open problem is also called an “aha” experience or Eureka moment. Previous research highlighted that a self-reported emotional reaction and increased skin conduction response follow an insight. Nevertheless, it is still uncertain whether an emotional response is a consequence or a signaling and preceding mechanism of an insight. As a result, our curiosity was sparked by determining if a specific physiological response, which might signal an emotional state, precedes the behavioral response (i.e., the solution), enabling us to differentiate between solutions with and without insight. During the piloting phase, 19 participants engaged in a remote association task where they had to answer 72 items. These items were separated into three blocks, each including 24 items. After a button press (signaling the moment of a solution), participants provided their solution and had to decide whether they had an insight. We further asked for confidence in their response and emotional state at the moment of the idea. During the experiment, physiological parameters, such as heart rate variability and skin conductance, were recorded. Using multi-level modeling, we compared correct solutions with and without insights and no response conditions. Based on the first preliminary findings of this study presented in Triste, Marconi Institute for Creativity, 2023, we present follow-up results investigating the spontaneous phenomenon of insight and its physiological and emotional antecedents.<br>
&nbsp;<br>
Title: <strong>Social Signals in Therapeutic Listening: The Effect of Nods and Smiling on Empathy and Rapport</strong><br>
Poster Number: 51<br>
Authors: <strong>McConville, Bethan; Lee, Matthew; McKeown, Gary</strong><br>
Abstract: Active listening is a crucial component of therapeutic interventions, creating social cohesion and trust between individuals to enhance the therapeutic relationship (Hutchby, 2005). This social cohesion is often referred to as dyadic synchrony and refers to the cooperation and reciprocal assurance between a dyad (Lei &amp; Gratch, 2023). Synchrony often facilitates dialogic interaction by enforcing the dynamic between the speaker and listener through various behavioural and non-verbal cues for the exhibition of empathy (Lei &amp; Gratch, 2023; Spencer &amp; McKeown, 2020). Active listening includes phatic communication, verbal confirmation of concentration such as “uh-huh,” as well as reflecting and rephrasing the speaker’s stream of consciousness back to them (Simon, 2018). Key non-verbal features of engagement are head nods and smiles. Here, we use therapeutic stimuli from recordings of online sessions from three different therapists that are available on the internet. We use affective computing software to measure the intensity, frequency, and depth of pitch of head nods and the intensity of FACS action units 12 and 6 during smile episodes. This has generated 120 thin-slice video clips of head nods, smiles, and a control group with no obvious social signals: forty clips each. These interactions are rated using measures of rapport and empathy in a pre-registered study. Ratings are continuous scales of empathy and rapport, with additional scales adapted from the empathy subscale of the Barrett-Lennard Relationship Inventory and a rapport scale (Gratch et al., 2015).<br>
&nbsp;<br>
Title: <strong>Digital Interventions for Social Anxiety: Improving Negative Beliefs and Heart Rate Variability During Public Speaking</strong><br>
Poster Number: 52<br>
Authors: <strong>Akdag, Ruya</strong><br>
Abstract: Social Anxiety Disorder (SAD) is a severe mental health issue that has doubled since the pandemic, affecting 20% of adolescents. Despite the availability of treatments, many socially anxious adolescents avoid therapy due to the fear of social exposure and negative evaluations, resulting in undertreatment. To address this issue, our study aims to deliver evidence-based therapies through digital interventions, which are cost-effective and non-threatening. In our proof-of-concept study, we developed digital variations of the detached mindfulness intervention, known to target metacognition, and the slow breathing intervention, known to target heart rate variability, and proved their effectiveness in alleviating their targeted mechanisms in a healthy student sample. In the current study, we will assess the effectiveness of these interventions in highly socially anxious youth during a socially stressful public speaking task. Adolescents (N = 270) will be randomly allocated to either the slow breathing intervention, detached mindfulness intervention, or their matched active controls. Participants will first receive a 10-minute digital intervention training, immediately followed by a public speaking test. We will measure state anxiety, negative metacognitive beliefs, and heart rate variability throughout the experiment. Additionally, we will assess participants’ subjective performance ratings to understand which aspects of public speaking tasks the intervention can target. The project is currently ongoing and will be completed in June. Therefore, I will present the full results, combined with the proof-of-concept findings, during the conference.<br>
&nbsp;<br>
Title: <strong>Can Guilt Feelings Enhance Nocebo Pain?</strong><br>
Poster Number: 53<br>
Authors: <strong>Türkarslan, Kutlu Kağan; Canel Çınarbaş, Deniz</strong><br>
Abstract: Objectives : In psychodynamic literature, it has been proposed that chronic pain problems with no physiological causes may function as expiatory punishment for individual’s guilt feelings. The aim of the present study was to investigate the effect of guilt feelings on formation of nocebo pain and whether the resultant nocebo pain would alleviate guilt feelings as expiatory punishment. Materials and Methods : 100 subjects participated in the experiment. Two independent variables of the experiment were guilt induction (guilt-no guilt) and nocebo manipulation (nocebo-no nocebo). Nocebo manipulation to induce headache was executed by telling the participants that they would receive mild electricity via an EEG cap. In addition, they watched a video in which a confederate imitates having pain during the experimental procedure. Two dependent variables of the experiment were guilt feelings and experienced pain. Guilt feelings were measured with Positive and Negative Affect Scale twice, once after guilt induction and once after nocebo pain manipulation. Experienced subjective pain scores were measured via a basic 0 to 10 visual pain scale. Results : The results showed that only the main effect of nocebo pain manipulation was significant. Conclusions: In a standard laboratory environment, the participants reported mild headaches in absence of any physical nocebo stimulation. Non-physical nocebo pain induction may conceive pain but guilt feelings did not incite the amount of reported nocebo pain and resultant pain did not alleviated guilt feelings.<br>
&nbsp;<br>
Title: <strong>The Two-Way Street of Interviews: Dyadic Interaction of Interviewer Mood and Applicant Impression Management Tactics</strong><br>
Poster Number: 54<br>
Authors: <strong>Sutphin, Daniel Jonas</strong><br>
Abstract: The job interview domain is a complex and interactive setting where job applicants seek to present themselves as having desirable competencies and characteristics. Thus, many job applicants strategically manage their behaviors (impression management) in front of interviewers. Interviewers, on their side, can also be subject to biases when assessing job applicants. One possible source of bias is the interviewer’s mood state, which can influence their perception of applicants and hence their ensuing hiring or salary decisions. As of yet, researchers have not examined how the interaction between applicants’ impression management behaviors and interviewers’ mood impacts selection decisions. Therefore, I propose a 2 x 2 between-subject experimental design, manipulating job applicants’ impression management behavior (self-/other-focused) and interviewers’ (the participants’) mood (pleasant/unpleasant). I will randomly assign participants to watch a pleasant or unpleasant video, manipulating their mood. Subsequently, I will present participants with a job description and application materials for a job applicant. Furthermore, I will randomly assign participants to listen to a prerecorded audio clip of a structured interview manipulated to contain self- or other-focused impression management behaviors. Finally, I will ask participants for their perceptions of the applicant and to provide hiring and salary decisions regarding the applicant. Given the substantial costs associated with talent acquisition and the potential for concealed biases in selecting job applicants, this research can make meaningful contributions toward minimizing organizational selection errors and may offer valuable insights for both research and practice. Data will be collected, analyzed, and ready to present by the conference date.<br>
&nbsp;<br>
Title: <strong>How Do (Social Media) Influencers’ Emotion Expressions Affect their Popularity?</strong><br>
Poster Number: 55<br>
Authors: <strong>Gu, Siyi; Heerdink, Marc W; van Kleef, Gerben</strong><br>
Abstract: Popularity is key to influencers’ career success. In four studies (total N=997), we show that influencers successfully navigating multiple demands on their emotional behavior by expressing authentic and appropriate are more likely to gain popularity.<br>
&nbsp;<br>
Title: <strong>Virtual Virtues and Shadows of Success: Digital Achievements Through the Lens of Plato and Aristotle</strong><br>
Poster Number: 56<br>
Authors: <strong>Karpouzis, Kostas</strong><br>
Abstract: This paper presents an in-depth analysis of gamification in digital applications, drawing from the ancient Greek philosophies of Plato and Aristotle. With the prevalence of gamification across various sectors, its ethical and societal implications warrant critical examination. Our research bridges classical philosophical insights with contemporary digital phenomena, offering a unique perspective on the ethical dimensions of gamification. Plato’s allegory of the cave and theory of forms are employed to explore the perception and value of virtual realities and achievements in gamified environments. This Platonic lens raises questions about the authenticity of gamified experiences and the potential risks of users mistaking virtual accomplishments for real-world fulfillment. Aristotle’s virtue ethics, focusing on moderation, virtue, and eudaimonia, provides a framework for assessing the impact of gamification on user behavior. The Aristotelian perspective scrutinizes how gamification may influence ethical decision-making and the development of moral virtues. This work also delves into specific gamification elements such as the hero’s journey narrative, altruistic actions, badge levels, and user autonomy, examining their ethical implications through these ancient philosophical doctrines. Additionally, the ethical responsibilities of gamification designers are discussed, emphasizing the importance of prioritizing user well-being and ethical development over commercial objectives. This study not only contributes to a deeper understanding of the ethical implications of gamification but also highlights the need for responsible design practices in digital applications, opening avenues for further research, including cross-cultural philosophical analyses, empirical studies on the impact of gamification, and the exploration of ethical guidelines for gamification design in light of technological advancements.<br>
&nbsp;<br>
Title: <strong>Emotional Assessement of Assertive Feedback from a Job Interview Training Agent</strong><br>
Poster Number: 57<br>
Authors: <strong>Koda, Tomoko; Yamauchi, Ryota; Takeuchi, Nao; Hotta, Miho</strong><br>
Abstract: In recent years, social signal processing techniques using multimodal information have been used in interview training systems [1-4]. Several studies have shown that practicing interviews with a virtual agent as an interviewer is more effective in improving interviewees’ performance than with human interviewers [5-7] and reduces interview anxiety [8]. However, these studies focused on the presence of a virtual agents and not on the communication methods agents use during interviews. Our proposed system recognizes the nonverbal behaviors of an interviewee, namely, gaze, facial expression, and posture [9-11]. A virtual agent acted as an advisor gives feedback on the interviewee’s behaviors that need improvement. We focus on assertive communication and implemented it as a communication method for virtual agents [12]. Assertive communication is a method of expressing one’s opinions and feelings while respecting another’s position and has been used in corporate training [13]. We examine the effectiveness of assertive feedback in terms of usefulness of the feedback, and interpersonal impressions of the agent. Whether the feedback is useful or threatening depends on the individual characteristics. Therefore, the learning-from-failure tendency [14], in which interviewees try to learn and grow from their failures rather than perceiving failures as threats, may influence the effectiveness of assertive feedback. The results indicated that assertive feedback showed higher effectiveness in emotional aspect by reducing the agent’s aggressiveness for those with a low tendency to learn from failures and by improving the agent’s perceived friendliness for those with a high tendency to learn from failures. (247 words) (list of references are omitted from the abstracts)<br>
&nbsp;<br>
Title: <strong>Are Members of Political Outgroups More Morally or Physically Disgusting?</strong><br>
Poster Number: 58<br>
Authors: <strong>Moran, Tal; Eyal, Tal</strong><br>
Abstract: Recent research has found that Americans are disgusted by anonymous members of their political outgroup. Determining whether the disgust elicited by political outgroup members is more physical or moral may contribute to the understating of what enables its elicitation and regulation. Building on research showing the experience of moral disgust involves relatively abstract construal and the experience of physical disgust involves relatively concrete construal, we predicted that disgust experienced toward political outgroup members is more moral than physical. Two preregistered experiments (total N = 854) found that (a) the effect of level of construal on the intensity of disgust from political outgroup members is more similar to the effect of level of construal on moral disgust than on physical disgust, and (b) the appraisal underlying disgust from political outgroup members involves more abstract than concrete construal, similar to moral disgust. We discuss implications of these findings for intergroup relations and emotion regulation.<br>
&nbsp;<br>
Title: <strong>Facial Expressivity and First Impressions During Online Social Interactions</strong><br>
Poster Number: 60<br>
Authors: <strong>Balabanova, Alisa; Kavanagh, Eithne; Kupfer, Tom R; Waller, Bridget M</strong><br>
Abstract: Facial expressions are an integral part of interpersonal communication. Facial expressions can display our internal states, change in response to the actions of others and influence others’ perceptions and behavioural tendencies. Therefore, facial expressivity has the potential to impacts first impressions and friendship formation. The current study explored the influence of facial expressivity and the understanding of display rules of emotions in the formation of first impressions and interpersonal connections in an informal, online group setting. Participants (N = 256) met in groups of three or four to test the hypotheses that a) more expressive individuals form better first impressions (in terms of likability, trust, and other interpersonal characteristics); b) more expressive individuals have bigger and denser social networks; and c) individuals with shared understandings of display rules of emotions are perceived more favourably by others. The results suggest that more expressive individuals are more liked, trusted and overall, perceived more favourably, by their interaction partners (a). We further discuss the outcomes of hypotheses b and c with relation to implications for how individuals engage with personal and professional social interactions in both online and face-to-face settings.<br>
&nbsp;<br>
Title: <strong>Oxytocin and Facial Expressivity</strong><br>
Poster Number: 61<br>
Authors: <strong>Buckee, Andrew; Kavanagh, Eithne; Balabanova, Alisa; Waller, Bridget M</strong><br>
Abstract: Greater facial expressivity has been linked to increased social cohesion, but the physiological mechanisms underlying this relationship have not been explored. Oxytocin is known to play a fundamental role in social interaction, particularly in terms of enhancing engagement with others. Levels of oxytocin are related to both the ability to recognise facial emotions in others and the salience of posed facial expressions; however, whether oxytocin is related to facial expressivity during real-world social interaction is largely unknown. Cortisol appears to be linked to variation in facial muscle activity, and, to a smaller extent, heightened facial emotional processing, thus highlighting a potential interplay between oxytocin, cortisol, and the regulation of facial and prosocial behaviour. Here, we will present preliminary findings on the relationship between oxytocin, cortisol, and facial expressivity (production) during social interaction. Salivary cortisol and oxytocin will be measured before and after participants engage in a social interaction between pairs of friends and pairs of strangers. Our findings will provide insight into the fundamental mechanisms underpinning social interaction, and the relationship between facial expressivity, social cohesion, and the levels of cortisol and oxytocin in the self and others.<br>
&nbsp;<br>
Title: <strong>Exploring Emotion Regulation Strategies Across Four Emotions: Anger, Disgust, Fear and Sadness</strong><br>
Poster Number: 62<br>
Authors: <strong>Meneghini, Anna Maria; Mignolli, Giada, Diletta; Colledani, Daiana</strong><br>
Abstract: What strategies do individuals employ to regulate anger, disgust, fear and sadness? How does the use of different strategies vary based on the type of emotion experienced? The use of six emotion regulation strategies (Distraction, Rumination, Reappraisal, Expressive Suppression, Expressive Engagement, Arousal Control) is analysed in relation to four emotions. One hundred and thirteen participants (Males = 41.6%; 44.6% of participants were aged between 20 and 29) were involved in this study. Guided by a concise description of the above mentioned six emotion regulation strategies, participants were asked to rate the extent to which they used each strategy when feeling angry, scared, sad or disgusted. A repeated measures ANOVA was run. Overall, participants were most likely to employ Rumination, whereas Arousal Control emerged as one of the least frequently utilized strategies for regulating anger, fear, sadness, and disgust. The ANOVA results unveiled significant differences in the use of the six strategies depending on the emotion experienced (except for fear). Participants exhibited significantly higher usage of Rumination compared to other strategies when feeling anger and sadness. When experiencing feelings of disgust, Expressive Engagement and Distraction were among the most used emotion regulation strategies, whereas Reappraisal was among the least frequently used. Expressive Suppression was significantly less utilised when feeling anger, and Arousal Control showed reduced usage during experiences of sadness. Collectively, among the four emotions, disgust emerged as the least regulated emotion. Results will be discussed according to the literature.<br>
&nbsp;<br>
Title: <strong>Why Do you Like some Colors and Dislike Others? Exploring Reasons Behind Color Preferences</strong><br>
Poster Number: 63<br>
Authors: <strong>Déborah, Epicoco; Mohr, Christine; Jonauskaite, Domicele</strong><br>
Abstract: For most people, colors carry affective meanings. People also know which colors they like and dislike. The Ecological Valence Theory (EVT) was introduced to explain the origin of color preferences (Palmer &amp; Schloss, 2010, PNAS). According to this theory, former affective experiences with colored objects shape preferences for these colors. Thus, people like blue because they think of a clear holiday sky and dislike brown because it reminds them of rotten foods. Most previous studies tested monochromatic objects (disregarding multicolored objects or abstract ideas) and used a limited range of pre-selected colors. Since its introduction, the EVT has been confirmed to be theoretically and empirically powerful. We further tested assumptions of the EVT by considering more diverse associations. We asked 135 participants (50 men) to select their favorite and least favorite colors (each time up to five) using a computerized color picker. Then, they provided free associations with each selected color. We coded these associations into nine semantic themes and analyzed their semantic meanings. In particular, we assessed whether participants associated concrete objects or abstract concepts with their chosen colors. Our results showed a large variability in free associations beyond monochromatic objects, mainly falling into Scenery, Sensory and Affective Experiences, and Abstract Concepts themes. We also obtained valence ratings of the reported associations in a new group of participants (N = 233) and will test whether positive experiences underly favorite colors and vice versa. Overall, such studies are crucial to go from descriptive to predictive models of color preferences.<br>
&nbsp;<br>
Title: <strong>Promoting Social and Emotional Learning (SEL) in Preschool Age: A Training Study</strong><br>
Poster Number: 64<br>
Authors: <strong>Grazzani, Ilaria; Cavioni, Valeria; Drago, Dimitra; Carlone, Beatrice</strong><br>
Abstract: Several studies have shown that early school interventions promote children’s development of social and emotional competences. Promoting Mental Health at School (Promehs) is a European, school-based mental health program focused on enhancing social and emotional learning (SEL), a psychological construct made up of five key components which include several skills such as the awareness of the emotions, the ability to manage emotions, perspective taking, and the disposition to show empathy towards others. In the present study, we implemented the Promehs program with female and male preschoolers to innovatively evaluate its effectiveness through a battery of direct evidence instead of questionnaires filled out by adults. Participants were 152 4- and 5-year-olds recruited at school in Northern Italy and randomly assigned to either an experimental group (Promehs intervention) or a control group (no intervention). All children, before and after the intervention phase, were administered validated measures of social, emotional, and cognitive abilities, including emotion understanding and theory-of-mind tasks. A repeated-measures Anova was performed showing significant Time x Group interaction since the experimental group outperformed the control group on emotion and cognitive measures of SEL (p&lt;.001). Educational implications of these outcomes are suggested.<br>
&nbsp;<br>
Title: <strong>Asymmetry in Face-Context Integration</strong><br>
Poster Number: 65<br>
Authors: <strong>Day, Samuel E; Zech, Hilmar; Shore, Danielle M</strong><br>
Abstract: During social interactions, smiles provide information about a social partner’s affect and intentions. Although previous research shows that explicit evaluations of smiles are influenced by context and vice versa, the joint effects of smiles and contexts on subsequent behaviour are less clear. Consequently, across three experiments, we assessed behavioural responses to face-context compound stimuli using a phone-based approach-avoidance task. Participants were instructed to push (“avoid”) or pull (“approach”) their phone according to smiler gender (study 1), smile type (study 2), or context valence (study 3). In Study 1, while participants reacted to faces in positive contexts more quickly than faces in negative contexts across response types, smile type did not significantly affect reaction time. In Study 2, reward smiles were approached more quickly than dominance smiles, and vice versa for avoidance responses. We also found a significant context-response interaction. Smiles in positive contexts were approached more quickly than smiles in negative contexts, but this relationship was absent for avoidance responses. In Study 3, positive situations were approached more quickly than negative situations, and vice versa for avoidance responses. Interestingly, smile type did not significantly affect reaction times for either approach or avoidance responses. Together, these findings show that while contexts implicitly affect behavioural responses to smiles, smiles don’t implicitly affect behavioural responses to contexts. This suggests that whilst situational context is automatically processed when evaluating facial expressions, processing of expressions when evaluating contexts is likely a more deliberative and effortful process.<br>
&nbsp;<br>
Title: <strong>Demographic, Clinical and Psychosocial Predictors of Positive Aspects of Informal Epilepsy Care</strong><br>
Poster Number: 66<br>
Authors: <strong>O’Rourke, Norm; Bachner, Yaacov; Shorer, Zamir; Shorer, Talia</strong><br>
Abstract: Caring for a child with epilepsy poses various economic and psychosocial challenges. These can lead to stress and burden but also positive experiences of epilepsy care. For this study, we computed path analyses to identify both direct and indirect predictors of positive aspects of caregiving by mothers with a child with epilepsy. Our path model included sociodemographic, illness and mental health factors. A total of 168 women were recruited while attending the Pediatric Neurology Clinic at Soroka Medical Center, Be’er Sheva, Israel. This sample included 130 Jewish-Israeli and 38 Arab-Bedouin mothers caring for a child with epilepsy who completed parallel questionnaire batteries in Hebrew or Arabic. In our path model, burden is directly predicted by emotional exhaustion, (Arab) ethnicity, and the absence of social support and life satisfaction. Positive aspects of caregiving are directly predicted, in turn, by self-efficacy and (low) caregiver burden. Positive aspects of caregiving are indirectly predicted by (Jewish) ethnicity (via higher social support, life satisfaction and self-efficacy), lower illness severity and emotional exhaustion (via higher self-efficacy), and higher psychological well-being (via lower emotional exhaustion). Bedouin mothers reported greater illness severity, symptoms of depression and caregiver burden. Differences between groups in epilepsy severity suggest that less severe cases in the Bedouin community do not come to clinical attention (e.g., concealed due to stigma). These findings underscore the importance of health promotion strategies and interventions for epilepsy caregivers, tailored to account for ethnic and cultural differences.<br>
&nbsp;<br>
Title: <strong>Enhancing Context-Dependent Emotion Regulation in Adolescents: A Pilot for an Ecological Momentary Intervention</strong><br>
Poster Number: 67<br>
Authors: <strong>Nimtz, Carmen; Karreman, Annemiek; Dejonckheere, Egon; Kupper, Nina</strong><br>
Abstract: Introduction: Successful emotion regulation (ER) depends on the flexible matching of strategies to the current situational context. However, there is a lack of research on ER interventions aimed at providing context-dependent strategy recommendations for adolescents. Therefore, this ecological momentary intervention (EMI) explores the effect and feasibility of a mobile application providing context-dependent ER strategy recommendations. It was hypothesized that the context-based EMI would improve adolescents’ wellbeing and ER more than a non-context based EMI or an ESM control. Method: Adolescents were randomly assigned to the intervention or control groups. For 14 days, all groups reported their emotions several times per day. The context-based EMI and the EMI control received educational content on ER skills and strategies. After reporting negative emotions, the EMI group received context-dependent strategy recommendations, while the EMI control received random recommendations. About 30 minutes later, all groups indicated their current emotions and the strategies they applied since the last prompt. Additionally, participants filled out questionnaires measuring ER and mental health factors pre- and post-intervention. Analyses were performed using multilevel models. Results: Data collection and analysis will be finalized by Spring 2024. Conclusion: This EMI is among the first to test the effectiveness of context-dependent just-in-time recommendations for ER strategy use in adolescents. The study’s results and limitations will provide future directions for tailored ER interventions.<br>
&nbsp;<br>
Title: <strong>The Role of Empathy in Foreign Language Didactics: A Learning Scenario for Teaching German as a Foreign Language</strong><br>
Poster Number: 68<br>
Authors: <strong>Tzafara, Ariadni</strong><br>
Abstract: In recent years the concept of empathy, as far as the educational sciences are concerned, has been discussed (e.g.&nbsp;Liekam, 2004; Scheu, 2012;) but to this day this discussion has not been carried out within the field of foreign language didactics. Although empathy is directly related to human relationships, it is not one of the main objectives of language teaching within the “Common European Framework of Reference for Languages” (CEFR). The aim of the study presented in the poster is to examine the benefit of empathy in the field of foreign language didactics and suggest a learning scenario to aid foreign language teachers in fostering empathy in the classroom. The “Reference Framework of Competences for Democratic Culture” (RFCDC) identifies empathy as a skill in the broader set of competences for democratic culture. Since the cultivation of competences is the main didactical goal of foreign language learning, as defined in the CEFR, the need to incorporate empathy as a skill to foreign language learning and to the related competences is apparent. Empathy is indeed not an emotion, but an affective-social ability which can be derived from emotions and can regulate emotions. And although it is long proven that affective factors play a role in foreign language learning (e.g.&nbsp;Börner &amp; Vogel, 2004; Burwitz-Melzer et al., 2020), empathy is still not researched in this respect. The study concludes that empathy can act as a supporting force that enables intercultural and multicultural interaction, that is, as a booster for intercultural competence.<br>
&nbsp;<br>
Title: <strong>Assessing Prospect Theory’s Concepts: Loss and Gain Zones in Risky Choice Framing</strong><br>
Poster Number: 69<br>
Authors: <strong>Novković, Vera</strong><br>
Abstract: The research goal was the operationalization and experimental verification of gain and loss zones in risky choice framing, using explanatory concepts from prospect theory (Tversky &amp; Kahneman, 1992) and the risk-as-feelings model (Loewenstein, et al., 2001). Zones were represented via combining subjective value and probability of risky choice outcomes, the choice between risky and safe options (prospect theory), as well as anticipative and anticipatory emotions – how a person feels when choosing and how they expect to feel after the choice outcome (risk-as-feelings). Zones were induced via counterbalanced risky choice framing tasks. Participants in the loss zone were expected to take risks more often, devalue the safe outcome, and add value to positive and negative risk outcomes. Subjective probability assessments for positive risky choice outcomes were expected to rise; self-assessments of emotional states during decision making would be more negative in the loss zone, with an improved anticipated emotional state. Opposite tendencies for each measurement were assumed in the gain zone, except for the anticipated emotional state, as no expectations could be formed from the theoretical basis. Research assumptions were largely confirmed: Tasks combining all four concepts elicited a basic framing effect. Direct measurement of subjective value, as well as anticipative and anticipatory emotions, proved successful and in line with expectations. Measuring subjective probability seems to require a finer scale. Results support the operationalization of gain and loss zones through combining concepts from prospect theory and the risk-as-feelings model, offering a basis for further experimental research into these mostly theoretical constructs.<br>
&nbsp;<br>
Title: <strong>Emotions in Contact: A Study of Arabic-English Contact</strong><br>
Poster Number: 70<br>
Authors: <strong>Ech-charfi, Ahmed; El asri, Khalid</strong><br>
Abstract: This study investigates the change of emotion words in Classical Arabic as a result of contact with English. 213 English words were selected for this purpose the equivalents of which were checked up in two bilingual English-Arabic dictionaries from two different periods. As is the case in other domains of contact, the processes found to operate in the semantic change of emotions were calquing, loan translation, loan rendition and extension, in addition to what is termed here “explanations”. Explanations are phrases intended to introduce the meaning of an item to users of bilingual dictionaries. What was noted is that some of these phrases ended up being lexicalizations of unfamiliar emotion categories. Loan words, however, were found to be very rare. It was argued that these kinds of change stand behind the development of a Modern Standard Arabic.<br>
&nbsp;<br>
Title: <strong>Do We Pout at the Moai? the Influence of Cross-Cultural Facial Icons on Emotional Responses?</strong><br>
Poster Number: 71<br>
Authors: <strong>Achour-Benallegue, Amel; Umemura, Hiroyuki; Kawabata, Hideaki</strong><br>
Abstract: Facial icons are depictions of faces in diverse artistic and ethnographic artifacts across regions and eras. Despite their diverse origins, these artifacts share common features, notably facial features serving as foundational elements for facial expressions, which are effective means of communicating emotions. Previous research indicates a tendency to perceive specific facial-icon styles as (human) face categories in terms of neural responses. Empirical studies demonstrate facial icons’ ability to induce facial mimicry and indicate potential emotional contagion, suggesting the influential role of simulated emotion in shaping the artistic relationship with facial icons. However, it remains unclear whether this emotion simulation occurs distinctly for different basic emotions and affects, and which morphometric features contribute to emotional contagion. To address these gaps, a study involving 45 participants conducted dual assessments. In the first, participants rated the expressed emotions in 11 cross-cultural facial icons, covering six basic emotions (happiness, sadness, surprise, disgust, fear, anger) and three affects (valence, arousal, dominance), along with seven morphometric features (human-likeness, ornamental-features, craft-quality, beauty, eye-contact, eye-expression, mouth-expression). In the second, participants assessed their own basic emotions and affects when exposed to these facial icons. Results revealed a significant impact of expressed emotions in facial icons on most participants’ basic emotions and affects, indicating an emotional contagion. Specific morphometric features emerged as influential factors in shaping self-reported emotions. Notably, self-reported sadness showed diminished scores in response to facial icons characterized by heightened aesthetics (beauty and ornamental-features), suggesting a substantial impact on crucial emotional states such as well-being.<br>
&nbsp;<br>
Title: <strong>Navigating Intimate Relationships: The Role of Emotion Dynamics in Dealing with Relational Needs Frustration</strong><br>
Poster Number: 72<br>
Authors: <strong>Pirrone, Davide; Scharmer, Aurelia; Sels, Laura; Verhofstadt, Lesley</strong><br>
Abstract: The present study aimed to explore the role of partners’ negative engaging and disengaging emotions in dealing with the frustration of autonomy and relatedness needs during conflict. In an observational study, partners from 141 heterosexual couples participated in a conflict interaction task followed by a video-mediated recall procedure during which they reported their level of relational need frustration and their emotions experienced at different moments during the interaction. Results showed that in partners, more autonomy frustration, experienced at the beginning of the conflict, was accompanied by more concurrent negative disengaging emotions (anger, irritation), whereas more relatedness frustration was accompanied by more negative engaging emotions (hurt, sadness, disappointment). Additionally, the concurrent association between partners’ relatedness frustration and their experience of negative engaging emotions was negatively moderated by their own relatedness relationship beliefs (as assessed by background questionnaires), indicating that for individuals who considered relatedness to be less important, relatedness frustration and negative engaging emotions were more strongly linked than for people with high relatedness beliefs. Finally, negative engaging emotions – assessed at the beginning of the conflict – were associated with more relatedness frustration at a subsequent time point in the interaction in men, but not in women. This study contributes to our understanding of how partners’ negative emotions and the frustration of important relational needs are intertwined.<br>
&nbsp;<br>
Title: <strong>How Emotions can Impact Consumer Behavior on Social Media</strong><br>
Poster Number: 73<br>
Authors: <strong>Kanzler, Andrea</strong><br>
Abstract: The phenomenon of influencers on social media platforms such as Instagram is still gaining traction, and academia and practitioners aim to understand why and how influencers can impact their audiences to follow them and to change their behavior. Emotions that content creators generate among their followers are one key element for the strength of their influence. Therefore, this study will focus on the emotional level of the follower-influencer relationship. First, we analyze how emotions reflect into the feeling of a parasocial relationship, i.e.&nbsp;when followers feel as if the influencer would be their close friend although they might have never met in person or have never spoken to each other. Second, we investigate how emotions lead to the perception of trustworthiness, i.e.&nbsp;the feeling of the follower that an influencer is honest, transparent and truthful. Finally, we will investigate how emotions towards hedonic and utilitarian content of an influencer can be used to shape consumer behavior. So far studies on influencers have mostly focused on follower counts, likes or comments to measure the effectiveness of influencers. Therefore, our research with its focus on emotions delivers new insights on the influencer-follower relationship. We analyze data from experiments and a survey to derive recommendations for theory and practitioners.<br>
&nbsp;<br>
Title: <strong>Cross-Cultural Comparison of ChatGPT’s Response Styles for Japanese and English</strong><br>
Poster Number: 74<br>
Authors: <strong>Schaaff, Kristina; Kumano, Shiro</strong><br>
Abstract: Despite the growing relevance of large language models like ChatGPT, research on how cross-cultural influences affect their response styles is limited. Understanding these impacts is crucial for developing systems that can meaningfully adapt to cultural differences. In their research, Chen et al.&nbsp;(1995) found that North American students have a more extreme response style than east asian students. Moreover, Schaaff et al.&nbsp;(2023) showed, that ChatGPT can respond to personality questionnaires in a similar way to healthy humans. Our study focuses on the response styles of Japanese and American adults, hypothesizing that cultural norms and values impact ChatGPT’s responses. To do this, we prompted ChatGPT in English and Japanese and additionally asked it to respond as if it were either an American or a Japanese adult. To ensure that the response behavior is not just related to one single questionnaire, we used the following questionnaires: Empathy quotient, ten-item personality measure, and interpersonal reactivity index. A three-way ANOVA revealed a significant main effect of prompt language (p &lt; .01) and a marginally significant main effect of imagined nationality (p = .067); namely, ChatGPT responded more extremely when prompted in English than in Japanese and when being asked to imagine being American than Japanese. There was no significant main effect of questionnaire or their interaction. Our findings have implications for improving the user experience and effectiveness of those systems in cross-cultural contexts as they show that ChatGPT adapts the way it responds to questions in correspondence to the persona and prompt language.<br>
&nbsp;<br>
Title: <strong>Categorical Versus Dimensional Models of Dissociation Part 1: Taxometric Analysis among Japanese Adolescents</strong><br>
Poster Number: 75<br>
Authors: <strong>Fukui, Yoshikazu; Nakatani, Tomomi; Nakai (Matsuo), Kazuya</strong><br>
Abstract: Disorganized/disoriented attachment resulting from repeated traumatic events in early childhood is considered the most critical risk factor for the future development of dissociative disorders. Dissociative disorders are also associated with severe emotional dysregulation. Therefore, it is clinically important to understand the characteristics of dissociation. Traditionally, dissociation has been viewed as categorical rather than dimensional, as suggested by early taxometric analyses (e.g., Waller et al., 1996). However, recent advances in taxometric methodology (Ruscio, 2007) and emerging studies have suggested that most psychological traits are dimensional (Haslam et al., 2020). Dissociation also needs to be re-examined. The present study used the taxometric analyses with Comparison Curve Fit Index (CCFI; Ruscio et al., 2017) to examine the latent structure of dissociation among Japanese adolescents (N=1170, 576 women, 593 men, and 1 of unknown gender). Dissociation severity was assessed using the Dissociation Experiences Scales-2 (Carlson &amp; Putnam, 1993), and the scores of three distinct subscales––absorption, amnesia, and depersonalization––were calculated according to three-factor model by Stockdale et al.&nbsp;(2002). Our comprehensive taxometric analysis, incorporating various taxon base rates, consistently supports a dimensional structure of dissociation, as indicated by a mean CCFI below .422. These results demonstrate the appropriateness of considering dissociation as dimensional. Our findings suggest the need to re-examine previous results of taxometric analyses related to dissociation.<br>
&nbsp;<br>
Title: <strong>The Emotional Reactions to Experienced (in)Tolerance as Potential Catalysts for Collective Action.</strong><br>
Poster Number: 76<br>
Authors: <strong>Stucke, Frederike; Simon, Bernd</strong><br>
Abstract: Pluralism often leads to heightened polarization, as various societal groups hold differing beliefs regarding what constitutes the right way of life. The disapproval-respect model of tolerance proposes that the disapproval at the intergroup level needs to be constrained by equality-based respect to enable tolerance. However, how do minorities react when they experience such (in)tolerance? And which emotional reactions encourage societal participation and a normative struggle for recognition? To address these questions, we conducted two 2x2 online experiments with samples of individuals with overweight (NStudy1 = 113, NStudy2= 227). We manipulated the disapproval and respect components of experienced (in)tolerance and examined the intergroup emotions, action tendencies, and willingness for normative and non-normative protest. We found, that the experience of (in)tolerance predicted the negative intergroup emotions anger and contempt, whereby more tolerance led to less anger and contempt. The anger reaction was significantly more pronounced than the contempt reaction. Mediation analyses indicated indirect effects of experienced (in)tolerance on action tendencies towards the outgroup and the willingness for normative protest via the intergroup emotion anger, with anger increasing the willingness to act. Contempt mediated the relationship between experienced (in)tolerance and confrontational action tendencies by negatively predicting the confrontational action tendencies. These findings reinforce the idea that anger plays a significant and influential role in the intergroup context, fostering political agency and empowering minorities to assert themselves in response to intolerance. Additionally, the findings suggest that intergroup contempt could be a less constructive emotion, as it inhibits approaching other groups.<br>
&nbsp;<br>
Title: <strong>Remorse in the Courtroom: A Content Analysis of Judgements About the Assessment of the Perpetrator’s Remorse</strong><br>
Poster Number: 77<br>
Authors: <strong>Ambrozkova, Zuzana</strong><br>
Abstract: Regret is a significant emotion in many legal systems, particularly in criminal law. In Czech criminal law, it is a mitigating circumstance, a condition for a decision to waive punishment or for a conditional release from imprisonment. As with other emotions, there are no objective criteria for its “measurement”. The perception of the emotions of others is a subjective assessment that can only be more or less accurate with the experience of the other. The question arises: how does a judge determine whether it is genuine, not feigned remorse? Is it decided based on how the accused behave - or how they “perform” in the courtroom? But what if we are used to expressing our emotions and sincere feelings in other ways, perhaps in private, without facial expressions, hand gestures or tears? Emotions are sociocultural phenomena. How we express emotions is a matter of our socialization and the environment in which we grow up. Presented research opens a discussion on how Czech judges perceive and evaluate the experience of remorse of the offender. A content analysis of court judgments about deciding on waiver of punishment for the years 2019 to 2022 maps how judges justify their decisions regarding leniency in relation to the emotion of offender remorse. The research identifies how remorse is evaluated in our context and, with the help of previous empirical and theoretical research, also understands the possible limitations of these evaluations.<br>
&nbsp;<br>
Title: <strong>Striking a Deal? a Meta-Analysis Investigating the Role of Specific Emotions in the Maintenance of Binge Eating</strong><br>
Poster Number: 78<br>
Authors: <strong>Borm, Insa M; Hartmann, Steffen; Barnow, Sven; Pruessner, Luise</strong><br>
Abstract: Introduction: Binge eating episodes have been conceptualized as a means to regulate emotions. However, studies examining the overall association between binge eating and changes in negative affect have produced inconsistent findings, questioning the regulatory function of binge eating. More fine-grained assumptions about changes in specific emotions may help to better understand the emotion regulation processes involved. Trade-off theory assumes that during binge eating episodes, aversive emotions that are difficult to tolerate (e.g., anger) are replaced (“traded”) by emotions that are still aversive, but easier to tolerate (e.g., guilt). An integration of studies testing these assumptions is still lacking. Method: The current meta-analysis focuses on changes in specific emotions (guilt, anger) around binge eating episodes. Effects (standardized mean change and Fisher’s r-to-Z transformed correlations) were integrated using random-effects models with robust variance estimation. Results: The synthesis included 14 studies (54 effect sizes, N = 553). Consistent with trade-off theory, there was a trend towards more pronounced increases in guilt levels compared to anger levels after binge eating episodes. However, both anger and guilt trajectories showed increases before binge eating, followed by subsequent decreases, with effects being small. Heterogeneity between studies was large across analyses. Conclusions: Contrary to trade-off-theory, the synthesis does not support the notion that anger is replaced by guilt after binge eating episodes. While the observed trend towards increased levels of guilt after binge eating merits further investigation, small effects suggest the need to consider emotions beyond guilt and anger to better understand binge eating and improve existing treatments.<br>
&nbsp;<br>
Title: <strong>Are There Differences Between Implicit and Explicit Behavior in Real-Time Emotional Identification in School-Age Children?</strong><br>
Poster Number: 79<br>
Authors: <strong>Mayo, Coral; Aguilera, Mari ; Ahufinger, Nadia; Verdaguer-Ribas, Oriol; Guerra, Ernesti; Pons, Francisco; Andreu, Llorenç; Sanz, Mònica</strong><br>
Abstract: Mixed emotions are the presence of two complex emotions toward a single target. We aim to study whether children can implicitly identify mixed emotions based on saccadic eye movements to displayed faces, and explicitly based on their verbal answers, and compare findings. To the best of our knowledge, this is the first eye-tracker study evaluating complex emotional contexts. Children (6-12 yo) were divided into two groups: a) typically developed (TD) (N=40), b) with a diagnosis (N=81) of Learning Disorder (LD) (dyslexia, dyscalculia, DLD, or ADHD). With the eye-tracker-software iMotions we presented an oral sentence (with the meaning of the emotion in the verb) simultaneously to four faces expressing different emotions. Then participants verbalized how they thought the person was feeling. We randomly presented 12 sentences including mixed emotions and 12 including non-mixed emotions. The proportion of eye fixations (implicit information) and their answers (explicit information) were analyzed. Implicit data analysis showed there were no differences between groups, and both can switch their look to the second target emotion in mixed condition. However, explicit data analysis showed they rarely verbalize two emotions. Plus, TD group verbalized correctly one of the two target emotions more times than LD group. Children can implicity recognize mixed emotions based on the semantic meaning of a sentence, given that they look significantly more at the two different emotions. Nonetheless, they seem to only become aware of one emotion. Furthermore, children with learning disorders present more difficulties when identifying explicit emotions than their TD peers.<br>
&nbsp;<br>
Title: <strong>Adolescent Emotional Behaviours and Self-Control: A 14-Year Longitudinal Study of Emotion Development in Family Context</strong><br>
Poster Number: 80<br>
Authors: <strong>Kelly, Dominic P; Cassganeau-Francis, Oliver; Francesconi, Marta; Flouri, Eirini</strong><br>
Abstract: Adolescence is associated with immaturities in emotional and behavioural problems (i.e., internalising and externalising behaviours; Ahmed et al., 2015) and self-control behaviours (Casey &amp; Caudle, 2013). To understand this phenomenon, developmental change and the impact of the home environment (i.e., socioeconomic indicators, maternal emotional health) must be accounted for. Participants are 4251 nationally representative English 17-year-olds (55.4% female). Predictors include emotional internalising and externalising data (Strengths and Difficulties Questionnaire between ages 3-14) and family/socioeconomic indicators at age 3 (i.e., maternal education, Index of Multiple Deprivation, maternal depression). The outcomes come from two hypothetical monetary self-control tasks where Choice A was constant while Choice B consisted of a limited set of 10 options on a sliding scale with each following option either increasing the potential cost of the risk or the monetary reward received after delaying gratification. Uniquely, this data was analysed with ‘survival models’ which account for the statistical artefact that the exact point of participants’ limit for self-control could lie between two options. Results suggest that a greater reluctance to risk take is associated with less externalising or more internalising problems during adolescence, a comparative increase in internalising problems longitudinally and growing up in an economically deprived neighbourhood. Results suggest that problems with delaying gratification are associated with a higher average level of externalising problems across development, parents not finishing secondary education, being male and lower general intelligence. Thus, emotion and self-control development are linked and situated in important contexts which can explain adolescent behaviours even 14 years later.<br>
&nbsp;<br>
Title: <strong>Curiosity as Integral to Feature Journalists’ Self-Concepts</strong><br>
Poster Number: 81<br>
Authors: <strong>Flammia, Christine A</strong><br>
Abstract: Journalism instruction has long assumed a sense of curiosity: that journalists have questions about the world, people, and events, and then care enough to answer those questions. Curiosity is fundamental to how American journalism is taught, credited as a journalistic edge, the very impetus of story creation. But for academic analysis, classifying curiosity as a useful reporting tool does not engage with how journalists truly use it in practice. As I use it, curiosity is the emotion, experience, or desire to learn about something not immediately useful; it’s knowledge-seeking for some non-immediate need. Feature stories are explicitly set apart by their non-immediate-news nature. This gives features a specific posture toward exploring topics and events with a sense of curiosity. Drawing on a set of 18 semi-structured interviews with U.S.-based feature journalists and editors, this research explores how these professionals use curiosity to find story ideas by exploring news stories more in depth; by asking probing questions to themselves and to others; and by actively engaging with topics that are overlooked, underreported, or otherwise misunderstood. This research explores how a feature journalist’s phenomenological experience and professional performance of curiosity influences how she positions herself in the industry and engages her work. A feature journalist’s phenomenological experience and professional performance of curiosity are essential components of her self-concept. Curiosity is not just an inner experience but a relational one, shaped by the journalistic process in which it is expressed.<br>
&nbsp;<br>
Title: <strong>“Morbid Curiosity” is Associated with less Reactivity to Horrific Stimuli</strong><br>
Poster Number: 82<br>
Authors: <strong>Taylor, Pamela M</strong><br>
Abstract: INTRODUCTION: Curiosity is an approach-orientation to novelty and the unknown. One type of curiosity is “morbid curiosity” (MC), which is a dispositional approach-orientation to abnormal stimuli that many people find aversive (e.g., horrific violence, disgusting body violations). However, it is unclear if MC reflects positive responses to aversive stimuli (e.g., pleasure, excitement) or lower negative reactivity (e.g., reduced horror) that dampens the aversiveness. Given that MC is positively associated with sensation-seeking (Harrison &amp; Frederick, 2020), and that sensation-seeking is associated with lower reactivity to stressors (Roberti, 2004), it is possible that MC may reflect lower arousal to typically aversive stimuli that allows people high in MC to enjoy exploring abnormal stimuli as novel items of interest with less of the aversive emotional responses that would reduce the pleasure of such exploration. METHODS: To explore MC’s association with negative emotional reactivity to abnormal harm, two repeated-measures studies were conducted online (N = 120). Participants read four tabloid headlines that described a real person being harmed in an abnormal way. After each, they rated how much horror (“horrified”, “shocked”, α = .82; measured on a 5-point Likert scale) and physical arousal (5-point visual Self-Assessment Manikin; Lang, 1980) the headline elicited. Lastly, they answered the Violence and Body Violations subscales of the Morbid Curiosity Scale (12 items, α = .92; Scrivener, 2021). RESULTS: In General Estimating Equations analyses, horror was negatively predicted by MC, B_study1 = -.26 [95%CI: -.44, -.08], B_study2 = -.36 [-.59, -.13], and positively predicted by arousal, B_study1 = .77 [.67, .86], B_study2 = .62 [.47, .78]. But when MC and arousal were entered as simultaneous predictors of horror, the association between MC and horror was mediated by arousal, B_study1 = -.13 [-.31, .05], B_study2 = -.22 [-.44, .00]. DISCUSSION: This suggests a physiological component to MC, whereby MC was associated with lower arousal in response to unpleasant stimuli, which in turn dampened aversive feelings of horror. Thus, horrific events that low-MC people might experience as aversively abnormal, high-MC people may experience as interesting novelty that stimulates the approach motivation of curiosity.<br>
&nbsp;<br>
Title: <strong>The Use of Emotion Regulation Strategies Across Diverse Emotions: Exploring Age-Related Variations</strong><br>
Poster Number: 83<br>
Authors: <strong>Colledani, Daiana; Mignolli, Giada, Diletta; Meneghini, Anna Maria</strong><br>
Abstract: To date, studies have not consistently provided evidence for age differences in emotion regulation. This study aims to explore whether there are differences between young and older individuals in their use of Reappraisal and Expressive Suppression when experiencing 10 emotions (anger, fear, sadness, disgust, guilt, shame, distress, upset, contempt and envy). One hundred and five participants (Males = 43.8%) were involved in this study. At the time of completing the questionnaire, 56 participants were aged between 18 and 39, and 49 were aged over 59. The questionnaire consisted in a brief description of Reappraisal and Expressive Suppression. Participants were asked to rate, for each strategy, how much they used it when experiencing each of the listed emotions. A series of T-Tests were run. Overall, the results show that the older group tended to use these emotion regulation strategies less than their younger counterparts. More specifically, while no significant difference between the groups emerged in relation to anger, disgust, distress, and contempt, older participants exhibited a reduced likelihood of employing the intended strategies when responding to emotions such as fear, sadness, guilt, shame, upset, and envy. The differences, which vary according to the strategies, will be discuss. In addition, also the differences between groups in terms of automatic versus intentional emotion regulation will be discussed.<br>
&nbsp;<br>
Title: <strong>The Effects of Local Mobile Safety Alerts on Fear, Risk Perceptions, Behavior, and Punitiveness</strong><br>
Poster Number: 84<br>
Authors: <strong>Benjamin, Amanda C.</strong><br>
Abstract: In addition to formal wireless emergency alert (WEA) systems, mobile applications like “Citizen” (fka Vigilante) provide real-time hyperlocal crime and safety alerts. Although marketed as a “personal safety” app, Citizen has faced criticisms over its potential to increase fear, anxiety, and promote surveillance and vigilantism. While alert systems and safety apps are ubiquitous, there is a lack of research testing these systems and their (un)intended effects on users and communities. To address this gap, the proposed randomized controlled trial will assess the effects of receiving crime alerts from Citizen over the course of one week. Mobile experience sampling methods will be utilized to measure fear, negative affective responses, and risk perceptions. It is predicted that repeated exposure to local crime and safety alerts will significantly increase fear of crime, perceived risk of victimization, punitiveness, and risk reduction behaviors compared to baseline and the control (no app) group. Differential effects of gender are expected, such that individuals socialized as women will report greater fear, risk perceptions, and safety precautions compared to men, while men will report higher punitive policy attitudes. The results of this study have practical implications for the promotion of safety, public policy, and psychological and emotional wellbeing. Further, additional insights into the potential role of demographic and contextual factors can improve targeted interventions, particularly for vulnerable populations. Keywords: Communication/mass media; social networks; specific emotions<br>
&nbsp;<br>
Title: <strong>Interpersonal Capitalization and Unmet Interpersonal Needs Among Adolescents at Varying Risk for Suicidal Ideation</strong><br>
Poster Number: 85<br>
Authors: <strong>Perezmontemayor Cruz, Ignacio; MacNeil, Sasha; Gouin, Jean-Philippe</strong><br>
Abstract: Introduction: Perceived burdensomeness and thwarted belongingness are appraisals of unmet interpersonal needs associated with higher risk of suicidal ideation. While prior studies have examined the influence of negative interpersonal experiences on unmet interpersonal needs, little is known about the role of positive interpersonal processes. Interpersonal capitalization, the action of sharing a positive personal event with close others, is an interpersonal process that increases positive affect and connectedness between the sharer and the responder. This study examined whether daily capitalization was associated with fluctuations in perceived burdensomeness, thwarted belongingness, and positive affect among adolescents at higher- and lower-risk of suicidal ideation.Methods: This study included adolescents (Mage=15.55; range=12-18; 74.55% female) with a major depressive disorder considered at higher-risk for suicidal ideation (Higher-Risk group; n=23), and adolescents without psychopathology considered at lower-risk for suicidal ideation (Lower-Risk group; n=32). Participants completed a ten-day daily-diary procedure with measures of daily interpersonal capitalization, positive affect, perceived burdensomeness, and loneliness as a proxy for thwarted belongingness. Within-person analyses examined the associations of daily capitalization with burdensomeness, loneliness, and positive affect across groups.Results: Only the higher-risk group reported lower perceived burdensomeness and loneliness on days where they engaged in more capitalization. While higher capitalization was associated with higher positive affect in both groups, the higher-risk group benefitted from larger increases in positive affect in response to capitalization.Conclusion: Engaging in daily interpersonal capitalization may be useful to reduce daily thwarted belongingness and perceived burdensomeness and increase positive affect among adolescents at higher risk for suicidal ideation.<br>
&nbsp;<br>
Title: <strong>Neural Correlates of Emotion-Label vs.&nbsp;Emotion-Laden Word Processing in Late Bilinguals: Evidence from an ERP Study</strong><br>
Poster Number: 86<br>
Authors: <strong>Tang, Dong; Li, Xueqiao; Fu, Yang; Wang, Huili; Li, Xueyan; Parviainen, Tiina; Kärkkäinen, Tommi</strong><br>
Abstract: The brain processes underlying the distinction between emotion-label words (e.g., happy, sad) and emotion-laden words (e.g., successful, failed) remain inconclusive in bilingualism research. The present study aims to directly compare the processing of these two types of emotion words in both the first language (L1) and second language (L2) by recording event-related potentials (ERP) from late Chinese-English bilinguals during a lexical decision task. The results revealed that in the early word processing stages, the N170 emotion effect emerged only for L1 negative emotion-laden words and L2 negative emotion-label words. In addition, larger early posterior negativity (EPN) was elicited by emotion-laden words than emotion-label words in both L1 and L2. In the later processing stages, the N400 emotion effect was evident for L1 emotion words, excluding positive emotion-laden words, while it was absent in L2. Notably, L1 emotion words elicited enhanced N400 and attenuated late positive complex (LPC) compared to those in L2. Taken together, these findings confirmed the engagement of emotion, and highlighted the modulation of emotion word type and valence in both early and late processing stages. Different neural mechanisms between L1 and L2 in processing written emotion words were elucidated.<br>
&nbsp;<br>
Title: <strong>Investigation of Interpersonal-Affective Motivation for Prosocial Behavior</strong><br>
Poster Number: 87<br>
Authors: <strong>Monnor, Teerawat</strong><br>
Abstract: Emotion plays a critical role in shaping prosocial behavior. Witnessing a person experiencing stress can encourage people to help. This interpersonal effect of emotion is, however, complex and not fully understood. People can give up helping because they realize that their effort might just be inefficient or because they don’t feel motivated enough, and individual differences (such as in compassion and altruistic attitude) can play a critical role. This project aims to shade more on this topic using a multi-componential approach to emotion, stating that emotion elicits in a multimodal fashion, including the appraisal, motivational, physiological, feeling and action ones. We want to empirically show that compassion leads to motivation to help and hypothesize that this effect should be stronger in participants with higher altruistic and empathic traits. The participant (the empathizer) will be asked to perform a task, adapted from the computer-based slider task, to help another participant not be given electric shocks. In different trials, the empathizer experiences different levels of potential stress in their counterpart (induced by different strengths of the electric shock) and different levels of task difficulty. While performing the task, the skin conductance and heart rate are measured (the physiological component). Other emotional components are assessed from performance and by subjective rating. These multimodal responses then get analyzed at both conditional and group levels. Furthermore, the participant will perform the same task, but to obtain monetary rewards. Their responses and performances for the two goals can be compared between the higher- and lower-altruistic group. Data collection will be conducted soon.<br>
&nbsp;<br>
Title: <strong>Psychophysiological Expressions of Neuroticism</strong><br>
Poster Number: 88<br>
Authors: <strong>Campero Oliart, Alejandro</strong><br>
Abstract: The influences of our personality permeate across many aspects of our lives, including our health. Neuroticism–a broad personality dimensions characterized by a tendency to experience dysregulating and negative emotional experiences–has shown to be a particularly strong health-related personality dimension. For example, higher neuroticism has shown to predict greater likelihood to develop physical health conditions as well as greater mortality risk later in life, with the current evidence pointing mostly to behavioral and psychological habits (i.e., lower social, physical, and cognitive activities) as underlying factors for this predictive link. However, the dysregulating experiences constituting neurotic personality expressions could also affect individuals’ health via physiological manifestations of distress. Thus, this study examined whether neuroticism manifested in three psycho-cardiac distress indices: Heart-rate (HR), heart-rate variability (HRV), and Baevsky’s stress index (SI). This study also explored the predictive strength of other broad personality dimensions according to the Big-Five personality model. College students (N = 71, Mage = 19.90, SD = 1.80, range: 18—28) first completed the Big-Five Personality Inventory. Then, their cardiac activity was monitored during a standard non-stimulating laboratory environment (i.e., seating privately in an armchair while breathing spontaneously). Multivariate regression analyses revealed that higher neuroticism uniquely predicted higher HR, lower HRV, and higher SI. Moreover, agreeableness also uniquely predicted higher HR and SI, while openness uniquely predicted lower HR, higher HRV, and lower SI. These findings are interpreted in the context of psychophysiological arousal, emotion-dysregulation, and stress-reactivity, their neurological bases, and their implications for mental, physical, and social facets of health.<br>
&nbsp;<br>
Title: <strong>Appraisals of Cultural Appropriation on Intergroup Anger and Affirmative Action Endorsement</strong><br>
Poster Number: 89<br>
Authors: <strong>Mosley, Ariel J</strong><br>
Abstract: Cultural appropriation is the act of taking, making us of, or imitation of a cultural product from an out-group that one does not identify with. The current research works examine the downstream consequences of exposure to acts of cultural appropriation on angry affect and affirmative action. Two experiments examined how perceivers respond to acts of out-group cultural use in various domains. In Study 1, White participants were exposed to a series of scenarios depicting out-group cultural use. Participants either read about White perpetrators engaged in cultural products associated with Black culture, or about Black perpetrators engaged in cultural products associated with White culture. Results from Study 1 demonstrated that reading about White perpetrators elicited greater angry affect than Black perpetrators. Study 2 examined how White and Black participants respond to acts of out-group cultural use to see if the perpetrator race effect on angry affect is unique to White participants. Study 2 also assessed endorsement of affirmative action policies in support of improving the status Black Americans. When reading about in-group actors engaged in use of Black culture (vs.&nbsp;out-group actors engaged in the use of White culture), White participants (but not Black participants) reported greater angry affect, and lower endorsement of affirmative action policies in support of Black Americans. This research illuminates how appraisals of cultural appropriation can facilitate a sense of anger and threat for White Americans. Implications for perceiving cultural appropriation for intergroup consequences are discussed.<br>
&nbsp;<br>
Title: <strong>Beyond Psychology : Understanding Emotions Through the Lenses of Anthropology</strong><br>
Poster Number: 90<br>
Authors: <strong>shaqiri, qendresa</strong><br>
Abstract: The difference between anthropology and psychology in investigating emotion is considerable. Psychology focuses mainly on the individual psychological experiences of emotions, whereas anthropology deemphasizes the individual idiosyncrasies to give more attention to the articulation of the personal and social experiences withing contexts of broader societal and power dynamics, by putting an emphasis into the complexity of production of emotions in everyday contexts. I argue here that there is a need for a more anthropological view of emotions in our society to counterbalance the hegemonic view of psychology of emotions. The social and cultural interpretation of emotions in contemporary western societies is mainly based on their scientific understanding such as psychology and neuroscience. I want to discuss here about the necessity for a more broader understanding, in our society, of emotional related issues such as mental health, and to advocate for the need to inject an anthropological understanding and explanation of these issues in the public discourse.<br>
&nbsp;<br>
Title: <strong>The Positive Relationship Between Warm Glow and Pro-Environmental Behaviour</strong><br>
Poster Number: 91<br>
Authors: <strong>Zhou, Linli; Sauter, Disa; Brick, Cameron</strong><br>
Abstract: Warm glow describes the phenomenon whereby acting pro-socially feels good. Here, we investigated the relationships between anticipated and experienced warm glow and pro-environmental behaviour and intentions. Study 1 (237 adults) measured real-time pro-environmental behaviour using the Carbon Emission Task, which involves trade-off decisions between bonus payment and environmental protection. Participants who made more conservation decisions (i.e., receiving less payment) experienced more warm glow. Study 2 (803 young adults) used the Work for Environmental Protection Task, a tedious and effortful task, as a stricter test of warm glow. Even in this boring task, people who completed more pages experienced more warm glow. Additionally, the effect of anticipated warm glow on experienced warm glow was partially mediated by pro-environmental behaviour. Study 3 replicated the mediation effects in a more generalized sample (953 adults). Moreover, it showed that people who anticipated more warm glow showed strongly costly (e.g.&nbsp;pay higher taxes) and general (e.g.&nbsp;take shorter showers) pro-environmental intentions, while experienced warm glow only influences general intentions. Together, these results demonstrate how pro-environmental behaviour can make us feel good, and point to a key role of anticipated feelings of warm glow in driving behaviour.<br>
&nbsp;<br>
Title: <strong>Fight or Flight? Pavlovian-to-Instrumental Transfer of Control over Fight-or-Flight Decisions</strong><br>
Poster Number: 92<br>
Authors: <strong>Eder, Andreas B; Mitschke, Vanessa</strong><br>
Abstract: In outcome-selective Pavlovian-to-instrumental transfer (PIT), conditioned stimuli (CS) predict specific outcomes and prime actions associated with these outcomes. This study expands the paradigm to explore fight-or-flight decisions. Participants first learned to either attack or retreat from animated monsters using a Sidman avoidance schedule during the instrumental phase. In the subsequent Pavlovian phase, they learned relations between specific environments and the appearance of certain monsters. During the transfer phase, participants chose between fight and flight to defend against invisible monsters, with intermittent CS presentations (environments without monsters). Study 1 found that CS presentations primed fight-or-flight decisions, demonstrating an outcome-selective PIT effect, and defensive actions compared to neutral CS, demonstrating an outcome-general PIT effect. Study 2 assessed the automaticity of the specific PIT effect under cognitive load and with instructions for the transfer phase where relations between CS and expected outcomes were verbally reversed post-training (between-manipulation). The results indicated a persistent fight-or-flight PIT effect with standard instructions and a reversed effect with reversal instructions. Notably, high cognitive load amplified the PIT effect in standard conditions but not with reversal instructions. Study 3 implemented a within-subject manipulation of high versus low threat. Results revealed a larger fight-or-flight PIT effect under low threat with standard instructions and no effect of threat level with reversal instructions. Collectively, these studies suggest that conditioned cues influence defensive action choices via activation of propositional knowledge structures. This knowledge retrieval is moderated by cognitive load and high threat, underscoring the complexity of cognitive and emotional influences in human defensive behavior.<br>
&nbsp;<br>
Title: <strong>Advancing Holistic Empathy Assessment in Virtual Reality</strong><br>
Poster Number: 93<br>
Authors: <strong>Jacobs, Elizabeth M; DeBruine, Lisa; Stumpf, Simone</strong><br>
Abstract: The immersive nature of Virtual Reality (VR) offers unique and exploratory means to evoke empathy in ways previously unattainable. However, to produce successful social interventions, we need a foundational understanding of how empathy is best measured within a VR landscape. Our work reports on three studies that evaluate commonly used empathy measures, such as questionnaires and physiological measurements, and assess their ability to reliably measure empathy in VR. In the first study, scores on trait empathy questionnaires that are frequently cited in the literature were compared, exposing a lack of consistency in the structural frameworks of these questionnaires. For example, questionnaire subscales that were meant to assess cognitive, affective, and general empathy did not show consistent intercorrelations. Building on the insights from this study, the following studies investigate the relationships between physiological responses (I.e., galvanic skin response and heart rate measurements), trait empathy from a general questionnaire, and state empathy questionnaire responses within an empathy-inducing virtual reality paradigm. By exploring the convergence or divergence of physiological responses and self-reported empathy, this set of studies seeks to establish a more robust and integrated framework for assessing empathy in technologically enriched environments.<br>
&nbsp;<br>
Title: <strong>Do Anticipatory Affect and Time Pressure Interact in Decisions under Risk?</strong><br>
Poster Number: 94<br>
Authors: <strong>Philips, Roxane; Brevers, Damien; Pachur, Thorsten; Vögele, Claus</strong><br>
Abstract: Background. Anticipatory affect and time pressure have been shown to impact decision-making under risk. In affect-rich choices participants pay less attention to probability-related information and switch from decision strategies that weigh all pieces of information (compensatory) to one that consider only one source of information (non-compensatory). Time pressure seems to have a similar impact on decision behavior. We thus sought to investigate the simultaneous impact of time pressure and anticipatory affect. Method. We used a risky choice paradigm in which participants (N=173) were requested to choose between lotteries that are rich (medial lotteries) or poor (monetary lotteries) in anticipatory affect. Participants were randomly allocated to a time pressure (i.e., instructed to make a choice as fast as they could) and a control group (i.e., instructed to take their time deciding). We used computational modeling to determine the best fitting decision strategy. Results. Most participants used a non-compensatory strategy in affect-rich compared to -poor decisions (X2= 90.53, p&lt;0.001). This effect was not modulated by time pressure (X2=0.104, p=0.92). Participants made more risky choices in the affect-poor compared to -rich condition (F=21.445, p&lt;0.001). This effect was primarily driven by a switch to non-compensatory strategy use. Conclusion. The impact of anticipatory affect on decision behavior was not significantly modulated by time pressure. Differences in risk taking across affect-rich and -poor choices are driven by changes in decision strategy.<br>
&nbsp;<br>
Title: <strong>Empathy Unleashed: Exploring the Impact of Cultivating Unlimited Empathy Mindset on Engaging in Empathic Effortful Behaviors</strong><br>
Poster Number: 95<br>
Authors: <strong>Ong, Desmond; Yang, Emily; Gueorguieva, Emma</strong><br>
Abstract: Empathy is considered a virtue, yet it can be challenging to exercise when it is difficult or distressing to relate to people in need. Building on recent research on mindsets about empathy (Hasson et al., 2022), inducing the belief that empathy is unlimited may motivate increasing empathy in effortful situations. Undergraduates were randomly assigned to read articles portraying empathy as limited or unlimited (N = 153). They then completed the empathy selection task, a 25-trial where participants could choose whether to empathize with a target or simply describe their physical characteristics. We hypothesized that an unlimited mindset would be associated with more empathy, even when empathy is costly. Indeed, reading about an unlimited mindset increases beliefs about unlimited empathy (manipulation check on beliefs, p &lt; .001). However, contrary to expectations, there was no main effect of the condition: the treatment did not significantly impact empathic effortful behaviors (p = .45). Nevertheless, in the unlimited condition, participants’ beliefs about empathy were more strongly related to empathic choices (a marginally significant slope, b = 1.64, p = .06) compared to those in the control condition (in which there was no significant slope, b = .51, p = .35; interaction p = .07). This study opens up additional research directions on the effect of mindset beliefs about empathy on empathic decision-making.<br>
&nbsp;<br>
Title: <strong>Differential Influence of Habitual Behavior Components on Compulsive and Problematic Reward-Seeking Behavior</strong><br>
Poster Number: 96<br>
Authors: <strong>Wuensch, Lavinia; Stussi, Yoann; Murray, Ryan; Denis-Bonnin, Maelys; Corino, Tamara; Sander, David; Péron, Julie; Pool, Eva R.</strong><br>
Abstract: Habitual behavior has been identified as a key process involved in a variety of mental health disorders. Previous research has shown that habit is not a unitary construct. The present study examined how different components of habitual behavior relate to compulsive and problematic reward-seeking behavior. Four hundred and one participants completed a French version of the Creature of Habit Scale, which measures two components of habitual behavior: routine and automaticity. Participants also completed questionnaires assessing compulsivity, impulsivity, affective stress, and a variety of problematic reward-seeking behaviors, from which five transdiagnostic factors were extracted using an exploratory factor analysis. A dynamic network analysis indicated that the two habitual behavior components were differentially related to these transdiagnostic factors: routine was associated to compulsivity, while automaticity was associated to problematic media consumption. These findings suggest that taking the non-unitary architecture of habit into account may help to better understand the role of habit in mental health.<br>
&nbsp;<br>
Title: <strong>Measuring Facial Movements in Dyadic Interactions Using the blenderFace Method</strong><br>
Poster Number: 97<br>
Authors: <strong>Zinkernagel, Axel; Alexandrowicz, Rainer; Lischetzke, Tanja; Schmitt, Manfred</strong><br>
Abstract: The blenderFace method is based on the open-source software Blender to precisely measure facial skin movements in video recordings, similar to motion capturing techniques used in the film industry. The process involves tracking markers placed on the facial skin using a pattern-matching algorithm, while effectively filtering out head movements. A significant advantage of the blenderFace method over automatic emotion recognition systems (e.g., AI-based systems) is its ability to record movement data not as classified emotions, but as raw x, y, and z coordinates for each frame. This data can then be subjected to detailed statistical analysis, allowing for a deeper theory-independend and pre-classification free understanding of facial cues in human interactions. In a first study (N = 106), we demonstrate the utility of the blenderFace method and present examples of statistical analyses that can be conducted using the data obtained. In a second study (N = 18) we used sunscreen painted markers only visible in the UV-range of light and videorecorded participants with two cameras in the visible and the UV-range of light. On the one hand, this modification facilitates a fair comparison of measurement precesion between the marker-based blenderFace method and marker-free AI-based methods (e.g., OpenFace) which are disrupted by visible painted markers. On the other hand, the adapted blenderFace method allows for an unobtrusive measurement of facial movements in dyadic interactions.<br>
&nbsp;<br>
Title: <strong>I may be Ambiguous, but I Am Still in Control: The Influence of the Ambiguous Emotional Load in Words on the Performance in Emotional Stroop Task</strong><br>
Poster Number: 98<br>
Authors: <strong>Wielgopolan, Adrianna; Imbir, Kamil</strong><br>
Abstract: How does the emotional ambiguity influence our cognitive functioning (Brainerd et al., 2021)? Based on a recently proposed theory describing the dimensional ambiguity in emotions’ structure (Wielgopolan &amp; Imbir, 2022), we differentiated the three spaces of ambiguity: ambivalence (positivity, negativity), origin (automaticity, reflectiveness), and activation (arousal, subjective significance). We hypothesized that stimuli ambiguous on every one of those spaces would have a different effect on our cognition. Using emotionally loaded words in the series of two experiments, we examined the effect of emotional ambiguity on the effectiveness of cognitive control using the simple Emotional Stroop Task (n = 60; Experiment 1) and its modified version with flankers (n = 60; Experiment 2). In both experiments, all groups of ambiguous words elicited significantly shorter reaction times than the control, unidimensional words. In Experiment 2, we observed significantly longer response times for incongruent compared to congruent trials. Additionally, in the incongruent trials, words with activation ambiguity produced reaction times significantly shorter than all other groups of words. These results show that the influence of emotionally ambiguous words (on three different emotional spaces) on cognitive control is significantly different than that of unidimensional words. It also further verifies the theory about the different kinds of emotional ambiguity.<br>
&nbsp;<br>
Title: <strong>The Effects of Emotion Brokering Frequency and Gender on Maternal Relationship Quality</strong><br>
Poster Number: 99<br>
Authors: <strong>Subramoney, Sivenesi; Cardoza Cortez, Marcela; Walle, Eric A</strong><br>
Abstract: There is emerging evidence that youth from immigrant families help their families navigate emotion-based communication. We refer to this assistance as emotion brokering, which is the process of helping someone understand the emotions of a person from a different culture. Research on other forms of brokering (i.e., interpreting language for others) suggests that frequent brokering for family members predicts greater familial conflict (Hua &amp; Costigan, 2012). However, research has yet to examine the relationship between emotion brokering frequency and relationship quality. In this study, we examined (a) the association between emotion brokering frequency and relationship quality (i.e., relationship conflict and relationship support) and (b) the role of gender as a moderator of the relationship between emotion brokering frequency and relationship quality. A sample of Latinx college students (n = 118) reported their frequency of emotion brokering for their mothers and rated their levels of conflict and support in their relationship with their mothers. As expected, analyses revealed that emotion brokering frequency for the mother was associated with greater reports of maternal relationship conflict, but not maternal relationship support. However, analyses also revealed that the association between emotion brokering frequency and relationship conflict varied by gender. Specifically, emotion brokering frequency was only positively associated with relationship conflict among men in the sample (p = .005). These findings highlight that the process of helping others understand emotions is situated in the context of a relationship. The findings have implications for understanding how families adapt to the emotions of a different culture.<br>
&nbsp;<br>
Title: <strong>The Eye of the Beholder: Perceiving Jealousy in Interpersonal Interactions</strong><br>
Poster Number: 100<br>
Authors: <strong>Ganesh Kumar, Manasa; Walle, Eric A</strong><br>
Abstract: Jealousy is experienced in triadic contexts when an intimate relationship with a beloved is threatened by a rival (Campos et al., 2010). This powerful emotion is experienced by adults and children alike. While research typically examines individuals’ experiences of jealousy, less work has considered people’s perceptions of others’ expressed jealousy. We investigated 5-year-olds’ (N = 38), 7-year-olds’ (N = 37) and adults’ (N = 27) perceptions of others’ jealousy-like behaviors. Participants viewed animations of a central character cry for one individual (but not another) when the central character’s relationships with the social partner was threatened. Participants perceiving jealousy were expected to select that the target character preferred the person for whom they cried. Analyses indicated that 5-year-olds (13%, χ2 = 20.63; p &lt; .001) and 7-year-olds (30%, χ2 = 6.08; p = .01) chose the expected option significantly below chance whereas adults chose the expected option significantly above chance (82%, χ2 = 10.70; p = .001). Adult performance was also significantly better than 5-year-olds (χ2 = 30.34; p &lt; .001) and 7-year-olds (χ2 = 16.74; p &lt; .001). Interestingly, 7-year-olds’ performance varied by child gender, with girls (44%) significantly more successful than boys (23%), χ2 = 3.63; p =.05. Thus, we conclude that children’s ability to understand others’ jealousy emerges around the age of 7 (with the ability emerging sooner in 7-year-old girls) and continues to develop as the individual reaches adulthood.<br>
&nbsp;<br>
Title: <strong>When is Envy Beneficial for Performance? Exploring the Curvilinear Relation Between Envy and Performance and the Moderating Role of Conscientiousness</strong><br>
Poster Number: 101<br>
Authors: <strong>Tai, Kenneth; Lee, Ki Young; Kim, Eugene ; Lemoine, James; Duffy, Michelle</strong><br>
Abstract: Despite the growing interest in workplace envy, empirical evidence regarding envy and employee performance is inconclusive. Integrating the social functional theory of emotions and self-regulation theory, we examine whether envy has a curvilinear relationship with performance and how this relationship is influenced by employee conscientiousness. In Study 1, using data from bank employees in Korea, we find that for employees who are higher on conscientiousness, envy has a curvilinear relationship with performance, such that the relationship is initially positive but becomes weaker and eventually disappears as envy increases further. However, for employees who are lower on conscientiousness, there is no relationship between envy and performance. Study 2, a three-wave study of sales and marketing employees from a healthcare company in the U.S., generally replicates the curvilinear moderated relationship. We discuss the theoretical and practical implications of our research.<br>
&nbsp;<br>
Title: <strong>Feasibility of Using High-Frequency SSVEP in Probing Top-Down and Bottom-Up Contributions in Affective Attention</strong><br>
Poster Number: 102<br>
Authors: <strong>Naar, Richard; Uusberg, Andero; Taras, Siim Erik; Uutsalu, Liisa; Uusberg, Helen</strong><br>
Abstract: Many affective processes, including emotion regulation, unfold over several seconds. This introduces a challenge for event-related approach often taken in EEG research. While typical ERP approaches enable investigation into temporal dynamics right after the onset of a stimulus, their sensitivity to more gradually unfolding processes is less optimal. At its core, ERP is merely a sudden change in stimulus contrast reflected in aggregated EEG waveform, which is, among other things, influenced by affective attention. Considering this, a potential solution would be to increase the number of these contrast changes in a unit of time, an approach known as SSVEP which provides an opportunity to conduct a query over a much longer time-window. In this study (N=44) we did just that; more specifically, we tested the feasibility of using a barely noticeable - and therefore less disturbing - periodic contrast modulation in the gamma range to probe variation in bottom-up capture of attention due to changes in affective content (negative vs.&nbsp;neutral) and the allocation of top-down attention (unregulated viewing vs.&nbsp;distraction) deployed towards the same stimuli. The time-frequency analysis based on rhythmic entrainment source separation revealed a sensitivity towards top-down attentional strategy, albeit in an unexpected direction (p&lt;.001), but surprisingly, no significant interplay between affective content and EEG power at the tagged frequency (42.5 Hz) was apparent in our data (p&gt;.05). This raises questions about the differential origins of these effects and about the feasibility of the high-frequency SSVEP in the context of emotion regulation.<br>
&nbsp;<br>
Title: <strong>Relations Between Emotion Beliefs and Emotion Regulation in China and the UK</strong><br>
Poster Number: 103<br>
Authors: <strong>Ge, Yiran; Parkinson, Brian</strong><br>
Abstract: This preregistered cross-sectional study investigated cultural differences in emotion beliefs and emotion regulation using measures that capture a wider range of emotion regulation strategies than previous studies. Young adults based in China (N = 161) and the UK (N = 155) completed questionnaires assessing independent and interdependent self-construals, beliefs about emotion controllability, usefulness and acceptability, and emotion regulation at the four stages of Gross’s (1998) process model. Chinese participants reported significantly higher controllability, usefulness, and acceptability beliefs for negative emotions and greater use of emotion regulation than British participants. In the combined dataset, independent self-construal significantly predicted use of emotion regulation strategies at all four stages whereas interdependent self-construal only significantly predicted response modulation. Further, controllability and usefulness beliefs predicted increased efforts in situation modification and attention deployment, controllability beliefs positively predicted cognitive change, and all three kinds of emotion beliefs positively predicted response modulation. There were also cultural differences in effects of emotion beliefs with acceptability having stronger effects on cognitive change in China and controllability only having a significant negative effect on response modulation in the UK. Further, our path model showed that all three beliefs mediated effects of independent self-construal on emotion regulation but only controllability beliefs mediated the effects of interdependent self-construal on emotion regulation. Our findings suggest that there are cultural differences in emotion beliefs, regulation strategies and the relations between them. Definitive evidence about causation will require further longitudinal research.<br>
&nbsp;<br>
Title: <strong>Exploring the Interplay of Emotions and Metacognition in L2 Pronunciation: Evidence from Italian Primary School.</strong><br>
Poster Number: 104<br>
Authors: <strong>Cannito, Loreta; Trotta, Eugenio; Bonvino, Aurora; Cottini, Milvia; Palladino, Paola</strong><br>
Abstract: The role of emotions in learning is widely acknowledged in literature. According to Pekrun’s Control-Value Model, when learners perceive control over an activity, they are more likely to experience positive emotions, while the opposite holds true for negative emotions. Therefore, students’ achievement emotions during the learning process are influenced by their perception of control and the value they assign to the activity. Also, numerous studies support the idea that proficiency in L2 pronunciation significantly contributes to overall language learning competence. Despite the crucial roles of these variables (achievement emotions and pronunciation’s level), the majority of scientific studies on this topic often neglecting to consider these factors concurrently. Furthermore, most of studies have focused on university students or young adults while few evidence are available for younger learners. Following a previous longitudinal study where the authors highlighted an influence of metacognitive and emotional skills on English Vocabulary primary school’s participants, this study was aimed at investigating if the same relationship applies when considering L2 pronunciation. To this purpose, 130 second and third-grade students from Italian primary schools were involved. We assessed their pronunciation on a selected pool of English two-syllable words. Their phonological parameters were assessed and analyzed using the PRAAT software. Consistently with Pekrun’s Theory, and in accordance with our previous results on L2 vocabulary performance, our preliminary results seem to indicate an interconnectedness of metacognitive skills and achievement emotions in also predicting pronunciation of English as L2, starting from primary school. More studies on this topic are needed.<br>
&nbsp;<br>
Title: <strong>Introducing and Validating a New Observational Paradigm for Assessing Triadic Family Interactions with Adolescents</strong><br>
Poster Number: 105<br>
Authors: <strong>Romet, Michaël P; Favez, Nicolas; Tissot, Hervé</strong><br>
Abstract: We present a novel observational tool designed for the standardized assessment of father-mother-adolescent conflict interactions, addressing a gap in existing instruments that predominantly focus on the mother-adolescent dyad through self-report measures. This study introduces and validates the Lausanne Trilogue Play – Conflict Discussion Task (LTP-CDT) and the Family Conflict and Alliance Assessment Scales – with adolescents (FCAAS-Ado). The task and coding system underwent testing with a sample of 82 family triads, consisting of the two parents and their adolescent child aged 10 to 13. Our findings demonstrate excellent inter-rater reliability for the coding system, and confirmatory factor analysis supports a robust two-factor structure of this new instrument. Criterion and construct validity were demonstrated through associations with self-reported marital satisfaction and coparenting. Furthermore, ecological validity for the LTP-CDT is established through family members’ self-reports regarding the typicality of their interactions. This tool holds promise for future research targeting diverse populations, for example low-income families or those with referred adolescents or parents, which will allow for the assessment of known-group validity for the FCAAS-Ado. The presentation discusses research and clinical implications of this innovative observational tool.<br>
&nbsp;<br>
Title: <strong>Reducing Hate: How Hatred may be Reduced by Changing People’s Appraisals</strong><br>
Poster Number: 106<br>
Authors: <strong>Steele, Amanda K; Roseman`, Ira J; Parkinson, Brian</strong><br>
Abstract: Prior research shows that hatred is an intensely negative emotion that is associated with perceiving someone as unchangeably malevolent, suggesting that people may not be able to stop hating someone. Yet is this really the case? The present research tested whether hatred could be reduced by changing the appraisals that research has shown contribute to causing hatred (e.g., perceived unchangeability and malevolence). A sample of 52 CloudResearch participants completed an online survey that asked them to describe two experiences of hatred (one about someone who is currently hated, and one about someone else who is no longer hated) and answer questions about their current thoughts and feelings. Results supported most of our hypotheses. For example, compared to people who are still hated, those who are no longer hated were perceived as less immoral, less evil, and were blamed less. In addition, participants who no longer felt hate perceived less dislike felt towards them than the participants who currently felt hate. Finally, our results for participant’s rated felt intensities of particular positive emotions (e.g., sympathy, compassion, and affection) and negative emotions (e.g., contempt, anger, and dislike) will be discussed.<br>
&nbsp;<br>
Title: <strong>Hume’s Square of Passions: Bumpy Emotions Stabilized by Habit</strong><br>
Poster Number: 107<br>
Authors: <strong>Royles, Joshua T</strong><br>
Abstract: In David Hume’s Treatise of Human Nature, “reason is and ought to be the slave of the passions.” The literature often ignores that this prioritization of emotion over reason follows Hume’s experiment on the square of passions comprised of pride and humility and love and hatred, each component formed by a double relation of ideas associated with a relation of impressions. The imagination, for Hume, is passive and unfixed, thus wildly unstable. However, the principles of association, which Hume claims as habit or reason, act as a stabilizing and gentle force that guides and assists this relation of ideas. The effects of these relations that replay and return upon the passive mind activate it to such an intense pitch that its ideas are perceived as impressions, which Hume labels impressions of reflection. The repetition changes nothing in the objects repeated, but it does make a difference in the mind that perceives it. The unsteadiness of the mind becomes constant and settled through repetition, and with the appearance of one object, in anticipation, the imagination immediately leaps to its frequently attending idea. This constant observation of habitual conjunction forms a belief, which converts what would be an idea into a feeling, that of a necessary connection. This feeling of necessity establishes an easy, smooth, and imperceptible transition from one idea to the next. The calm and steadying force of habit—exemplified in the square of passions—is why Hume places reason in a subservient, assisting role to our more violent emotions. Key words: Philosophy; Emotion Regulation; Emotion Theory; Habit; Passions; Reason; David Hume<br>
&nbsp;<br>
Title: <strong>Exploring Experiences of Anxiety, Alexithymia and Interoception in Autistic Adolescents: A Reflexive Thematic Analysis</strong><br>
Poster Number: 108<br>
Authors: <strong>Adams, Kiera L; Catmur, Caroline; Bird, Geoffrey; Waite, Polly</strong><br>
Abstract: Alexithymia (a difficulty identifying and describing emotions) has been linked to abnormal interoception, defined as the detection and interpretation of bodily signals. Both alexithymia and interoception have been suggested as potential explanations for the frequent comorbidity of autism and anxiety. The aim of this study was to gain a better understanding of how interoception and alexithymia may be linked to experiences of anxiety in autistic adolescents. Semi-structured interviews were conducted on thirteen British, autistic adolescents who reported experiencing significant anxiety. Initial patient and public involvement work was conducted to inform research design. Purposive sampling was used to generate a diverse sample. Interviews were analysed using a reflexive thematic analysis approach alongside during data collection, allowing for the information power approach to inform sample size. A key finding was the significant heterogeneity in how participants experienced both interoception and alexithymia. Some struggled to detect internal signals at all, which they related to a difficulty in recognising and thus regulating emotions. A number of these participants described being unable to discriminate between positive and negative emotions without using contextual cues. For others, especially those who experienced more general sensory hypersensitivity, bodily signals could become overwhelming, and were often the cause of catastrophising and subsequent anxiety. Both of these routes could lead to either meltdowns or shutdowns. However, some participants considered their experiences of interoception and alexithymia to be “normal,” and did not view it as affecting their anxiety.<br>
&nbsp;<br>
Title: <strong>Can Insights from the MAS’ Coordination/Cooperation Dichotomy Enlighten Empathy Investigation?</strong><br>
Poster Number: 109<br>
Authors: <strong>Eliott, Fernanda</strong><br>
Abstract: In the Multi-Agent-Systems (MAS) literature, it is not rare to see coordination and cooperation interchangeably used. That drove us to reflect on the dichotomy between the two concepts, which can serve as a backbone to guide an intriguing investigation of empathy and decision-making. We are inspired by Malone and Crowston (1990), whose work provides examples of coordination and a framework to facilitate interdisciplinary transfers and the creation of cooperative tools. Hence, we started examining questions as below through the lenses of coordination vs.&nbsp;cooperation in MAS: What distinguishes coordination from cooperation? Why do you pick one instead of the other to characterize a task? Would you change your choice if focusing on the actor(s) making decisions instead of the task? What can be learned about empathy and moral decision-making as we investigate these questions? Is morality a combinatorial system? More specifically, we are dissecting concepts related to homeostatic regulation, decision-making, environment, task, and affordances to create a framework for a mapping of ensembles. We are tracking definitions across concepts, disciplines, and experts to depict how they intercept visually – and we invite people across cultures to share their insights so that we can adjust this work accordingly. In summary, we are examining multidisciplinary sources to create a cognitively grounded taxonomy and framework. We aim to help the MAS community easily identify a testbed to assess their affective-inspired computational approaches and to provide an additional resource for people interested in research on emotion. Finally, this invigorating work contributes to AI literacy efforts.<br>
&nbsp;<br>
Title: <strong>Triumph - not pride - is the main emotion expressed after success in non-interactive sports</strong><br>
Poster Number: 110<br>
Authors: <strong>Krippl, Martin; Königsmark, Varg</strong><br>
Abstract: Hwang and Matsumoto (2012) demonstrated the distinguishability of triumph from pride expressions in Judo fighters. They identified three factors (Hwang &amp; Matsumoto, 2014)— expansion, aggression, and attention—constituting triumph expressions, while pride was characterized by expansion and smiling. Our study aimed to determine the dominant emotion (triumph or pride) expressed in non-fighting, non-interactive sports, specifically elite high jumpers, utilizing the Facial Action Coding System (FACS, Ekman, Friesen &amp; Hager, 2002). Data from 66 elite high jumpers during their seasonal main event were analyzed, comparing conditions of successful clearance with bar failure and a baseline period. Triumph and pride were differentiated primarily by aggressive and expansive behaviors, respectively. Results indicate that triumph/aggression prevailed as the primary emotion/behavior post-bar clearance, with pride/expansion also more frequent than during baseline. However, pride/expansion levels failed to differentiate between bar clearance and failure. Notably, actions such as making a fist, shouting, lowering the eyebrows (Action Unit [AU] 4), and raising the upper lip (AU 10) occurred significantly more after successful bar clearance than after failure. Regression analysis, using triumph as a criterion, predicted competition rank, seasonal best, personal best, and absolute height significantly. Pride frequency after clearance was predicted by height, personal best, and rank, excluding seasonal best. Triumph consistently had higher predicted variance than pride. PCA identified aggression/triumph and expansion/pride factors, introducing additional factors like social signals (including clapping), punching above the shoulders, and pointing. Results show triumph to be more related to success than pride, even in non-interactive sports competition.<br>
&nbsp;<br>
Title: <strong>Parent Empathy and Adolescent Disclosure in the Context of Type 1 Diabetes Management</strong><br>
Poster Number: 111<br>
Authors: <strong>Main, Alexandra; Wiebe, Deborah; Miramontes, Maritza; Disla, Janice; Hanes, Erica; Cakan, Nedim; Raymond, Jennifer</strong><br>
Abstract: Close interpersonal relationships are an important feature of health and wellbeing across development (Pietromonaco &amp; Collins, 2017). Adolescent disclosure to parents is a key aspect of positive parent-adolescent relationships and youth adjustment (Smetana et al., 2006). However, it is unclear whether parental empathy influences adolescents‚Äô disclosure to parents in the moment, as well as their overall tendency to disclose to parents about their diabetes management challenges. We leveraged a study of diverse families with an adolescent with type 1 diabetes (Mage = 12.74 years, 56% female, 80% Latinx) to examine how observed parental empathy during parent-adolescent conflict discussions about diabetes management was associated with observed adolescent disclosure and adolescent self-reported disclosure to parents. Parent empathy, adolescent disclosure, and parent positive affect during parent-adolescent conversations were rated by trained coders. Parents reported on their own empathy using the Interpersonal Reactivity Index (Davis, 1983) and adolescents reported on their own disclosure (Osborn et al., 2013), parental knowledge of their diabetes management (Berg et al., 2008), and parental acceptance (Epstein, 1983). Correlation analyses revealed that observed parental empathy was associated with both observed (r = .33, p = .01) and self-reported disclosure (r = .24, p = .04). These associations remained in hierarchical multiple regressions after covarying other parent-adolescent relationship and parent dispositional, demographic, and diabetes variables (Œ≤ = .30, p = .03 and Œ≤ = 0.31, p = .015, respectively). This study holds implications for promoting greater parental communication of empathy to encourage adolescent disclosure in the context of chronic illness management.<br>
&nbsp;<br>
Title: <strong>Emotion Regulation and Well-Being of Families with Children Who Have Learning Disorders</strong><br>
Poster Number: 112<br>
Authors: <strong>Verdaguer-Ribas, Oriol; Aguilera, Mari ; Ahufinger, Nadia; Mayo, Coral; Andreu, Llorenç; Sanz-Torrent, Mònica</strong><br>
Abstract: Previous studies have suggested that parents of children that have specific learning disorders (LD), dyslexia, dyscalculia, ADHD and developmental language disorder (DLD) exhibit higher levels of distress and a higher probability of being anxious, depressed and/or stressed than parents of typically developing children. This study investigated the emotion regulation and well-being of parents whose children have LD. Emotion regulation (DERS) and affective symptomatology (DASS) questionnaires were administered to 123 parents (106 mothers) in order to assess their emotion regulation and emotional well-being, respectively. Parents were divided in three groups: i) parents whose children have typical development (TD), ii) whose children have only one of these disorders (DLD, dyslexia, dyscalculia or ADHD) and a third group of iii) those who had children who had two or more of these LD. Parents whose children had at least two of the LD are the group that struggle the most regarding emotion regulation and more emotional symptomatology. That is, they showed statistically significant differences when it comes to DERS and DASS total scores compared to the two other groups. Furthermore, parents whose children had just one disorder exhibited more difficulties in emotion regulation and emotional symptomatology than the TD group and these differences were statistically significant. Our findings demonstrate that having a kid with a learning disorder involves more emotional suffering and more difficulties in parents’ emotion regulation. Furthermore, an increase in the number of children with learning difficulties leads to a significantly higher level of parent emotion dysregulation and emotional symptomatology.<br>
&nbsp;<br>
Title: <strong>Impact of Emotional Abuse on Empathy: The Mediating Roles of Alexithymia and Sensory Processing Sensitivity</strong><br>
Poster Number: 113<br>
Authors: <strong>McQuarrie, Amanda; Jakobson, Lorna S; Smith, Stephen D</strong><br>
Abstract: Childhood emotional abuse can impact the development of empathy. To examine whether personality variables related to atypicalities in emotional awareness mediate this relationship, we had 499 participants (M = 20.2 years; 77.2% female) complete self-report measures of childhood emotional abuse, empathy and related constructs, alexithymia, and sensory processing sensitivity (SPS). We distinguished between an “adaptive” facet of SPS (being sensitive to subtle cues) and a potentially “maladaptive” facet (being sensitive to uncomfortable stimuli). Full mediation was supported in all tested models. Those reporting greater exposure to childhood emotional abuse scored higher on all three mediators (alexithymia and both facets of SPS). Both maladaptive and adaptive facets of SPS predicted stronger behavioural and emotional contagion (key variables thought to underlie empathy). Alexithymia interfered with, and SPS (particularly the adaptive facets), promoted the ability to understand and feel for other people. Both facets of SPS predicted the ability to imagine how fictional characters feel. Finally, feeling personal distress in tense interpersonal situations was positively mediated by alexithymia and maladaptive SPS traits, and negatively mediated by adaptive SPS traits. This latter finding suggests that alexithymia and maladaptive SPS traits interfere with the ability to self-regulate when seeing others who are suffering; this could limit one’s ability or desire to act with compassion. Overall, the findings suggest that aspects of personality are shaped by exposure to childhood emotional abuse, and that individual differences in the relative strength of specific traits linked to alexithymia and SPS are important determinants of variations in empathy-related constructs.<br>
&nbsp;<br>
Title: <strong>Religiosity and Emotion Regulation Strategies among the Hindus in India</strong><br>
Poster Number: 114<br>
Authors: <strong>Thingujam, Nutankumar S</strong><br>
Abstract: Past research showed that the cognitive reappraisal dimension of emotion regulation was associated with higher religiosity among Christianity, Islam and Judaism participants. In the current study, one hundred Hindus in North East India (Males = 48; Mean age = 25.42; age ranged from 20 to 32 years) responded to two religiosity scales (Attitude toward Hinduism Scale, Francis, Santosh, Robbins, &amp; Vij, 2008; 20-item Dimensions of Religiosity Scale, Joseph &amp; Diduca, 2007) and two measures of emotion regulation strategies (Gross &amp; John, 2003; Garnefski &amp; Kraaij, 2006). Results indicated that the earlier finding of the correlation between emotion regulation and religiosity is replicated. In particular, positive attitude toward religion, intrinsic religious orientation, extrinsic social religious orientation, extrinsic personal religious orientation, and other dimensions of religiosity (preoccupation, conviction, emotional involvement, and guidance) were significantly associated with many aspects of both the emotion regulation questionnaire and cognitive emotion regulation questionnaire. However, Gross and John’s emotion regulation questionnaire, which was utilized in both the present and past studies, yielded inadequate alpha reliabilities in the present data (α = &gt;. 479 for cognitive reappraisal &amp; .457 for emotional suppression). Nevertheless, Garnefski and Kraaij’s cognitive emotion regulation questionnaire provided acceptable alpha reliabilities (α = .72 to .79) except for the acceptance strategy of cognitive emotion regulation (α = .66). Thus, the present study extends the earlier findings on the relationship between religiosity and emotion regulation in various cognitive emotion regulation strategies.<br>
&nbsp;<br>
Title: <strong>Basic Symbolic Number Skills Longitudinally Predict Mathematics Anxiety in the First Years of Primary School</strong><br>
Poster Number: 115<br>
Authors: <strong>O’Connor, Patrick A.; Morsanyi, Kinga; McCormack, Teresa</strong><br>
Abstract: Mathematical anxiety (MA) and mathematics performance typically correlate negatively in studies of adolescents and adults, but not always amongst young children, with some theorists questioning the relevance of MA to mathematics performance in this age group. Evidence is also limited in relation to the developmental origins of MA and whether MA in young children can be linked to their earlier mathematics performance. To address these questions, the current study investigated whether basic and formal mathematics skills around 4 and 5 years of age were predictive of MA around the age of 7–8. Additionally, we also examined the cross-sectional relationships between MA and mathematics performance in 7–8-year-old children. Specifically, children in our study were assessed in their first (T1; aged 4–5), second (T2; aged 5–6), and fourth years of school (T3; aged 7–8). At T1 and T2, children completed measures of basic numerical skills, IQ, and working memory, as well as curriculum-based mathematics tests. At T3, children completed two self-reported MA questionnaires, together with a curriculum-based mathematics test. The results showed that MA could be reliably measured in a sample of 7–8-year-olds and demonstrated the typical negative correlation between MA and mathematical performance (although the strength of this relationship was dependent on the specific content domain). Importantly, although early formal mathematical skills were unrelated to later MA, there was evidence of a longitudinal relationship between basic early symbolic number skills and later MA, supporting the idea that poorer basic numerical skills relate to the development of MA.<br>
&nbsp;<br>
Title: <strong>Cognitive Reappraisal of Food Reduces Desire to Eat but at the Cost of Increasing Negative-Emotionality.</strong><br>
Poster Number: 116<br>
Authors: <strong>Saad, Maram; Weinbach, Noam</strong><br>
Abstract: Cognitive reappraisal has been traditionally studied as an emotion regulation strategy for downregulating negative affect. In recent years, studies have demonstrated that cognitive reappraisal can be used for downregulating the desire to eat by reinterpreting thoughts regarding food and eating (e.g., thinking about the negative consequences of eating particular foods). Given that emotions and food craving are tightly linked, this study assessed the potential influence of food-related reappraisal on negative emotionality. The study included 40 healthy participants who performed a computerized task in which participants were presented with their own craved foods and were required to either watch these food items naturally or use food-related reappraisal to downregulate their desire to eat these foods. Then, participants rated their negative affect and desire to eat. Replicating previous results, participants successfully used cognitive reappraisal for downregulating their desire to eat their own craved foods. However, the results also demonstrated that food-related reappraisal increased negative affect. Despite previous suggestions regarding the potential of using cognitive reappraisal for treating obesity, the current study highlights the need to better understand potential costs of food-related reappraisal due to its potential negative impact on emotional well-being.<br>
&nbsp;<br>
Title: <strong>Eye-Movement Study of the Discrimination Between Facial Expressions of Fear and Surprise: Can Individuals be Trained?</strong><br>
Poster Number: 117<br>
Authors: <strong>Gallant, Adele; Cloutier, Karolyn; Richard, Mia; Roy-Charland, Annie</strong><br>
Abstract: The project explored the perceptual-attentional limitation hypothesis in the discrimination between fear and surprise and the presence of a bias for the mouth. We also investigated if participants could be trained to focus on relevant cues (brows/mouth), and if that training would impact emotion discrimination accuracy. Participants completed a pre-test, a training, and a post-test (identical to the pre-test task). Participants viewed either pairs of fear expressions, or pairs of fear and surprise and were instructed to judge if the emotions were the same or different. The training phase for the experimental group was the same task but with feedback (correct or incorrect) after each trial. The control group completed an unrelated cognitive task. Experiment 2 followed the same procedure, but with different encoders in the training phase. This was done to circumvent the possible role of differing exposure to the stimuli between groups (experimental and control). The results from both experiments do not clearly support the presence of bias for the mouth; neither in accuracy, nor in time spent in the relevant areas. Results suggest that the perceptual-attentional limitation might be attentional rather than perceptual but, once again, other factors seem to come into play. In both experiments the experimental group was more accurate in the post-test, suggesting that the training improved accuracy and changed the focus of attention. These findings indicate that the confusion between fear and surprise is not due to irreversible limitations (e.g., biological factors) since individuals can be trained to improve their discrimination.<br>
&nbsp;<br>
Title: <strong>Contextual Influence or Racial Bias? the Intersection of Emotion Perception and Emoter Race</strong><br>
Poster Number: 118<br>
Authors: <strong>Reschke, Peter; Walle, Eric A</strong><br>
Abstract: Research has documented the influence of “context” (e.g., posture, scene, voice, social cues) on emotion perception. However, another factor has received less attention: emoter race. Better understanding of how the race of the one whose emotion is being perceived may influence emotion categorization is of utmost importance. In two studies, two separate samples of 80 participants from a predominantly white U.S. university were shown fully crossed, photoshopped combinations of faces and postures posed by distinct actors of different races (Asian, Black, Hispanic, White) expressing anger, disgust, fear, sadness, and joy. Study 1 subjects were asked to categorize the emotion using forced choice. Study 2 subjects were recorded “telling a story” about each face-posture combination (shown in a random order for 30 s) and their narrations were transcribed and labels matching the face emotion were extracted and summed for analysis. For study 1, a repeated-measures GLMM revealed a significant Face ´ Posture ´ Race interaction predicting face categorizations, ps &lt; .001, highlighting nuances in contextualized facial emotion perception. For instance, participants were equally as likely to categorize a Disgust-Anger face-posture combination as ‘disgust’ (M = 44%) or ‘anger’ (M = 42%) if the race of the emoter was white (p = ns). How, subjects were overwhelmingly more likely to categorize the same face-posture combination as ‘anger’ (M = 81%) than ‘disgust’ (M = 15%) if the emoter was Black (p &lt; .001). A GLMM for study 2 partially confirmed this pattern (p = .007). Implications for emotion perception and anti-racist practices will be discussed.<br>
&nbsp;<br>
Title: <strong>Two Types of Shame, and Why They Frequently Co-Occur</strong><br>
Poster Number: 119<br>
Authors: <strong>Parrott, W. Gerrod</strong><br>
Abstract: One longstanding approach to shame construes it as a response to the public exposure of a personal defect, failure, or transgression. An alternative approach depicts shame as resulting from a broadly negative self-assessment that is internal and personal, not external and public. These approaches describe two contrasting emotions that could be called “public shame” and “private shame.” Private shame would involve judging oneself to be defective, contemptible, or inferior without feeling publicly exposed or worried about other people’s lowered esteem. Public shame would involve the reverse: recognizing that one faces public disapproval and reputational damage without losing self-esteem. I will present evidence from an American sample that both forms of shame occur. Occasionally one type of shame occurs in the absence of the other, but more often both forms occur simultaneously and I will discuss three reasons for their co-occurrence. (1) Perceiving one’s self to be flawed often gives rise to anticipation of public disapproval. (2) Public disapproval typically elicits some degree of personal concurrence. (3) Private and public shame are associated with individualist and collectivist cultures, respectively, but in all cultures people’s self-concepts incorporate both independent and interdependent elements thereby allowing the experience of both private and public shame.<br>
&nbsp;<br>
Title: <strong>Any-to-Any: How Moral Events Evoke Emotions by Way of Appraisals</strong><br>
Poster Number: 120<br>
Authors: <strong>Lopez, Lukas; Dahl, Audun; Walle, Eric A</strong><br>
Abstract: Moral events evoke emotions that shape situations. The morally outraged person may protest the violation; the morally disgusted may avoid the violator. Appraisals are key determinants of moral emotions. An appraisal perspective predicts an any-to-any relation between events and emotions: Any moral event could evoke any emotion, depending on how the person appraises the event. Appraisal accounts differ from traditional accounts of 1-to-1 correspondences between moral domains and emotions (Rozin et al., 1999), and constructionist theories that deny appraisal emotion links (Cameron et al., 2015). In four preregistered studies, we 1) assessed variations in participants’ emotion responses to moral violations from different moral domains (Graham et al., 2009; Rozin et al., 1999), and 2) examined participants’ corresponding appraisal dimension ratings (Lazarus, 2006; Piazza et al., 2019). Fit indices (AIC, and BIC scores) of Generalized Linear Mixed Models revealed that specific moral events predicted participants’ emotions better than moral domains for violations from both Rozin et al.&nbsp;(1999) and Graham et al.&nbsp;(2009). Further Mixed Linear Models found that all emotions (anger, disgust, surprise, sadness, fear) were positively associated with appraisal ratings of personal value and ‘no emotion’ responses associated with lower personal value ratings. Participant anger was also significantly associated with appraisals of predictability and preventability, while disgust and surprise had significant associations with unexpectedness appraisals. Further experimental evidence indicated that appraisal framings of moral and political events changed emotional responses. In support of appraisal accounts, results demonstrated that appraisals, not moral domains, accounted for emotional responses to moral events.<br>
&nbsp;<br>
Title: <strong>Aesthetics of Illustrations in Emotional Design: Effects on User Experience and Multimedia Learning.</strong><br>
Poster Number: 122<br>
Authors: <strong>Venni, Julien; Betrancourt, Mireille</strong><br>
Abstract: In multimedia learning, emotional design is defined as the deliberate manipulation of design elements to induce emotional states conducive to learning (Plass &amp; Kaplan, 2016). Although emotional design is supposed to increase visual attractiveness, no study has yet explored the effect of aesthetic value on learning. An experimental study (N=60) compared two versions of an instructional website including the same illustrations either with high aesthetic or low aesthetic visual design (as assessed in a preliminary study). Participants had to perform four information search tasks and a learning task. Data collected included performances, subjective evaluations (interest, user experience, cognitive load), and eye gaze. Results indicated that participants in high aesthetic condition expressed higher activated (t(58) = 2.06, p &lt;.022) and maintained (t(58) = 2.86, p &lt;.003) situational interest. In addition, user experience was enhanced in the high aesthetic condition (t(58) = 3.09, p = .002). Yet, there was no effect on learning performance and only one of the four information tasks lead to better scores in the high aesthetic version. There was no difference in extraneous cognitive load, measuring format-induced complexity, but the high esthetic version was perceived as more difficult (t(58) = 2.00, p = .05). Additionally, in the first 5 seconds, illustrations with low aesthetic design held attention longer (t(28) = -2.82, p = .004). Overall, the findings indicate that aesthetic visual design is a strong determinant of affective measures that are known to be associated with learning, though it may not have direct effect on short-term learning performances.<br>
&nbsp;<br>
Title: <strong>The Effect of Computationally-Derived Affective States on Memory</strong><br>
Poster Number: 123<br>
Authors: <strong>Pupillo, Francesco</strong><br>
Abstract: Fluctuations of affective states are a common everyday life experience which have been shown to influence cognitive performance. However, there is no consensus on the direction of this relationship; in fact, while some studies have found detrimental effects of negative and positive affective states on cognition, others reported cognitive improvements under either negative or positive affective states. The heterogeneity of the findings on affect-cognition interaction can be attributable to the variety of methods that have been used to induce affective states. Recent theoretical accounts propose that affective states can be mapped onto parameters derived from computational models applied to reinforcement learning tasks, such as expected reward and prediction error. As a consequence, reinforcement learning tasks can also be use to induce fluctuations in affective states. The present study intends to use a reinforcement learning task to manipulate the fluctuations in affect and link them to prospective memory retrieval, namely the likelihood of remembering intentions when specific conditions occur. The aim of the present study is two-fold. Firstly, it expects to find the specific computational properties of affective states, by linking participants’ self-reported affect to the parameters of a reinforcement learning model fit to participants’ data. Secondly, by linking the computational features of affect to prospective memory performance, it will provide new evidence on the relationship between affect and cognition. Data collection is still ongoing.<br>
&nbsp;<br>
Title: <strong>Metacognitive Confidence and Affect - Two Sides of the Same Coin?</strong><br>
Poster Number: 124<br>
Authors: <strong>Voodla, Alan; Uusberg, Andero; Desender, Kobe</strong><br>
Abstract: Decision confidence is a prototypical metacognitive representation as it has been shown to track the probability that a decision is correct in various computational models and experiments. Confidence has also been associated with affective valence, such that higher confidence is associated with more positive affect and vice versa. This suggests that similarly to confidence, in decision-making contexts affect could be a metacognitive signal reflecting the probability that a decision is correct. We tested this proposal in 2 perceptual decision-making experiments, where we investigated confidence and affect ratings in response to the probability that a decision is correct manipulated via expected and actual task difficulty. The findings indicate that confidence and affect ratings both track the probability that a decision is correct. We discuss various mechanisms and future directions that could clarify the cognitive and affective aspects of confidence.<br>
&nbsp;<br>
Title: <strong>Emotion Regulation Choice under Cognitive Load</strong><br>
Poster Number: 125<br>
Authors: <strong>Ortner, Catherine NM; Adeyemi-King, Faridah</strong><br>
Abstract: When regulating their emotions, individuals choose distraction over reappraisal for high intensity negative stimuli and vice versa for low intensity negative stimuli (Sheppes et al., 2014). Presumably, they weigh the costs (e.g., effort to reappraise, Sheppes et al., 2014) and benefits (e.g., enduring effects of reappraisal on negative emotions, Thiruchselvam et al., 2011) of choosing each strategy, according to the context. However, the cognitive processes underlying such choices are not well-understood. Deliberate executive control processes may be engaged to override a tendency to disengage attention from intense negative stimuli (Sheppes et al., 2014). Accordingly, emotion regulation choice should be cognitively costly, particularly for high intensity stimuli. We tested this proposition in an experiment in which we manipulated stimulus intensity and cognitive load during emotion regulation choices. Adult participants (N = 65) learned how to implement reappraisal and distraction. After briefly viewing each of 60 negative images (30 low and 30 high intensity), participants viewed a display of a single digit (low cognitive load) or a series of five digits (high cognitive load). They chose between reappraisal and distraction before being prompted to enter the digits. Participants were more likely to choose distraction for high than low intensity stimuli, but there was no effect of cognitive load and no interaction. Decision times were slower under high than low cognitive load, but there were no other effects on decision times. Results suggest that emotion regulation choice is effortful, independent of stimulus intensity. Implications for the emotion regulation choice process will be discussed.<br>
&nbsp;<br>
Title: <strong>Emotions Felt While Gambling: a Comparison Between Scratch Card, Slot Machines, and Casino Gamblers</strong><br>
Poster Number: 126<br>
Authors: <strong>Monaci, Mariagrazia; Scacchi, Luca</strong><br>
Abstract: Theoretical models and previous evidence suggest that difficulty in regulating emotions might be involved in gambling, and that dysfunctional gambling behavior is associated to emotional (dys)regulation. Also, different games may elicit different emotions, and therefore being differently associated to emotion regulation. The aim of the study is to compare the emotions felt while gambling in three non-clinical subgroups: scratch-card, slot machine, and casino gamblers, games with a different collocation and perception on the chance-ability dimension. Participants (N = 425 gamblers, 45.7%F) contacted in three different contexts (scratch-card vendors N = 160, 56.9%F; slot machine venues, N = 129, 48.8%F; casino N = 136, 55.9%F) completed a questionnaire including the 2 question lie/bet instrument, a list of high/low arousal positive and negative emotions felt while gambling, locus of control. No gender differences emerged among the subgroup of players, while age is higher in casino players, followed by slot machine and finally scratch-card players. Main results confirmed that problematic gamblers have a less internal locus of control, alike to slot-machine and scratch-card gamblers compared to casino gamblers, who mainly chose games less associated to pure chance. Problematic gamblers feel more negative emotions and more high arousal positive emotions, the latter significantly more intense in scratch-card players, while negative emotions are higher in slot-machine players followed by casino and lastly by scratch-card players. Findings suggest considering gamblers as a heterogeneous group with respect to their search for emotions and, in addition, that regulation of positive emotions may play a central role in gambling.<br>
&nbsp;<br>
Title: <strong>The Power of Love</strong><br>
Poster Number: 127<br>
Authors: <strong>Edwards, Lauren</strong><br>
Abstract: The idea that love is a disposition, or involves dispositions, is not new…The problem is that nobody in the literature on love seems to have properly considered the question of what a disposition is and whether a better understanding of it can help us construct a plausible dispositional theory of love. (Naar 2013, p.&nbsp;344) It is precisely this problem - what is a disposition (aka power) and what can the ontology of dispositions tell us about love’s nature – that this paper attempts to answers. I argue that if love is a power then, because it is a disposition, the starting assumption ought to be that it shares the qualities of powers. In particular, I examine three, uncontroversial properties of dispositions: (1) they have stimuli events and manifestations; (2) they exist independently of the actualization of those stimuli events/manifestations; and (3) they are massively multi-track. If love shares in these qualities, then it can, radically, exist without a beloved. In other words, there can be love even when this love is not of anything. This would fly in the face of nearly all current, philosophical, and scientific understandings of love. But, if it’s true, it would have significant consequences. For instance, it would suggest a type of expansive love that could be cultivated on one’s own. This, I submit, can be understood as a character trait – as being a loving person – or a more realistic and general way of conceptualizing agape (love of all humanity).<br>
&nbsp;<br>
Title: <strong>An Event-Related Potential Examination of the Neural Responses to Emotional and Movement-Related Images</strong><br>
Poster Number: 128<br>
Authors: <strong>Smith, Stephen D; MacKay, Christine; Desroches, Amy</strong><br>
Abstract: Previous neuroimaging research has demonstrated that the perception of emotional images elicits activity in brain regions related to the planning and execution of movements. However, little research has investigated whether these emotion-movement interactions occur at early or later stages of visual perception. In the current research, event-related potentials (ERPs) were used to examine the time course of the independent and combined effects of perceiving emotions and implied movement. Twenty-five participants viewed images from four categories: 1) emotional images involving a scenario that implied movement; 2) emotional images containing no implied movement; 3) neutral images involving a scenario that implied movement, and 4) neutral images with no implied movement. Both emotional stimuli and movement-related stimuli led to larger N200 (200-300 ms) ERP components. Furthermore, at frontal sites, there was a marginal interaction between emotion and implied movement, such that negative stimuli showed greater N200 amplitudes vs.&nbsp;neutral stimuli, but only for images with implied movement. The late positive potential (LPP; 500-1000ms) was significant for emotion (at frontal sites) and movement (at frontal, central, and posterior sites). The LPP also produced a significant interaction at parietal sites, with larger LPPs for negative vs.&nbsp;neutral images, but only if the images contained implied movement. Together, these results suggest that the perception of emotion and movement interact at later stages of visual perception. They also highlight the importance of controlling for implied movement when developing stimulus sets for affective neuroscience research.<br>
&nbsp;<br>
Title: <strong>Meaning, Modernity, and the Machine: Theories About Emotional Vectors and AI-Generated Images as Art</strong><br>
Poster Number: 129<br>
Authors: <strong>Johnson, Perry</strong><br>
Abstract: Images generated by Artificial Intelligence (AI) have been lauded as “art” that will replace human artists. Can the emotional payload of art be conveyed by a machine without emotional understanding? There is an implicit understanding between artist and viewer that art contains meaning and was created by an individual with whom empathy is possible. This discourse will explore three possible mechanisms through which AI-generated images elicit emotions, and whether each mechanism serves the same purpose as art. One potential is to see the machine as a transparent lens on the emotional context of the dataset that created it, in the way that a premodern artist was a transparent lens. The notion of an individual artist’s unique expression is barely half a millennium in development; throughout most of human history, individual expression was not seen as the emotional goal of art. Therefore, AI may fit the mold of premodern creator. A second possible emotional vector is that the viewer uses the image to perceive themselves, projecting their own context onto the image. Their emotional response is not predicated on any larger cultural context or empathy with the creator of the image. A third possibility is that there is an emotional understanding, real or imagined, within the machine. Only if the machine is emotionally aware can it serve the same purpose as the artist. The purpose of the artist is not to give an emotional hit; the purpose of the artist is to connect.<br>
&nbsp;<br>
</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.isre.org/">
      <i class="bi bi-globe" role="img" aria-label="Website">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/company/isre-org/?viewAsMember=true">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/isreorg">
      <i class="bi bi-twitter-x" role="img" aria-label="Twitter">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.facebook.com/IsreOrg/">
      <i class="bi bi-facebook" role="img" aria-label="Facebook">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/isre.ig/">
      <i class="bi bi-instagram" role="img" aria-label="Instagram">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>